<!-- doc/src/sgml/textsearch.sgml -->

<chapter id="textsearch">
<!-- pgdoc-cn_start sig_en=e7ef1f9cbd5dd4841d90aa373a6649b6 sig_cn_org=None source=14.1 
 <title>Full Text Search</title>
________________________________________________________-->
 <title>全文搜索</title>
<!-- pgdoc-cn_end sig_en=e7ef1f9cbd5dd4841d90aa373a6649b6 -->

<!-- pgdoc-cn_start sig_en=a3f31bb7aa91767d2d3a123cada472cc sig_cn_org=None source=14.1 
  <indexterm zone="textsearch">
   <primary>full text search</primary>
  </indexterm>
________________________________________________________-->
  <indexterm zone="textsearch">
   <primary>全文搜索</primary>
  </indexterm>
<!-- pgdoc-cn_end sig_en=a3f31bb7aa91767d2d3a123cada472cc -->

<!-- pgdoc-cn_start sig_en=7e4c6554f398f6fea21f9aa782798154 sig_cn_org=None source=14.1 
  <indexterm zone="textsearch">
   <primary>text search</primary>
  </indexterm>
________________________________________________________-->
  <indexterm zone="textsearch">
   <primary>文本搜索</primary>
  </indexterm>
<!-- pgdoc-cn_end sig_en=7e4c6554f398f6fea21f9aa782798154 -->

 <sect1 id="textsearch-intro">
<!-- pgdoc-cn_start sig_en=c2fcf93c611ba5f3baff759a5cc428dd sig_cn_org=None source=14.1 
  <title>Introduction</title>
________________________________________________________-->
  <title>介绍</title>
<!-- pgdoc-cn_end sig_en=c2fcf93c611ba5f3baff759a5cc428dd -->

<!-- pgdoc-cn_start sig_en=7b097ddaf96e3c078e251f727e379ccb sig_cn_org=None source=14.1 
  <para>
   Full Text Searching (or just <firstterm>text search</firstterm>) provides
   the capability to identify natural-language <firstterm>documents</firstterm> that
   satisfy a <firstterm>query</firstterm>, and optionally to sort them by
   relevance to the query.  The most common type of search
   is to find all documents containing given <firstterm>query terms</firstterm>
   and return them in order of their <firstterm>similarity</firstterm> to the
   query.  Notions of <varname>query</varname> and
   <varname>similarity</varname> are very flexible and depend on the specific
   application. The simplest search considers <varname>query</varname> as a
   set of words and <varname>similarity</varname> as the frequency of query
   words in the document.
  </para>
________________________________________________________-->
  <para>
   全文搜索（或者<firstterm>文本搜索</firstterm>）提供了确定满足一个<firstterm>查询</firstterm>的自然语言<firstterm>文档</firstterm>的能力，并可以选择将它们按照与查询的相关度排序。最常用的搜索类型是找到所有包含给定<firstterm>查询词</firstterm>的文档并按照它们与查询的<firstterm>相似性</firstterm>顺序返回它们。<varname>查询</varname>和<varname>相似性</varname>的概念非常灵活并且依赖于特定的应用。最简单的搜索认为<varname>查询</varname>是一组词而<varname>相似性</varname>是查询词在文档中的频度。
  </para>
<!-- pgdoc-cn_end sig_en=7b097ddaf96e3c078e251f727e379ccb -->

<!-- pgdoc-cn_start sig_en=74b9b3e924c49494cf2c1c723e27b685 sig_cn_org=None source=14.1 
  <para>
   Textual search operators have existed in databases for years.
   <productname>PostgreSQL</productname> has
   <literal>~</literal>, <literal>~*</literal>, <literal>LIKE</literal>, and
   <literal>ILIKE</literal> operators for textual data types, but they lack
   many essential properties required by modern information systems:
  </para>
________________________________________________________-->
  <para>
  文本搜索操作符已经在数据库中存在很多年了。<productname>PostgreSQL</productname>对文本数据类型提供了<literal>~</literal>、<literal>~*</literal>、<literal>LIKE</literal>和<literal>ILIKE</literal>操作符，但是它们缺少现代信息系统所要求的很多基本属性：
  </para>
<!-- pgdoc-cn_end sig_en=74b9b3e924c49494cf2c1c723e27b685 -->

  <itemizedlist  spacing="compact" mark="bullet">
   <listitem>
<!-- pgdoc-cn_start sig_en=e93697f84f17ab4c3180fbf5a5af1031 sig_cn_org=None source=14.1 
    <para>
     There is no linguistic support, even for English.  Regular expressions
     are not sufficient because they cannot easily handle derived words, e.g.,
     <literal>satisfies</literal> and <literal>satisfy</literal>. You might
     miss documents that contain <literal>satisfies</literal>, although you
     probably would like to find them when searching for
     <literal>satisfy</literal>. It is possible to use <literal>OR</literal>
     to search for multiple derived forms, but this is tedious and error-prone
     (some words can have several thousand derivatives).
    </para>
________________________________________________________-->
    <para>
     即使对英语也缺乏语言的支持。正则表达式是不够的，因为它们不能很容易地处理派生词，例如<literal>satisfies</literal>和<literal>satisfy</literal>。你可能会错过包含<literal>satisfies</literal>的文档，尽管你可能想要在对于<literal>satisfy</literal>的搜索中找到它们。可以使用<literal>OR</literal>来搜索多个派生形式，但是这样做太罗嗦也容易出错（有些词可能有数千种派生）。
    </para>
<!-- pgdoc-cn_end sig_en=e93697f84f17ab4c3180fbf5a5af1031 -->
   </listitem>

   <listitem>
<!-- pgdoc-cn_start sig_en=cb1f55d3e859c0cfd0c61cf2798f47e7 sig_cn_org=None source=14.1 
    <para>
     They provide no ordering (ranking) of search results, which makes them
     ineffective when thousands of matching documents are found.
    </para>
________________________________________________________-->
    <para>
     它们不提供对搜索结果的排序（排名），这使它们面对数以千计被找到的文档时变得无效。
    </para>
<!-- pgdoc-cn_end sig_en=cb1f55d3e859c0cfd0c61cf2798f47e7 -->
   </listitem>

   <listitem>
<!-- pgdoc-cn_start sig_en=9a52e5f1f969d8406cb37072dc389c2f sig_cn_org=None source=14.1 
    <para>
     They tend to be slow because there is no index support, so they must
     process all documents for every search.
    </para>
________________________________________________________-->
    <para>
     它们很慢因为没有索引支持，因此它们必须为每次搜索处理所有的文档。
    </para>
<!-- pgdoc-cn_end sig_en=9a52e5f1f969d8406cb37072dc389c2f -->
   </listitem>
  </itemizedlist>

<!-- pgdoc-cn_start sig_en=65f9d286f8f526729b8ca70f13af34be sig_cn_org=None source=14.1 
  <para>
   Full text indexing allows documents to be <emphasis>preprocessed</emphasis>
   and an index saved for later rapid searching. Preprocessing includes:
  </para>
________________________________________________________-->
  <para>
   全文索引允许文档被<emphasis>预处理</emphasis>并且保存一个索引用于以后快速的搜索。预处理包括：
  </para>
<!-- pgdoc-cn_end sig_en=65f9d286f8f526729b8ca70f13af34be -->

  <itemizedlist  mark="none">
   <listitem>
<!-- pgdoc-cn_start sig_en=c0242b24298b53e430279404ea71c873 sig_cn_org=None source=14.1 
    <para>
     <emphasis>Parsing documents into <firstterm>tokens</firstterm></emphasis>. It is
     useful to identify various classes of tokens, e.g., numbers, words,
     complex words, email addresses, so that they can be processed
     differently.  In principle token classes depend on the specific
     application, but for most purposes it is adequate to use a predefined
     set of classes.
     <productname>PostgreSQL</productname> uses a <firstterm>parser</firstterm> to
     perform this step.  A standard parser is provided, and custom parsers
     can be created for specific needs.
    </para>
________________________________________________________-->
    <para>
     <emphasis>将文档解析成<firstterm>记号</firstterm></emphasis>。标识出多种类型的记号是有所帮助的，例如数字、词、复杂的词、电子邮件地址，这样它们可以被以不同的方式处理。原则上记号分类取决于相关的应用，但是对于大部分目的都可以使用一套预定义的分类。<productname>PostgreSQL</productname>使用一个<firstterm>解析器</firstterm>来执行这个步骤。其中提供了一个标准的解析器，并且为特定的需要也可以创建定制的解析器。
    </para>
<!-- pgdoc-cn_end sig_en=c0242b24298b53e430279404ea71c873 -->
   </listitem>

   <listitem>
<!-- pgdoc-cn_start sig_en=87d797e78f0d2341dcf3814ee014d149 sig_cn_org=None source=14.1 
    <para>
     <emphasis>Converting tokens into <firstterm>lexemes</firstterm></emphasis>.
     A lexeme is a string, just like a token, but it has been
     <firstterm>normalized</firstterm> so that different forms of the same word
     are made alike.  For example, normalization almost always includes
     folding upper-case letters to lower-case, and often involves removal
     of suffixes (such as <literal>s</literal> or <literal>es</literal> in English).
     This allows searches to find variant forms of the
     same word, without tediously entering all the possible variants.
     Also, this step typically eliminates <firstterm>stop words</firstterm>, which
     are words that are so common that they are useless for searching.
     (In short, then, tokens are raw fragments of the document text, while
     lexemes are words that are believed useful for indexing and searching.)
     <productname>PostgreSQL</productname> uses <firstterm>dictionaries</firstterm> to
     perform this step.  Various standard dictionaries are provided, and
     custom ones can be created for specific needs.
    </para>
________________________________________________________-->
    <para>
     <emphasis>将记号转换成<firstterm>词位</firstterm></emphasis>。和一个记号一样，一个词位是一个字符串，但是它已经被<firstterm>正规化</firstterm>，这样同一个词的不同形式被变成一样。例如，正规化几乎总是包括将大写字母转换成小写形式，并且经常涉及移除后缀（例如英语中的<literal>s</literal>或<literal>es</literal>）。这允许搜索找到同一个词的变体形式，而不需要冗长地输入所有可能的变体。此外，这个步骤通常会消除<firstterm>停用词</firstterm>，它们是那些太普通的词，它们对于搜索是无用的（简而言之，记号是文档文本的原始片段，而词位是那些被认为对索引和搜索有用的词）。<productname>PostgreSQL</productname>使用<firstterm>词典</firstterm>来执行这个步骤。已经提供了多种标准词典，并且为特定的需要也可以创建定制的词典。
    </para>
<!-- pgdoc-cn_end sig_en=87d797e78f0d2341dcf3814ee014d149 -->
   </listitem>

   <listitem>
<!-- pgdoc-cn_start sig_en=329c855b6cfff5f7a2bf3c73658773f2 sig_cn_org=None source=14.1 
    <para>
     <emphasis>Storing preprocessed documents optimized for
     searching</emphasis>.  For example, each document can be represented
     as a sorted array of normalized lexemes. Along with the lexemes it is
     often desirable to store positional information to use for
     <firstterm>proximity ranking</firstterm>, so that a document that
     contains a more <quote>dense</quote> region of query words is
     assigned a higher rank than one with scattered query words.
    </para>
________________________________________________________-->
    <para>
     <emphasis>为搜索优化存储预处理好的文档</emphasis>。例如，每一个文档可以被表示为正规化的词位的一个有序数组。与词位一起，通常还想要存储用于<firstterm>近似排名</firstterm>的位置信息，这样一个包含查询词更<quote>密集</quote>区域的文档要比那些包含分散的查询词的文档有更高的排名。
    </para>
<!-- pgdoc-cn_end sig_en=329c855b6cfff5f7a2bf3c73658773f2 -->
   </listitem>
  </itemizedlist>

<!-- pgdoc-cn_start sig_en=5e9f76754b6f7d71c5abb541a79ba1a9 sig_cn_org=None source=14.1 
  <para>
   Dictionaries allow fine-grained control over how tokens are normalized.
   With appropriate dictionaries, you can:
  </para>
________________________________________________________-->
  <para>
   词典允许对记号如何被正规化进行细粒度的控制。使用合适的词典，你可以：
  </para>
<!-- pgdoc-cn_end sig_en=5e9f76754b6f7d71c5abb541a79ba1a9 -->

  <itemizedlist  spacing="compact" mark="bullet">
   <listitem>
<!-- pgdoc-cn_start sig_en=a7129d91ca0cf84710f2bc7c18fdc0db sig_cn_org=None source=14.1 
    <para>
     Define stop words that should not be indexed.
    </para>
________________________________________________________-->
    <para>
     定义不应该被索引的停用词。
    </para>
<!-- pgdoc-cn_end sig_en=a7129d91ca0cf84710f2bc7c18fdc0db -->
   </listitem>

   <listitem>
<!-- pgdoc-cn_start sig_en=fa2ffc391eefeede8b72216b455ae748 sig_cn_org=None source=14.1 
    <para>
     Map synonyms to a single word using <application>Ispell</application>.
    </para>
________________________________________________________-->
    <para>
     使用<application>Ispell</application>把同义词映射到一个单一词。
    </para>
<!-- pgdoc-cn_end sig_en=fa2ffc391eefeede8b72216b455ae748 -->
   </listitem>

   <listitem>
<!-- pgdoc-cn_start sig_en=a94198d83c95f149ce8ebaf9714ed07c sig_cn_org=None source=14.1 
    <para>
     Map phrases to a single word using a thesaurus.
    </para>
________________________________________________________-->
    <para>
     使用一个分类词典把短语映射到一个单一词。
    </para>
<!-- pgdoc-cn_end sig_en=a94198d83c95f149ce8ebaf9714ed07c -->
   </listitem>

   <listitem>
<!-- pgdoc-cn_start sig_en=077b6a9d7b860eb16c0bda8f8fa848bc sig_cn_org=None source=14.1 
    <para>
     Map different variations of a word to a canonical form using
     an <application>Ispell</application> dictionary.
    </para>
________________________________________________________-->
    <para>
     使用一个<application>Ispell</application>词典把一个词的不同变体映射到一种规范的形式。
    </para>
<!-- pgdoc-cn_end sig_en=077b6a9d7b860eb16c0bda8f8fa848bc -->
   </listitem>

   <listitem>
<!-- pgdoc-cn_start sig_en=0ecc607f118efed3ba8507d4ff87d28c sig_cn_org=None source=14.1 
    <para>
     Map different variations of a word to a canonical form using
     <application>Snowball</application> stemmer rules.
    </para>
________________________________________________________-->
    <para>
     使用<application>Snowball</application>词干分析器规则将一个词的不同变体映射到一种规范的形式。
    </para>
<!-- pgdoc-cn_end sig_en=0ecc607f118efed3ba8507d4ff87d28c -->
   </listitem>
  </itemizedlist>

<!-- pgdoc-cn_start sig_en=e398a62c358dd9af961944f751cc0e58 sig_cn_org=None source=14.1 
  <para>
   A data type <type>tsvector</type> is provided for storing preprocessed
   documents, along with a type <type>tsquery</type> for representing processed
   queries (<xref linkend="datatype-textsearch"/>).  There are many
   functions and operators available for these data types
   (<xref linkend="functions-textsearch"/>), the most important of which is
   the match operator <literal>@@</literal>, which we introduce in
   <xref linkend="textsearch-matching"/>.  Full text searches can be accelerated
   using indexes (<xref linkend="textsearch-indexes"/>).
  </para>
________________________________________________________-->
  <para>
   我们提供了一种数据类型<type>tsvector</type>来存储预处理后的文档，还提供了一种类型<type>tsquery</type>来表示处理过的查询（<xref linkend="datatype-textsearch"/>）。有很多函数和操作符可以用于这些数据类型（<xref linkend="functions-textsearch"/>），其中最重要的是匹配操作符<literal>@@</literal>，它在<xref linkend="textsearch-matching"/>中介绍。全文搜索可以使用索引来加速（<xref linkend="textsearch-indexes"/>）。
  </para>
<!-- pgdoc-cn_end sig_en=e398a62c358dd9af961944f751cc0e58 -->


  <sect2 id="textsearch-document">
<!-- pgdoc-cn_start sig_en=4884a6c08c01b7df42426d1e1693ab37 sig_cn_org=None source=14.1 
   <title>What Is a Document?</title>
________________________________________________________-->
   <title>什么是一个文档？</title>
<!-- pgdoc-cn_end sig_en=4884a6c08c01b7df42426d1e1693ab37 -->

<!-- pgdoc-cn_start sig_en=b902ef3b8fbb65fc229300b2e7e23e16 sig_cn_org=None source=14.1 
   <indexterm zone="textsearch-document">
    <primary>document</primary>
    <secondary>text search</secondary>
   </indexterm>
________________________________________________________-->
   <indexterm zone="textsearch-document">
    <primary>文档</primary>
    <secondary>全文搜索</secondary>
   </indexterm>
<!-- pgdoc-cn_end sig_en=b902ef3b8fbb65fc229300b2e7e23e16 -->

<!-- pgdoc-cn_start sig_en=6c041cd6a928bcd26ba36c0d46c94513 sig_cn_org=None source=14.1 
   <para>
    A <firstterm>document</firstterm> is the unit of searching in a full text search
    system; for example, a magazine article or email message.  The text search
    engine must be able to parse documents and store associations of lexemes
    (key words) with their parent document. Later, these associations are
    used to search for documents that contain query words.
   </para>
________________________________________________________-->
   <para>
    一个<firstterm>document</firstterm>是在一个全文搜索系统中进行搜索的单元，例如，一篇杂志文章或电子邮件消息。文本搜索引擎必须能够解析文档并存储词位（关键词）与它们的父文档之间的关联。随后，这些关联会被用来搜索包含查询词的文档。
   </para>
<!-- pgdoc-cn_end sig_en=6c041cd6a928bcd26ba36c0d46c94513 -->

<!-- pgdoc-cn_start sig_en=32cc2d199632699a2560e324d2e9e187 sig_cn_org=None source=14.1 
   <para>
    For searches within <productname>PostgreSQL</productname>,
    a document is normally a textual field within a row of a database table,
    or possibly a combination (concatenation) of such fields, perhaps stored
    in several tables or obtained dynamically. In other words, a document can
    be constructed from different parts for indexing and it might not be
    stored anywhere as a whole. For example:

<programlisting>
SELECT title || ' ' ||  author || ' ' ||  abstract || ' ' || body AS document
FROM messages
WHERE mid = 12;

SELECT m.title || ' ' || m.author || ' ' || m.abstract || ' ' || d.body AS document
FROM messages m, docs d
WHERE m.mid = d.did AND m.mid = 12;
</programlisting>
   </para>
________________________________________________________-->
   <para>
    对于<productname>PostgreSQL</productname>中的搜索，一个文档通常是一个数据库表中一行内的一个文本形式的域，或者可能是这类域的一个组合（连接），这些域可能存储在多个表或者是动态获取。换句话说，一个文档可能从用于索引的不同部分构建，并且它可能被作为一个整体存储在某个地方。例如：

<programlisting>
SELECT title || ' ' ||  author || ' ' ||  abstract || ' ' || body AS document
FROM messages
WHERE mid = 12;

SELECT m.title || ' ' || m.author || ' ' || m.abstract || ' ' || d.body AS document
FROM messages m, docs d
WHERE m.mid = d.did AND m.mid = 12;
</programlisting>
   </para>
<!-- pgdoc-cn_end sig_en=32cc2d199632699a2560e324d2e9e187 -->

   <note>
<!-- pgdoc-cn_start sig_en=aa81de969a78806540bc93bf024653b7 sig_cn_org=None source=14.1 
    <para>
     Actually, in these example queries, <function>coalesce</function>
     should be used to prevent a single <literal>NULL</literal> attribute from
     causing a <literal>NULL</literal> result for the whole document.
    </para>
________________________________________________________-->
    <para>
     实际上在这些例子查询中，<function>coalesce</function>应该被用来防止一个单一<literal>NULL</literal>属性导致整个文档的一个<literal>NULL</literal>结果。
    </para>
<!-- pgdoc-cn_end sig_en=aa81de969a78806540bc93bf024653b7 -->
   </note>

<!-- pgdoc-cn_start sig_en=d36ef09d8df6e05331cb1401dba3c32f sig_cn_org=None source=14.1 
   <para>
    Another possibility is to store the documents as simple text files in the
    file system. In this case, the database can be used to store the full text
    index and to execute searches, and some unique identifier can be used to
    retrieve the document from the file system.  However, retrieving files
    from outside the database requires superuser permissions or special
    function support, so this is usually less convenient than keeping all
    the data inside <productname>PostgreSQL</productname>.  Also, keeping
    everything inside the database allows easy access
    to document metadata to assist in indexing and display.
   </para>
________________________________________________________-->
   <para>
    另一种存储文档的可能性是作为文件系统中的简单文本文件。在这种情况下，数据库可以被用来存储全文索引并执行搜索，并且某些唯一标识符可以被用来从文件系统检索文档。但是，从数据库的外面检索文件要求超级用户权限或者特殊函数支持，因此这种方法通常不如把所有数据放在<productname>PostgreSQL</productname>内部方便。另外，把所有东西放在数据库内部允许方便地访问文档元数据来协助索引和现实。
   </para>
<!-- pgdoc-cn_end sig_en=d36ef09d8df6e05331cb1401dba3c32f -->

<!-- pgdoc-cn_start sig_en=08cb541845134567a795662d03c38d9e sig_cn_org=None source=14.1 
   <para>
    For text search purposes, each document must be reduced to the
    preprocessed <type>tsvector</type> format.  Searching and ranking
    are performed entirely on the <type>tsvector</type> representation
    of a document &mdash; the original text need only be retrieved
    when the document has been selected for display to a user.
    We therefore often speak of the <type>tsvector</type> as being the
    document, but of course it is only a compact representation of
    the full document.
   </para>
________________________________________________________-->
   <para>
    对于文本搜索目的，每一个文档必须被缩减成预处理后的<type>tsvector</type>格式。搜索和排名被整个在一个文档的<type>tsvector</type>表示上执行 &mdash; 只有当文档被选择来显示给用户时才需要检索原始文本。我们因此经常把<type>tsvector</type>说成是文档，但是当然它只是完整文档的一种紧凑表示。
   </para>
<!-- pgdoc-cn_end sig_en=08cb541845134567a795662d03c38d9e -->
  </sect2>

  <sect2 id="textsearch-matching">
<!-- pgdoc-cn_start sig_en=818a3610b9b59480c6e3ce68ad4da6b5 sig_cn_org=None source=14.1 
   <title>Basic Text Matching</title>
________________________________________________________-->
   <title>基本文本匹配</title>
<!-- pgdoc-cn_end sig_en=818a3610b9b59480c6e3ce68ad4da6b5 -->

<!-- pgdoc-cn_start sig_en=3e7135cd908245ecd6ada84c4c964837 sig_cn_org=None source=14.1 
   <para>
    Full text searching in <productname>PostgreSQL</productname> is based on
    the match operator <literal>@@</literal>, which returns
    <literal>true</literal> if a <type>tsvector</type>
    (document) matches a <type>tsquery</type> (query).
    It doesn't matter which data type is written first:

<programlisting>
SELECT 'a fat cat sat on a mat and ate a fat rat'::tsvector @@ 'cat &amp; rat'::tsquery;
 ?column?
-&minus;-&minus;-&minus;-&minus;-&minus;
 t

SELECT 'fat &amp; cow'::tsquery @@ 'a fat cat sat on a mat and ate a fat rat'::tsvector;
 ?column?
-&minus;-&minus;-&minus;-&minus;-&minus;
 f
</programlisting>
   </para>
________________________________________________________-->
   <para>
    <productname>PostgreSQL</productname>中的全文搜索基于匹配操作符<literal>@@</literal>，它在一个<type>tsvector</type>（文档）匹配一个<type>tsquery</type>（查询）时返回<literal>true</literal>。哪种数据类型写在前面没有影响：

<programlisting>
SELECT 'a fat cat sat on a mat and ate a fat rat'::tsvector @@ 'cat &amp; rat'::tsquery;
 ?column?
----------
 t

SELECT 'fat &amp; cow'::tsquery @@ 'a fat cat sat on a mat and ate a fat rat'::tsvector;
 ?column?
----------
 f
</programlisting>
   </para>
<!-- pgdoc-cn_end sig_en=3e7135cd908245ecd6ada84c4c964837 -->

<!-- pgdoc-cn_start sig_en=d7a1d16ec581357d25069a9228d7c4b5 sig_cn_org=106e1d58aa3c5134aa85d97ae2ccf77e source=15.7 
   <para>
    As the above example suggests, a <type>tsquery</type> is not just raw
    text, any more than a <type>tsvector</type> is.  A <type>tsquery</type>
    contains search terms, which must be already-normalized lexemes, and
    may combine multiple terms using AND, OR, NOT, and FOLLOWED BY operators.
    (For syntax details see <xref linkend="datatype-tsquery"/>.)  There are
    functions <function>to_tsquery</function>, <function>plainto_tsquery</function>,
    and <function>phraseto_tsquery</function>
    that are helpful in converting user-written text into a proper
    <type>tsquery</type>, primarily by normalizing words appearing in
    the text.  Similarly, <function>to_tsvector</function> is used to parse and
    normalize a document string.  So in practice a text search match would
    look more like this:

<programlisting>
SELECT to_tsvector('fat cats ate fat rats') @@ to_tsquery('fat &amp; rat');
 ?column?
-&minus;-&minus;-&minus;-&minus;-&minus;
 t
</programlisting>

    Observe that this match would not succeed if written as

<programlisting>
SELECT 'fat cats ate fat rats'::tsvector @@ to_tsquery('fat &amp; rat');
 ?column?
-&minus;-&minus;-&minus;-&minus;-&minus;
 f
</programlisting>

    since here no normalization of the word <literal>rats</literal> will occur.
    The elements of a <type>tsvector</type> are lexemes, which are assumed
    already normalized, so <literal>rats</literal> does not match <literal>rat</literal>.
   </para>
________________________________________________________-->
   <para>
    如上面的示例所示，<type>tsquery</type>不仅仅是原始文本，就像<type>tsvector</type>一样。
    一个<type>tsquery</type>包含搜索项，这些项必须是已经标准化的词元，并且可以使用AND、OR、NOT和FOLLOWED BY操作符组合多个项。
    （有关语法详细信息，请参见<xref linkend="datatype-tsquery"/>。）有一些函数<function>to_tsquery</function>、
    <function>plainto_tsquery</function>和<function>phraseto_tsquery</function>，
    这些函数有助于将用户编写的文本转换为正确的<type>tsquery</type>，主要是通过标准化文本中出现的单词。
    同样，<function>to_tsvector</function>用于解析和标准化文档字符串。因此，在实践中，文本搜索匹配看起来更像这样：

<programlisting>
SELECT to_tsvector('fat cats ate fat rats') @@ to_tsquery('fat &amp; rat');
 ?column?
----------
 t
</programlisting>

    注意，如果写成以下形式，此匹配将不成功：

<programlisting>
SELECT 'fat cats ate fat rats'::tsvector @@ to_tsquery('fat &amp; rat');
 ?column?
----------
 f
</programlisting>

    因为这里不会对单词<literal>rats</literal>进行标准化。一个<type>tsvector</type>的元素是词元，假定已经标准化，
    因此<literal>rats</literal>不匹配<literal>rat</literal>。
   </para>
<!-- pgdoc-cn_end sig_en=d7a1d16ec581357d25069a9228d7c4b5 -->

<!-- pgdoc-cn_start sig_en=27d7e028a8e81a0584b4539c422d5dd5 sig_cn_org=None source=14.1 
   <para>
    The <literal>@@</literal> operator also
    supports <type>text</type> input, allowing explicit conversion of a text
    string to <type>tsvector</type> or <type>tsquery</type> to be skipped
    in simple cases.  The variants available are:

<programlisting>
tsvector @@ tsquery
tsquery  @@ tsvector
text @@ tsquery
text @@ text
</programlisting>
   </para>
________________________________________________________-->
   <para>
    <literal>@@</literal>操作符也支持<type>text</type>输出，它允许在简单情况下跳过从文本字符串到<type>tsvector</type>或<type>tsquery</type>的显式转换。可用的变体是：

<programlisting>
tsvector @@ tsquery
tsquery  @@ tsvector
text @@ tsquery
text @@ text
</programlisting>
   </para>
<!-- pgdoc-cn_end sig_en=27d7e028a8e81a0584b4539c422d5dd5 -->

<!-- pgdoc-cn_start sig_en=739bf8fbfc93c1a2927f7dd1248640dc sig_cn_org=None source=14.1 
   <para>
    The first two of these we saw already.
    The form <type>text</type> <literal>@@</literal> <type>tsquery</type>
    is equivalent to <literal>to_tsvector(x) @@ y</literal>.
    The form <type>text</type> <literal>@@</literal> <type>text</type>
    is equivalent to <literal>to_tsvector(x) @@ plainto_tsquery(y)</literal>.
   </para>
________________________________________________________-->
   <para>
    前两种我们已经见过。形式<type>text</type> <literal>@@</literal> <type>tsquery</type>等价于<literal>to_tsvector(x) @@ y</literal>。形式<type>text</type> <literal>@@</literal> <type>text</type>等价于<literal>to_tsvector(x) @@ plainto_tsquery(y)</literal>。
   </para>
<!-- pgdoc-cn_end sig_en=739bf8fbfc93c1a2927f7dd1248640dc -->

<!-- pgdoc-cn_start sig_en=a1cc2ebd65262e4d78507cf3043188e9 sig_cn_org=None source=14.1 
   <para>
    Within a <type>tsquery</type>, the <literal>&amp;</literal> (AND) operator
    specifies that both its arguments must appear in the document to have a
    match.  Similarly, the <literal>|</literal> (OR) operator specifies that
    at least one of its arguments must appear, while the <literal>!</literal> (NOT)
    operator specifies that its argument must <emphasis>not</emphasis> appear in
    order to have a match.
    For example, the query <literal>fat &amp; ! rat</literal> matches documents that
    contain <literal>fat</literal> but not <literal>rat</literal>.
   </para>
________________________________________________________-->
   <para>
    在<type>tsquery</type>中，<literal>&amp;</literal>（AND）操作符指定它的两个参数都必须出现在文档中才表示匹配。类似地，<literal>|</literal>（OR）操作符指定至少一个参数必须出现，而<literal>!</literal>（NOT）操作符指定它的参数<emphasis>不</emphasis>出现才能匹配。例如，查询<literal>fat &amp; ! rat</literal>匹配包含<literal>fat</literal>但不包含<literal>rat</literal>的文档。
   </para>
<!-- pgdoc-cn_end sig_en=a1cc2ebd65262e4d78507cf3043188e9 -->

<!-- pgdoc-cn_start sig_en=ce6e8cc907f6dc4ed6338f9e54789e1f sig_cn_org=7f06a3b1395017870e8f6585978cecb1 source=15.7 
   <para>
    Searching for phrases is possible with the help of
    the <literal>&lt;-&gt;</literal> (FOLLOWED BY) <type>tsquery</type> operator, which
    matches only if its arguments have matches that are adjacent and in the
    given order.  For example:

<programlisting>
SELECT to_tsvector('fatal error') @@ to_tsquery('fatal &lt;-&gt; error');
 ?column?
-&minus;-&minus;-&minus;-&minus;-&minus;
 t

SELECT to_tsvector('error is not fatal') @@ to_tsquery('fatal &lt;-&gt; error');
 ?column?
-&minus;-&minus;-&minus;-&minus;-&minus;
 f
</programlisting>

    There is a more general version of the FOLLOWED BY operator having the
    form <literal>&lt;<replaceable>N</replaceable>&gt;</literal>,
    where <replaceable>N</replaceable> is an integer standing for the difference between
    the positions of the matching lexemes.  <literal>&lt;1&gt;</literal> is
    the same as <literal>&lt;-&gt;</literal>, while <literal>&lt;2&gt;</literal>
    allows exactly one other lexeme to appear between the matches, and so
    on.  The <literal>phraseto_tsquery</literal> function makes use of this
    operator to construct a <literal>tsquery</literal> that can match a multi-word
    phrase when some of the words are stop words.  For example:

<programlisting>
SELECT phraseto_tsquery('cats ate rats');
       phraseto_tsquery
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 'cat' &lt;-&gt; 'ate' &lt;-&gt; 'rat'

SELECT phraseto_tsquery('the cats ate the rats');
       phraseto_tsquery
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 'cat' &lt;-&gt; 'ate' &lt;2&gt; 'rat'
</programlisting>
   </para>
________________________________________________________-->
   <para>
    通过<literal>&lt;-&gt;</literal>（FOLLOWED BY）<type>tsquery</type>运算符，可以搜索短语，
    仅当其参数具有相邻且按给定顺序匹配时才匹配。例如：

<programlisting>
SELECT to_tsvector('fatal error') @@ to_tsquery('fatal &lt;-&gt; error');
 ?column?
----------
 t

SELECT to_tsvector('error is not fatal') @@ to_tsquery('fatal &lt;-&gt; error');
 ?column?
----------
 f
</programlisting>

    还有一个更一般的FOLLOWED BY运算符版本，形式为<literal>&lt;<replaceable>N</replaceable>&gt;</literal>，
    其中<replaceable>N</replaceable>是一个整数，表示匹配词元位置之间的差异。<literal>&lt;1&gt;</literal>等同于<literal>&lt;-&gt;</literal>，
    而<literal>&lt;2&gt;</literal>允许匹配之间出现一个其他词元，依此类推。<literal>phraseto_tsquery</literal>函数利用此运算符构建一个
    可匹配多词短语的<literal>tsquery</literal>，当其中一些词是停用词时。例如：

<programlisting>
SELECT phraseto_tsquery('cats ate rats');
       phraseto_tsquery
-------------------------------
 'cat' &lt;-&gt; 'ate' &lt;-&gt; 'rat'

SELECT phraseto_tsquery('the cats ate the rats');
       phraseto_tsquery
-------------------------------
 'cat' &lt;-&gt; 'ate' &lt;2&gt; 'rat'
</programlisting>
   </para>
<!-- pgdoc-cn_end sig_en=ce6e8cc907f6dc4ed6338f9e54789e1f -->

<!-- pgdoc-cn_start sig_en=467172ab311bbbf35415f7ce40bdb153 sig_cn_org=None source=14.1 
   <para>
    A special case that's sometimes useful is that <literal>&lt;0&gt;</literal>
    can be used to require that two patterns match the same word.
   </para>
________________________________________________________-->
   <para>
    一种有时候有用的特殊情况是，<literal>&lt;0&gt;</literal>可以被用来要求两个匹配同一个词的模式。
   </para>
<!-- pgdoc-cn_end sig_en=467172ab311bbbf35415f7ce40bdb153 -->

<!-- pgdoc-cn_start sig_en=20e608876cf81da8be49e721364eb961 sig_cn_org=None source=14.1 
   <para>
    Parentheses can be used to control nesting of the <type>tsquery</type>
    operators.  Without parentheses, <literal>|</literal> binds least tightly,
    then <literal>&amp;</literal>, then <literal>&lt;-&gt;</literal>,
    and <literal>!</literal> most tightly.
   </para>
________________________________________________________-->
   <para>
    圆括号可以被用来控制<type>tsquery</type>操作符的嵌套。如果没有圆括号，<literal>|</literal>的计算优先级最低，然后从低到高依次是<literal>&amp;</literal>、<literal>&lt;-&gt;</literal>、<literal>!</literal>。
   </para>
<!-- pgdoc-cn_end sig_en=20e608876cf81da8be49e721364eb961 -->

<!-- pgdoc-cn_start sig_en=42f0f057eb6b131832d56eb1164f0187 sig_cn_org=None source=14.1 
   <para>
    It's worth noticing that the AND/OR/NOT operators mean something subtly
    different when they are within the arguments of a FOLLOWED BY operator
    than when they are not, because within FOLLOWED BY the exact position of
    the match is significant.  For example, normally <literal>!x</literal> matches
    only documents that do not contain <literal>x</literal> anywhere.
    But <literal>!x &lt;-&gt; y</literal> matches <literal>y</literal> if it is not
    immediately after an <literal>x</literal>; an occurrence of <literal>x</literal>
    elsewhere in the document does not prevent a match.  Another example is
    that <literal>x &amp; y</literal> normally only requires that <literal>x</literal>
    and <literal>y</literal> both appear somewhere in the document, but
    <literal>(x &amp; y) &lt;-&gt; z</literal> requires <literal>x</literal>
    and <literal>y</literal> to match at the same place, immediately before
    a <literal>z</literal>.  Thus this query behaves differently from
    <literal>x &lt;-&gt; z &amp; y &lt;-&gt; z</literal>, which will match a
    document containing two separate sequences <literal>x z</literal> and
    <literal>y z</literal>.  (This specific query is useless as written,
    since <literal>x</literal> and <literal>y</literal> could not match at the same place;
    but with more complex situations such as prefix-match patterns, a query
    of this form could be useful.)
   </para>
________________________________________________________-->
   <para>
    值得注意的是，当AND/OR/NOT操作符在一个FOLLOWED BY操作符的参数中时，它们表示与不在那些参数中时不同的含义，因为在FOLLOWED BY中匹配的准确位置是有意义的。例如，通常<literal>!x</literal>仅匹配在任何地方都不包含<literal>x</literal>的文档。但如果<literal>y</literal>不是紧接在一个<literal>x</literal>后面，<literal>!x &lt;-&gt; y</literal>就会匹配那个<literal>y</literal>，在文档中其他位置出现的<literal>x</literal>不会阻止匹配。另一个例子是，<literal>x &amp; y</literal>通常仅要求<literal>x</literal>和<literal>y</literal>均出现在文档中的某处，但是<literal>(x &amp; y) &lt;-&gt; z</literal>要求<literal>x</literal>和<literal>y</literal>在紧挨着<literal>z</literal>之前的同一个位置匹配。因此这个查询的行为会不同于<literal>x &lt;-&gt; z &amp; y &lt;-&gt; z</literal>，它将匹配一个含有两个单独序列<literal>x z</literal>以及<literal>y z</literal>的文档（这个特定的查询一点用都没有，因为<literal>x</literal>和<literal>y</literal>不可能在同一个位置匹配，但是对于前缀匹配模式之类的更复杂的情况，这种形式的查询就会有用武之地）。
   </para>
<!-- pgdoc-cn_end sig_en=42f0f057eb6b131832d56eb1164f0187 -->
  </sect2>

  <sect2 id="textsearch-intro-configurations">
<!-- pgdoc-cn_start sig_en=e6683cb9b4a1efd592e3661c2d3f5eb6 sig_cn_org=None source=14.1 
   <title>Configurations</title>
________________________________________________________-->
   <title>配置</title>
<!-- pgdoc-cn_end sig_en=e6683cb9b4a1efd592e3661c2d3f5eb6 -->

<!-- pgdoc-cn_start sig_en=61f80cec91b2abc91c4c026ec49c7259 sig_cn_org=None source=14.1 
   <para>
    The above are all simple text search examples.  As mentioned before, full
    text search functionality includes the ability to do many more things:
    skip indexing certain words (stop words), process synonyms, and use
    sophisticated parsing, e.g., parse based on more than just white space.
    This functionality is controlled by <firstterm>text search
    configurations</firstterm>.  <productname>PostgreSQL</productname> comes with predefined
    configurations for many languages, and you can easily create your own
    configurations.  (<application>psql</application>'s <command>\dF</command> command
    shows all available configurations.)
   </para>
________________________________________________________-->
   <para>
    前述的都是简单的文本搜索例子。正如前面所提到的，全文搜索功能包括做更多事情的能力：跳过索引特定词（停用词）、处理同义词并使用更高级的解析，例如基于空白之外的解析。这个功能由<firstterm>文本搜索配置</firstterm>控制。<productname>PostgreSQL</productname>中有多种语言的预定义配置，并且你可以很容易地创建你自己的配置（<application>psql</application>的<command>\dF</command>命令显示所有可用的配置）。
   </para>
<!-- pgdoc-cn_end sig_en=61f80cec91b2abc91c4c026ec49c7259 -->

<!-- pgdoc-cn_start sig_en=af4394415114f11f3d2ab479aa1585b2 sig_cn_org=None source=14.1 
   <para>
    During installation an appropriate configuration is selected and
    <xref linkend="guc-default-text-search-config"/> is set accordingly
    in <filename>postgresql.conf</filename>.  If you are using the same text search
    configuration for the entire cluster you can use the value in
    <filename>postgresql.conf</filename>.  To use different configurations
    throughout the cluster but the same configuration within any one database,
    use <command>ALTER DATABASE ... SET</command>.  Otherwise, you can set
    <varname>default_text_search_config</varname> in each session.
   </para>
________________________________________________________-->
   <para>
    在安装期间一个合适的配置将被选择并且<xref linkend="guc-default-text-search-config"/>也被相应地设置在<filename>postgresql.conf</filename>中。如果你正在对整个集簇使用相同的文本搜索配置，你可以使用在<filename>postgresql.conf</filename>中使用该值。要在集簇中使用不同的配置但是在任何一个数据库内部使用同一种配置，使用<command>ALTER DATABASE ... SET</command>。否则，你可以在每个会话中设置<varname>default_text_search_config</varname>。
   </para>
<!-- pgdoc-cn_end sig_en=af4394415114f11f3d2ab479aa1585b2 -->

<!-- pgdoc-cn_start sig_en=8dd6f0d034bb727df29590e9faaafe1c sig_cn_org=None source=14.1 
   <para>
    Each text search function that depends on a configuration has an optional
    <type>regconfig</type> argument, so that the configuration to use can be
    specified explicitly.  <varname>default_text_search_config</varname>
    is used only when this argument is omitted.
   </para>
________________________________________________________-->
   <para>
    依赖一个配置的每一个文本搜索函数都有一个可选的<type>regconfig</type>参数，因此要使用的配置可以被显式指定。只有当这个参数被忽略时，<varname>default_text_search_config</varname>才被使用。
   </para>
<!-- pgdoc-cn_end sig_en=8dd6f0d034bb727df29590e9faaafe1c -->

<!-- pgdoc-cn_start sig_en=860c5afd12e536626309d269da21a7d8 sig_cn_org=None source=14.1 
   <para>
    To make it easier to build custom text search configurations, a
    configuration is built up from simpler database objects.
    <productname>PostgreSQL</productname>'s text search facility provides
    four types of configuration-related database objects:
   </para>
________________________________________________________-->
   <para>
    为了让建立自定义文本搜索配置更容易，一个配置可以从更简单的数据库对象来建立。<productname>PostgreSQL</productname>的文本搜索功能提供了四类配置相关的数据库对象：
   </para>
<!-- pgdoc-cn_end sig_en=860c5afd12e536626309d269da21a7d8 -->

  <itemizedlist  spacing="compact" mark="bullet">
   <listitem>
<!-- pgdoc-cn_start sig_en=99e2c23a282cea8b39cd4cbac0b7b2c8 sig_cn_org=None source=14.1 
    <para>
     <firstterm>Text search parsers</firstterm> break documents into tokens
     and classify each token (for example, as words or numbers).
    </para>
________________________________________________________-->
    <para>
     <firstterm>文本搜索解析器</firstterm>将文档拆分成记号并分类每个记号（例如，作为词或者数字）。
    </para>
<!-- pgdoc-cn_end sig_en=99e2c23a282cea8b39cd4cbac0b7b2c8 -->
   </listitem>

   <listitem>
<!-- pgdoc-cn_start sig_en=09505e5b6259eff10b4a0db5fa2deba3 sig_cn_org=None source=14.1 
    <para>
     <firstterm>Text search dictionaries</firstterm> convert tokens to normalized
     form and reject stop words.
    </para>
________________________________________________________-->
    <para>
     <firstterm>文本搜索词典</firstterm>将记号转变成正规化的形式并拒绝停用词。
    </para>
<!-- pgdoc-cn_end sig_en=09505e5b6259eff10b4a0db5fa2deba3 -->
   </listitem>

   <listitem>
<!-- pgdoc-cn_start sig_en=d4c3ce9823cb08d81df70d9aed4a0781 sig_cn_org=None source=14.1 
    <para>
     <firstterm>Text search templates</firstterm> provide the functions underlying
     dictionaries.  (A dictionary simply specifies a template and a set
     of parameters for the template.)
    </para>
________________________________________________________-->
    <para>
     <firstterm>文本搜索模板</firstterm>提供位于词典底层的函数（一个词典简单地指定一个模板和一组用于模板的参数）。
    </para>
<!-- pgdoc-cn_end sig_en=d4c3ce9823cb08d81df70d9aed4a0781 -->
   </listitem>

   <listitem>
<!-- pgdoc-cn_start sig_en=9b58b4470511c73bdcc8fb73af24f19c sig_cn_org=None source=14.1 
    <para>
     <firstterm>Text search configurations</firstterm> select a parser and a set
     of dictionaries to use to normalize the tokens produced by the parser.
    </para>
________________________________________________________-->
    <para>
     <firstterm>文本搜索配置</firstterm>选择一个解析器和一组用于将解析器产生的记号正规化的词典。
    </para>
<!-- pgdoc-cn_end sig_en=9b58b4470511c73bdcc8fb73af24f19c -->
   </listitem>
  </itemizedlist>

<!-- pgdoc-cn_start sig_en=9d2e9c14649490256fe1a9e3a297e3ae sig_cn_org=None source=14.1 
   <para>
    Text search parsers and templates are built from low-level C functions;
    therefore it requires C programming ability to develop new ones, and
    superuser privileges to install one into a database.  (There are examples
    of add-on parsers and templates in the <filename>contrib/</filename> area of the
    <productname>PostgreSQL</productname> distribution.)  Since dictionaries and
    configurations just parameterize and connect together some underlying
    parsers and templates, no special privilege is needed to create a new
    dictionary or configuration.  Examples of creating custom dictionaries and
    configurations appear later in this chapter.
   </para>
________________________________________________________-->
   <para>
    文本搜索解析器和模板是从低层 C 函数构建而来，因此它要求 C 编程能力来开发新的解析器和模板，并且还需要超级用户权限来把它们安装到一个数据库中（在<productname>PostgreSQL</productname>发布的<filename>contrib/</filename>区域中有一些附加的解析器和模板的例子）。由于词典和配置只是对底层解析器和模板的参数化和连接，不需要特殊的权限来创建一个新词典或配置。创建定制词典和配置的例子将在本章稍后的部分给出。
   </para>
<!-- pgdoc-cn_end sig_en=9d2e9c14649490256fe1a9e3a297e3ae -->

  </sect2>

 </sect1>

 <sect1 id="textsearch-tables">
<!-- pgdoc-cn_start sig_en=a2042b395e1a6b47eef5bdf0e9df1b4b sig_cn_org=None source=14.1 
  <title>Tables and Indexes</title>
________________________________________________________-->
  <title>表和索引</title>
<!-- pgdoc-cn_end sig_en=a2042b395e1a6b47eef5bdf0e9df1b4b -->

<!-- pgdoc-cn_start sig_en=050fa397de1bda83f93e5386425be44f sig_cn_org=None source=14.1 
  <para>
   The examples in the previous section illustrated full text matching using
   simple constant strings.  This section shows how to search table data,
   optionally using indexes.
  </para>
________________________________________________________-->
  <para>
   在前一节中的例子演示了使用简单常数字符串进行全文匹配。本节展示如何搜索表数据，以及可选择地使用索引。
  </para>
<!-- pgdoc-cn_end sig_en=050fa397de1bda83f93e5386425be44f -->

  <sect2 id="textsearch-tables-search">
<!-- pgdoc-cn_start sig_en=40d7bbb5a229c82db021cb3bddd9c8d8 sig_cn_org=None source=14.1 
   <title>Searching a Table</title>
________________________________________________________-->
   <title>搜索一个表</title>
<!-- pgdoc-cn_end sig_en=40d7bbb5a229c82db021cb3bddd9c8d8 -->

<!-- pgdoc-cn_start sig_en=8243ac1b2f0a0ec0fcbee500079d8063 sig_cn_org=None source=14.1 
   <para>
    It is possible to do a full text search without an index.  A simple query
    to print the <structname>title</structname> of each row that contains the word
    <literal>friend</literal> in its <structfield>body</structfield> field is:

<programlisting>
SELECT title
FROM pgweb
WHERE to_tsvector('english', body) @@ to_tsquery('english', 'friend');
</programlisting>

    This will also find related words such as <literal>friends</literal>
    and <literal>friendly</literal>, since all these are reduced to the same
    normalized lexeme.
   </para>
________________________________________________________-->
   <para>
    可以在没有一个索引的情况下做一次全文搜索。一个简单的查询将打印每一个行的<structname>title</structname>，这些行在其<structfield>body</structfield>域中包含词<literal>friend</literal>：

<programlisting>
SELECT title
FROM pgweb
WHERE to_tsvector('english', body) @@ to_tsquery('english', 'friend');
</programlisting>

    这将还会找到相关的词例如<literal>friends</literal>和<literal>friendly</literal>，因为这些都被约减到同一个正规化的词位。
   </para>
<!-- pgdoc-cn_end sig_en=8243ac1b2f0a0ec0fcbee500079d8063 -->

<!-- pgdoc-cn_start sig_en=b2122a57aeb03ba2b5eff3cd139cb5b8 sig_cn_org=None source=14.1 
   <para>
    The query above specifies that the <literal>english</literal> configuration
    is to be used to parse and normalize the strings.  Alternatively we
    could omit the configuration parameters:

<programlisting>
SELECT title
FROM pgweb
WHERE to_tsvector(body) @@ to_tsquery('friend');
</programlisting>

    This query will use the configuration set by <xref
    linkend="guc-default-text-search-config"/>.
   </para>
________________________________________________________-->
   <para>
    以上的查询指定要使用<literal>english</literal>配置来解析和正规化字符串。我们也可以忽略配置参数：

<programlisting>
SELECT title
FROM pgweb
WHERE to_tsvector(body) @@ to_tsquery('friend');
</programlisting>

    这个查询将使用由<xref linkend="guc-default-text-search-config"/>设置的配置。
   </para>
<!-- pgdoc-cn_end sig_en=b2122a57aeb03ba2b5eff3cd139cb5b8 -->

<!-- pgdoc-cn_start sig_en=4cbe122c178adcc1279b585e54f4714d sig_cn_org=None source=14.1 
   <para>
    A more complex example is to
    select the ten most recent documents that contain <literal>create</literal> and
    <literal>table</literal> in the <structname>title</structname> or <structname>body</structname>:

<programlisting>
SELECT title
FROM pgweb
WHERE to_tsvector(title || ' ' || body) @@ to_tsquery('create &amp; table')
ORDER BY last_mod_date DESC
LIMIT 10;
</programlisting>

    For clarity we omitted the <function>coalesce</function> function calls
    which would be needed to find rows that contain <literal>NULL</literal>
    in one of the two fields.
   </para>
________________________________________________________-->
   <para>
    一个更复杂的例子是选择 10 个最近的文档，要求它们在<structname>title</structname>或<structname>body</structname>中包含<literal>create</literal>和<literal>table</literal>：

<programlisting>
SELECT title
FROM pgweb
WHERE to_tsvector(title || ' ' || body) @@ to_tsquery('create &amp; table')
ORDER BY last_mod_date DESC
LIMIT 10;
</programlisting>

    为了清晰，我们忽略<function>coalesce</function>函数调用，它可能需要被用来查找在这两个域之中包含<literal>NULL</literal>的行。
   </para>
<!-- pgdoc-cn_end sig_en=4cbe122c178adcc1279b585e54f4714d -->

<!-- pgdoc-cn_start sig_en=1e1adda4dd1671ffaca527d1ce2996e2 sig_cn_org=None source=14.1 
   <para>
    Although these queries will work without an index, most applications
    will find this approach too slow, except perhaps for occasional ad-hoc
    searches.  Practical use of text searching usually requires creating
    an index.
   </para>
________________________________________________________-->
   <para>
    尽管这些查询可以在没有索引的情况下工作，大部分应用会发现这种方法太慢了，除了偶尔的临时搜索。实际使用文本搜索通常要求创建一个索引。
   </para>
<!-- pgdoc-cn_end sig_en=1e1adda4dd1671ffaca527d1ce2996e2 -->

  </sect2>

  <sect2 id="textsearch-tables-index">
<!-- pgdoc-cn_start sig_en=bfc2ab68708cc2be44921212db7befc3 sig_cn_org=None source=14.1 
   <title>Creating Indexes</title>
________________________________________________________-->
   <title>创建索引</title>
<!-- pgdoc-cn_end sig_en=bfc2ab68708cc2be44921212db7befc3 -->

<!-- pgdoc-cn_start sig_en=e0d62f35d0a5a8527c514bc93ea7cb7f sig_cn_org=None source=14.1 
   <para>
    We can create a <acronym>GIN</acronym> index (<xref
    linkend="textsearch-indexes"/>) to speed up text searches:

<programlisting>
CREATE INDEX pgweb_idx ON pgweb USING GIN (to_tsvector('english', body));
</programlisting>

    Notice that the 2-argument version of <function>to_tsvector</function> is
    used.  Only text search functions that specify a configuration name can
    be used in expression indexes (<xref linkend="indexes-expressional"/>).
    This is because the index contents must be unaffected by <xref
    linkend="guc-default-text-search-config"/>.  If they were affected, the
    index contents might be inconsistent because different entries could
    contain <type>tsvector</type>s that were created with different text search
    configurations, and there would be no way to guess which was which.  It
    would be impossible to dump and restore such an index correctly.
   </para>
________________________________________________________-->
   <para>
    我们可以创建一个<acronym>GIN</acronym>索引（<xref linkend="textsearch-indexes"/>）来加速文本搜索：

<programlisting>
CREATE INDEX pgweb_idx ON pgweb USING GIN(to_tsvector('english', body));
</programlisting>

    注意这里使用了<function>to_tsvector</function>的双参数版本。只有指定了一个配置名称的文本搜索函数可以被用在表达式索引（<xref linkend="indexes-expressional"/>）中。这是因为索引内容必须是没有被<xref linkend="guc-default-text-search-config"/>影响的。如果它们被影响，索引内容可能会不一致因为不同的项可能包含被使用不同文本搜索配置创建的<type>tsvector</type>，并且没有办法猜测哪个是哪个。也没有可能正确地转储和恢复这样的一个索引。
   </para>
<!-- pgdoc-cn_end sig_en=e0d62f35d0a5a8527c514bc93ea7cb7f -->

<!-- pgdoc-cn_start sig_en=4255a4527165b2a9fceb580d6da8bcdb sig_cn_org=None source=14.1 
   <para>
    Because the two-argument version of <function>to_tsvector</function> was
    used in the index above, only a query reference that uses the 2-argument
    version of <function>to_tsvector</function> with the same configuration
    name will use that index.  That is, <literal>WHERE
    to_tsvector('english', body) @@ 'a &amp; b'</literal> can use the index,
    but <literal>WHERE to_tsvector(body) @@ 'a &amp; b'</literal> cannot.
    This ensures that an index will be used only with the same configuration
    used to create the index entries.
   </para>
________________________________________________________-->
   <para>
    由于<function>to_tsvector</function>的双参数版本被使用在上述的索引中，只有一个使用了带有相同配置名的双参数版<function>to_tsvector</function>的查询引用才能使用该索引。即，<literal>WHERE to_tsvector('english', body) @@ 'a &amp; b'</literal> 可以使用该索引，但<literal>WHERE to_tsvector(body) @@ 'a &amp; b'</literal>不能。这保证一个索引只能和创建索引项时所用的相同配置一起使用。
   </para>
<!-- pgdoc-cn_end sig_en=4255a4527165b2a9fceb580d6da8bcdb -->

<!-- pgdoc-cn_start sig_en=33f20f46cbb746f43f616f58c13d6be7 sig_cn_org=None source=14.1 
  <para>
    It is possible to set up more complex expression indexes wherein the
    configuration name is specified by another column, e.g.:

<programlisting>
CREATE INDEX pgweb_idx ON pgweb USING GIN (to_tsvector(config_name, body));
</programlisting>

    where <literal>config_name</literal> is a column in the <literal>pgweb</literal>
    table.  This allows mixed configurations in the same index while
    recording which configuration was used for each index entry.  This
    would be useful, for example, if the document collection contained
    documents in different languages.  Again,
    queries that are meant to use the index must be phrased to match, e.g.,
    <literal>WHERE to_tsvector(config_name, body) @@ 'a &amp; b'</literal>.
   </para>
________________________________________________________-->
  <para>
    可以建立更复杂的表达式索引，在其中配置名被另一个列指定，例如：

<programlisting>
CREATE INDEX pgweb_idx ON pgweb USING GIN(to_tsvector(config_name, body));
</programlisting>

    这里<literal>config_name</literal>是<literal>pgweb</literal>表中的一个列。这允许在同一个索引中有混合配置，同时记录哪个配置被用于每一个索引项。例如，如果文档集合包含不同语言的文档，这就可能会有用。同样，要使用索引的查询必须被措辞成匹配，例如<literal>WHERE to_tsvector(config_name, body) @@ 'a &amp; b'</literal>。
   </para>
<!-- pgdoc-cn_end sig_en=33f20f46cbb746f43f616f58c13d6be7 -->

<!-- pgdoc-cn_start sig_en=1fa9e3bc9e2c67097be2205ee1fbf483 sig_cn_org=None source=14.1 
   <para>
    Indexes can even concatenate columns:

<programlisting>
CREATE INDEX pgweb_idx ON pgweb USING GIN (to_tsvector('english', title || ' ' || body));
</programlisting>
   </para>
________________________________________________________-->
   <para>
    索引甚至可以连接列：

<programlisting>
CREATE INDEX pgweb_idx ON pgweb USING GIN(to_tsvector('english', title || ' ' || body));
</programlisting>
   </para>
<!-- pgdoc-cn_end sig_en=1fa9e3bc9e2c67097be2205ee1fbf483 -->

<!-- pgdoc-cn_start sig_en=8c94988da27cd3ae4d3807fe982057b6 sig_cn_org=None source=14.1 
   <para>
    Another approach is to create a separate <type>tsvector</type> column
    to hold the output of <function>to_tsvector</function>.  To keep this
    column automatically up to date with its source data, use a stored
    generated column.  This example is a
    concatenation of <literal>title</literal> and <literal>body</literal>,
    using <function>coalesce</function> to ensure that one field will still be
    indexed when the other is <literal>NULL</literal>:

<programlisting>
ALTER TABLE pgweb
    ADD COLUMN textsearchable_index_col tsvector
               GENERATED ALWAYS AS (to_tsvector('english', coalesce(title, '') || ' ' || coalesce(body, ''))) STORED;
</programlisting>

    Then we create a <acronym>GIN</acronym> index to speed up the search:

<programlisting>
CREATE INDEX textsearch_idx ON pgweb USING GIN (textsearchable_index_col);
</programlisting>

    Now we are ready to perform a fast full text search:

<programlisting>
SELECT title
FROM pgweb
WHERE textsearchable_index_col @@ to_tsquery('create &amp; table')
ORDER BY last_mod_date DESC
LIMIT 10;
</programlisting>
   </para>
________________________________________________________-->
   <para>
    另一种方法是创建一个单独的<type>tsvector</type>列来保存<function>to_tsvector</function>的输出。若要使此列与其源数据保持自动更新，用存储生成的列。这个例子是<literal>title</literal>和<literal>body</literal>的连接，使用<function>coalesce</function>来保证当其他域为<literal>NULL</literal>时一个域仍然能留在索引中：

<programlisting>
ALTER TABLE pgweb
    ADD COLUMN textsearchable_index_col tsvector
               GENERATED ALWAYS AS (to_tsvector('english', coalesce(title, '') || ' ' || coalesce(body, ''))) STORED;
</programlisting>

    然后我们创建一个<acronym>GIN</acronym>索引来加速搜索：

<programlisting>
CREATE INDEX textsearch_idx ON pgweb USING GIN(textsearchable_index_col);
</programlisting>

    现在我们准备好执行一个快速的全文搜索了：

<programlisting>
SELECT title
FROM pgweb
WHERE textsearchable_index_col @@ to_tsquery('create &amp; table')
ORDER BY last_mod_date DESC
LIMIT 10;
</programlisting>
   </para>
<!-- pgdoc-cn_end sig_en=8c94988da27cd3ae4d3807fe982057b6 -->

<!-- pgdoc-cn_start sig_en=ffff65c9ca964c7bb5d928cd26b7dcd3 sig_cn_org=None source=14.1 
   <para>
    One advantage of the separate-column approach over an expression index
    is that it is not necessary to explicitly specify the text search
    configuration in queries in order to make use of the index.  As shown
    in the example above, the query can depend on
    <varname>default_text_search_config</varname>.  Another advantage is that
    searches will be faster, since it will not be necessary to redo the
    <function>to_tsvector</function> calls to verify index matches.  (This is more
    important when using a GiST index than a GIN index; see <xref
    linkend="textsearch-indexes"/>.)  The expression-index approach is
    simpler to set up, however, and it requires less disk space since the
    <type>tsvector</type> representation is not stored explicitly.
   </para>
________________________________________________________-->
   <para>
    单独列方法相对于表达式索引的一个优势在于，它不必为了利用索引而在查询中显式地指定文本搜索配置。如上述例子所示，查询可以依赖<varname>default_text_search_config</varname>。另一个优势是搜索将会更快，因为它不必重做<function>to_tsvector</function>调用来验证索引匹配（在使用 GiST 索引时这一点比使用 GIN 索引时更重要；见<xref linkend="textsearch-indexes"/>）。表达式索引方法更容易建立，但是它要求更少的磁盘空间，因为<type>tsvector</type>表示没有被显式地存储下来。
   </para>
<!-- pgdoc-cn_end sig_en=ffff65c9ca964c7bb5d928cd26b7dcd3 -->

  </sect2>

 </sect1>

 <sect1 id="textsearch-controls">
<!-- pgdoc-cn_start sig_en=4db5da94ef6314ad004703952e702b23 sig_cn_org=None source=14.1 
  <title>Controlling Text Search</title>
________________________________________________________-->
  <title>控制文本搜索</title>
<!-- pgdoc-cn_end sig_en=4db5da94ef6314ad004703952e702b23 -->

<!-- pgdoc-cn_start sig_en=6b0edcf6dd5af2755a39994e50ea0091 sig_cn_org=None source=14.1 
  <para>
   To implement full text searching there must be a function to create a
   <type>tsvector</type> from a document and a <type>tsquery</type> from a
   user query. Also, we need to return results in a useful order, so we need
   a function that compares documents with respect to their relevance to
   the query. It's also important to be able to display the results nicely.
   <productname>PostgreSQL</productname> provides support for all of these
   functions.
  </para>
________________________________________________________-->
  <para>
   要实现全文搜索必须要有一个从文档创建<type>tsvector</type>以及从用户查询创建<type>tsquery</type>的函数。而且我们需要一种有用的顺序返回结果，因此我们需要一个函数能够根据文档与查询的相关性比较文档。还有一点重要的是要能够很好地显示结果。<productname>PostgreSQL</productname>对所有这些函数都提供了支持。
  </para>
<!-- pgdoc-cn_end sig_en=6b0edcf6dd5af2755a39994e50ea0091 -->

  <sect2 id="textsearch-parsing-documents">
<!-- pgdoc-cn_start sig_en=b85de404f4eb133c5950dc9ae7b4ba35 sig_cn_org=None source=14.1 
   <title>Parsing Documents</title>
________________________________________________________-->
   <title>解析文档</title>
<!-- pgdoc-cn_end sig_en=b85de404f4eb133c5950dc9ae7b4ba35 -->

<!-- pgdoc-cn_start sig_en=aba5eed76d2dd9a0523f4c533db00d5a sig_cn_org=None source=14.1 
   <para>
    <productname>PostgreSQL</productname> provides the
    function <function>to_tsvector</function> for converting a document to
    the <type>tsvector</type> data type.
   </para>
________________________________________________________-->
   <para>
    <productname>PostgreSQL</productname>提供了函数<function>to_tsvector</function>将一个文档转换成<type>tsvector</type>数据类型。
   </para>
<!-- pgdoc-cn_end sig_en=aba5eed76d2dd9a0523f4c533db00d5a -->

<!-- pgdoc-cn_start sig_en=c8c60c26008501d27f5a3510f83f4072 sig_cn_org=None source=14.1 
   <indexterm>
    <primary>to_tsvector</primary>
   </indexterm>
________________________________________________________-->
   <indexterm>
    <primary>to_tsvector</primary>
   </indexterm>
<!-- pgdoc-cn_end sig_en=c8c60c26008501d27f5a3510f83f4072 -->

<!-- pgdoc-cn_start sig_en=a890724e80695677bd5defa42be18b7e sig_cn_org=None source=14.1 
<synopsis>
to_tsvector(<optional> <replaceable class="parameter">config</replaceable> <type>regconfig</type>, </optional> <replaceable class="parameter">document</replaceable> <type>text</type>) returns <type>tsvector</type>
</synopsis>
________________________________________________________-->
<synopsis>
to_tsvector(<optional> <replaceable class="parameter">config</replaceable> <type>regconfig</type>, </optional> <replaceable class="parameter">document</replaceable> <type>text</type>) returns <type>tsvector</type>
</synopsis>
<!-- pgdoc-cn_end sig_en=a890724e80695677bd5defa42be18b7e -->

<!-- pgdoc-cn_start sig_en=740f05542b2ad98d2ce321875686adac sig_cn_org=None source=14.1 
   <para>
    <function>to_tsvector</function> parses a textual document into tokens,
    reduces the tokens to lexemes, and returns a <type>tsvector</type> which
    lists the lexemes together with their positions in the document.
    The document is processed according to the specified or default
    text search configuration.
    Here is a simple example:

<screen>
SELECT to_tsvector('english', 'a fat  cat sat on a mat - it ate a fat rats');
                  to_tsvector
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 'ate':9 'cat':3 'fat':2,11 'mat':7 'rat':12 'sat':4
</screen>
   </para>
________________________________________________________-->
   <para>
    <function>to_tsvector</function>把一个文本文档解析成记号，把记号缩减成词位，并且返回一个<type>tsvector</type>，它列出了词位以及词位在文档中的位置。文档被根据指定的或默认的文本搜索配置来处理。下面是一个简单例子：

<screen>
SELECT to_tsvector('english', 'a fat  cat sat on a mat - it ate a fat rats');
                  to_tsvector
-----------------------------------------------------
 'ate':9 'cat':3 'fat':2,11 'mat':7 'rat':12 'sat':4
</screen>
   </para>
<!-- pgdoc-cn_end sig_en=740f05542b2ad98d2ce321875686adac -->

<!-- pgdoc-cn_start sig_en=9efcc41c2da42bbf0d007ff1b2a11cff sig_cn_org=None source=14.1 
   <para>
    In the example above we see that the resulting <type>tsvector</type> does not
    contain the words <literal>a</literal>, <literal>on</literal>, or
    <literal>it</literal>, the word <literal>rats</literal> became
    <literal>rat</literal>, and the punctuation sign <literal>-</literal> was
    ignored.
   </para>
________________________________________________________-->
   <para>
    在上面这个例子中我们看到，作为结果的<type>tsvector</type>不包含词<literal>a</literal>、<literal>on</literal>或<literal>it</literal>，词<literal>rats</literal>变成了<literal>rat</literal>，并且标点符号<literal>-</literal>被忽略了。
   </para>
<!-- pgdoc-cn_end sig_en=9efcc41c2da42bbf0d007ff1b2a11cff -->

<!-- pgdoc-cn_start sig_en=531bdd4f51320d8a483fce6241f3cfa3 sig_cn_org=None source=14.1 
   <para>
    The <function>to_tsvector</function> function internally calls a parser
    which breaks the document text into tokens and assigns a type to
    each token.  For each token, a list of
    dictionaries (<xref linkend="textsearch-dictionaries"/>) is consulted,
    where the list can vary depending on the token type.  The first dictionary
    that <firstterm>recognizes</firstterm> the token emits one or more normalized
    <firstterm>lexemes</firstterm> to represent the token.  For example,
    <literal>rats</literal> became <literal>rat</literal> because one of the
    dictionaries recognized that the word <literal>rats</literal> is a plural
    form of <literal>rat</literal>.  Some words are recognized as
    <firstterm>stop words</firstterm> (<xref linkend="textsearch-stopwords"/>), which
    causes them to be ignored since they occur too frequently to be useful in
    searching.  In our example these are
    <literal>a</literal>, <literal>on</literal>, and <literal>it</literal>.
    If no dictionary in the list recognizes the token then it is also ignored.
    In this example that happened to the punctuation sign <literal>-</literal>
    because there are in fact no dictionaries assigned for its token type
    (<literal>Space symbols</literal>), meaning space tokens will never be
    indexed. The choices of parser, dictionaries and which types of tokens to
    index are determined by the selected text search configuration (<xref
    linkend="textsearch-configuration"/>).  It is possible to have
    many different configurations in the same database, and predefined
    configurations are available for various languages. In our example
    we used the default configuration <literal>english</literal> for the
    English language.
   </para>
________________________________________________________-->
   <para>
    <function>to_tsvector</function>函数在内部调用了一个解析器，它把文档文本分解成记号并且为每一种记号分配一个类型。对于每一个记号，会去查询一个词典列表（<xref linkend="textsearch-dictionaries"/>），该列表会根据记号的类型而变化。第一个<firstterm>识别</firstterm>记号的词典产生一个或多个正规化的<firstterm>词位</firstterm>来表示该记号。例如，<literal>rats</literal>变成<literal>rat</literal>是因为一个词典识别到该词<literal>rats</literal>是<literal>rat</literal>的复数形式。一些词会被识别为<firstterm>停用词</firstterm>（<xref linkend="textsearch-stopwords"/>），这将导致它们被忽略，因为它们出现得太频繁以至于在搜索中起不到作用。在我们的例子中有<literal>a</literal>、<literal>on</literal>和<literal>it</literal>是停用词。如果在列表中没有词典能识别该记号，那它将也会被忽略。在这个例子中标点符号<literal>-</literal>就属于这种情况，因为事实上没有词典会给它分配记号类型（<literal>空间符号</literal>），即空间记号不会被索引。对于解析器、词典以及要索引哪些记号类型是由所选择的文本搜索配置（<xref linkend="textsearch-configuration"/>）决定的。可以在同一个数据库中有多种不同的配置，并且有用于很多种语言的预定义配置。在我们的例子中，我们使用用于英语的默认配置<literal>english</literal>。
   </para>
<!-- pgdoc-cn_end sig_en=531bdd4f51320d8a483fce6241f3cfa3 -->

<!-- pgdoc-cn_start sig_en=a0dcfeff69a002c514b341dda5ece106 sig_cn_org=None source=14.1 
   <para>
    The function <function>setweight</function> can be used to label the
    entries of a <type>tsvector</type> with a given <firstterm>weight</firstterm>,
    where a weight is one of the letters <literal>A</literal>, <literal>B</literal>,
    <literal>C</literal>, or <literal>D</literal>.
    This is typically used to mark entries coming from
    different parts of a document, such as title versus body.  Later, this
    information can be used for ranking of search results.
   </para>
________________________________________________________-->
   <para>
    函数<function>setweight</function>可以被用来对<type>tsvector</type>中的项标注一个给定的<firstterm>权重</firstterm>，这里一个权重可以是四个字母之一：<literal>A</literal>、<literal>B</literal>、<literal>C</literal>或<literal>D</literal>。这通常被用来标记来自文档不同部分的项，例如标题对正文。稍后，这种信息可以被用来排名搜索结果。
   </para>
<!-- pgdoc-cn_end sig_en=a0dcfeff69a002c514b341dda5ece106 -->

<!-- pgdoc-cn_start sig_en=333e87218aaa4a4884c3f1bec973515c sig_cn_org=None source=14.1 
   <para>
    Because <function>to_tsvector</function>(<literal>NULL</literal>) will
    return <literal>NULL</literal>, it is recommended to use
    <function>coalesce</function> whenever a field might be null.
    Here is the recommended method for creating
    a <type>tsvector</type> from a structured document:

<programlisting>
UPDATE tt SET ti =
    setweight(to_tsvector(coalesce(title,'')), 'A')    ||
    setweight(to_tsvector(coalesce(keyword,'')), 'B')  ||
    setweight(to_tsvector(coalesce(abstract,'')), 'C') ||
    setweight(to_tsvector(coalesce(body,'')), 'D');
</programlisting>

    Here we have used <function>setweight</function> to label the source
    of each lexeme in the finished <type>tsvector</type>, and then merged
    the labeled <type>tsvector</type> values using the <type>tsvector</type>
    concatenation operator <literal>||</literal>.  (<xref
    linkend="textsearch-manipulate-tsvector"/> gives details about these
    operations.)
   </para>
________________________________________________________-->
   <para>
    因为<function>to_tsvector</function>(<literal>NULL</literal>) 将返回<literal>NULL</literal>，不论何时一个域可能为空时，我们推荐使用<function>coalesce</function>。下面是我们推荐的从一个结构化文档创建一个<type>tsvector</type>的方法：

<programlisting>
UPDATE tt SET ti =
    setweight(to_tsvector(coalesce(title,'')), 'A')    ||
    setweight(to_tsvector(coalesce(keyword,'')), 'B')  ||
    setweight(to_tsvector(coalesce(abstract,'')), 'C') ||
    setweight(to_tsvector(coalesce(body,'')), 'D');
</programlisting>

    这里我们已经使用了<function>setweight</function>在完成的<type>tsvector</type>标注每一个词位的来源，并且接着将标注过的<type>tsvector</type>值用<type>tsvector</type>连接操作符<literal>||</literal>合并在一起（<xref linkend="textsearch-manipulate-tsvector"/>给出了关于这些操作符的细节）。
   </para>
<!-- pgdoc-cn_end sig_en=333e87218aaa4a4884c3f1bec973515c -->

  </sect2>

  <sect2 id="textsearch-parsing-queries">
<!-- pgdoc-cn_start sig_en=b8868350a6924022c599d48ac11ae0a4 sig_cn_org=None source=14.1 
   <title>Parsing Queries</title>
________________________________________________________-->
   <title>解析查询</title>
<!-- pgdoc-cn_end sig_en=b8868350a6924022c599d48ac11ae0a4 -->

<!-- pgdoc-cn_start sig_en=01abbb20980878e7d81a1d864e7c4839 sig_cn_org=None source=14.1 
   <para>
    <productname>PostgreSQL</productname> provides the
    functions <function>to_tsquery</function>,
    <function>plainto_tsquery</function>,
    <function>phraseto_tsquery</function> and
    <function>websearch_to_tsquery</function>
    for converting a query to the <type>tsquery</type> data type.
    <function>to_tsquery</function> offers access to more features
    than either <function>plainto_tsquery</function> or
    <function>phraseto_tsquery</function>, but it is less forgiving about its
    input. <function>websearch_to_tsquery</function> is a simplified version
    of <function>to_tsquery</function> with an alternative syntax, similar
    to the one used by web search engines.
   </para>
________________________________________________________-->
   <para>
    <productname>PostgreSQL</productname>提供了函数<function>to_tsquery</function>、<function>plainto_tsquery</function>、<function>phraseto_tsquery</function>以及<function>websearch_to_tsquery</function>用来把一个查询转换成<type>tsquery</type>数据类型。<function>to_tsquery</function>提供了比<function>plainto_tsquery</function>和<function>phraseto_tsquery</function>更多的特性，但是它对其输入要求更加严格。<function>websearch_to_tsquery</function>是<function>to_tsquery</function>的一个简化版本，它使用一种可选择的语法，类似于Web搜索引擎使用的语法。
   </para>
<!-- pgdoc-cn_end sig_en=01abbb20980878e7d81a1d864e7c4839 -->

<!-- pgdoc-cn_start sig_en=cb38be849fced3f93c4340167f6ec2a0 sig_cn_org=None source=14.1 
   <indexterm>
    <primary>to_tsquery</primary>
   </indexterm>
________________________________________________________-->
   <indexterm>
    <primary>to_tsquery</primary>
   </indexterm>
<!-- pgdoc-cn_end sig_en=cb38be849fced3f93c4340167f6ec2a0 -->

<!-- pgdoc-cn_start sig_en=2d0c47e48af11c5fe33788baf6211f52 sig_cn_org=None source=14.1 
<synopsis>
to_tsquery(<optional> <replaceable class="parameter">config</replaceable> <type>regconfig</type>, </optional> <replaceable class="parameter">querytext</replaceable> <type>text</type>) returns <type>tsquery</type>
</synopsis>
________________________________________________________-->
<synopsis>
to_tsquery(<optional> <replaceable class="parameter">config</replaceable> <type>regconfig</type>, </optional> <replaceable class="parameter">querytext</replaceable> <type>text</type>) returns <type>tsquery</type>
</synopsis>
<!-- pgdoc-cn_end sig_en=2d0c47e48af11c5fe33788baf6211f52 -->

<!-- pgdoc-cn_start sig_en=a788b61150251db6f66be15755ea3a03 sig_cn_org=75c594faae748b8503255db8f7162d84 source=15.7 
   <para>
    <function>to_tsquery</function> creates a <type>tsquery</type> value from
    <replaceable>querytext</replaceable>, which must consist of single tokens
    separated by the <type>tsquery</type> operators <literal>&amp;</literal> (AND),
    <literal>|</literal> (OR), <literal>!</literal> (NOT), and
    <literal>&lt;-&gt;</literal> (FOLLOWED BY), possibly grouped
    using parentheses.  In other words, the input to
    <function>to_tsquery</function> must already follow the general rules for
    <type>tsquery</type> input, as described in <xref
    linkend="datatype-tsquery"/>.  The difference is that while basic
    <type>tsquery</type> input takes the tokens at face value,
    <function>to_tsquery</function> normalizes each token into a lexeme using
    the specified or default configuration, and discards any tokens that are
    stop words according to the configuration.  For example:

<screen>
SELECT to_tsquery('english', 'The &amp; Fat &amp; Rats');
  to_tsquery
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 'fat' &amp; 'rat'
</screen>

    As in basic <type>tsquery</type> input, weight(s) can be attached to each
    lexeme to restrict it to match only <type>tsvector</type> lexemes of those
    weight(s).  For example:

<screen>
SELECT to_tsquery('english', 'Fat | Rats:AB');
    to_tsquery
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 'fat' | 'rat':AB
</screen>

    Also, <literal>*</literal> can be attached to a lexeme to specify prefix matching:

<screen>
SELECT to_tsquery('supern:*A &amp; star:A*B');
        to_tsquery
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 'supern':*A &amp; 'star':*AB
</screen>

    Such a lexeme will match any word in a <type>tsvector</type> that begins
    with the given string.
   </para>
________________________________________________________-->
   <para>
    <function>to_tsquery</function>从<replaceable>querytext</replaceable>创建一个<type>tsquery</type>值，
    其必须由用<type>tsquery</type>运算符<literal>&amp;</literal>（AND）、<literal>|</literal>（OR）、
    <literal>!</literal>（NOT）和<literal>&lt;-&gt;</literal>（FOLLOWED BY）分隔的单个标记组成，
    可能使用括号进行分组。换句话说，输入到<function>to_tsquery</function>的内容必须已遵循
    <xref linkend="datatype-tsquery"/>中描述的<type>tsquery</type>输入的一般规则。不同之处在于，
    基本的<type>tsquery</type>输入按面值接受标记，而<function>to_tsquery</function>会使用指定或默认配置将
    每个标记标准化为一个词元，并丢弃那些配置为停用词的标记。例如：

<screen>
SELECT to_tsquery('english', 'The &amp; Fat &amp; Rats');
  to_tsquery
---------------
 'fat' &amp; 'rat'
</screen>

    与基本<type>tsquery</type>输入一样，可以附加权重以限制每个词元仅匹配具有该权重的<type>tsvector</type>词元。
    例如：

<screen>
SELECT to_tsquery('english', 'Fat | Rats:AB');
    to_tsquery
------------------
 'fat' | 'rat':AB
</screen>

    此外，<literal>*</literal>可以附加到词元以指定前缀匹配：

<screen>
SELECT to_tsquery('supern:*A &amp; star:A*B');
        to_tsquery
--------------------------
 'supern':*A &amp; 'star':*AB
</screen>

    这样的词元将匹配以给定字符串开头的<type>tsvector</type>中的任何单词。
   </para>
<!-- pgdoc-cn_end sig_en=a788b61150251db6f66be15755ea3a03 -->

<!-- pgdoc-cn_start sig_en=cb575a7c603051f1bcdaf47fa54eee71 sig_cn_org=None source=14.1 
   <para>
    <function>to_tsquery</function> can also accept single-quoted
    phrases.  This is primarily useful when the configuration includes a
    thesaurus dictionary that may trigger on such phrases.
    In the example below, a thesaurus contains the rule <literal>supernovae
    stars : sn</literal>:

<screen>
SELECT to_tsquery('''supernovae stars'' &amp; !crab');
  to_tsquery
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 'sn' &amp; !'crab'
</screen>

    Without quotes, <function>to_tsquery</function> will generate a syntax
    error for tokens that are not separated by an AND, OR, or FOLLOWED BY
    operator.
   </para>
________________________________________________________-->
   <para>
    <function>to_tsquery</function>也能够接受单引号短语。当配置包括一个会在这种短语上触发的分类词典时就是它的主要用处。在下面的例子中，一个分类词典含规则<literal>supernovae stars : sn</literal>：

<screen>
SELECT to_tsquery('''supernovae stars'' &amp; !crab');
  to_tsquery
---------------
 'sn' &amp; !'crab'
</screen>

    在没有引号时，<function>to_tsquery</function>将为那些没有被 AND、OR 或者 FOLLOWED BY 操作符分隔的记号产生一个语法错误。
   </para>
<!-- pgdoc-cn_end sig_en=cb575a7c603051f1bcdaf47fa54eee71 -->

<!-- pgdoc-cn_start sig_en=928bc17808804192d33544fc3a69771f sig_cn_org=None source=14.1 
   <indexterm>
    <primary>plainto_tsquery</primary>
   </indexterm>
________________________________________________________-->
   <indexterm>
    <primary>plainto_tsquery</primary>
   </indexterm>
<!-- pgdoc-cn_end sig_en=928bc17808804192d33544fc3a69771f -->

<!-- pgdoc-cn_start sig_en=70d6f37aba2505c48a7d8e03f0499882 sig_cn_org=None source=14.1 
<synopsis>
plainto_tsquery(<optional> <replaceable class="parameter">config</replaceable> <type>regconfig</type>, </optional> <replaceable class="parameter">querytext</replaceable> <type>text</type>) returns <type>tsquery</type>
</synopsis>
________________________________________________________-->
<synopsis>
plainto_tsquery(<optional> <replaceable class="parameter">config</replaceable> <type>regconfig</type>, </optional> <replaceable class="parameter">querytext</replaceable> <type>text</type>) returns <type>tsquery</type>
</synopsis>
<!-- pgdoc-cn_end sig_en=70d6f37aba2505c48a7d8e03f0499882 -->

<!-- pgdoc-cn_start sig_en=fcc1a37e5a3f8542f93ce9362f813e51 sig_cn_org=None source=14.1 
   <para>
    <function>plainto_tsquery</function> transforms the unformatted text
    <replaceable>querytext</replaceable> to a <type>tsquery</type> value.
    The text is parsed and normalized much as for <function>to_tsvector</function>,
    then the <literal>&amp;</literal> (AND) <type>tsquery</type> operator is
    inserted between surviving words.
   </para>
________________________________________________________-->
   <para>
    <function>plainto_tsquery</function>将未格式化的文本<replaceable>querytext</replaceable>转换成一个<type>tsquery</type>值。该文本被解析并被正规化，很像<function>to_tsvector</function>，然后<literal>&amp;</literal>（AND）布尔操作符被插入到留下来的词之间。
   </para>
<!-- pgdoc-cn_end sig_en=fcc1a37e5a3f8542f93ce9362f813e51 -->

<!-- pgdoc-cn_start sig_en=03483b889f721aa0bfe2c9fbf4b3351f sig_cn_org=88b4ee209a44a5de55915fd672f9cfdc source=15.7 
   <para>
    Example:

<screen>
SELECT plainto_tsquery('english', 'The Fat Rats');
 plainto_tsquery
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 'fat' &amp; 'rat'
</screen>

    Note that <function>plainto_tsquery</function> will not
    recognize <type>tsquery</type> operators, weight labels,
    or prefix-match labels in its input:

<screen>
SELECT plainto_tsquery('english', 'The Fat &amp; Rats:C');
   plainto_tsquery
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 'fat' &amp; 'rat' &amp; 'c'
</screen>

    Here, all the input punctuation was discarded.
   </para>
________________________________________________________-->
   <para>
    例子:

<screen>
SELECT plainto_tsquery('english', 'The Fat Rats');
 plainto_tsquery
-----------------
 'fat' &amp; 'rat'
</screen>

    注意<function>plainto_tsquery</function>不会识别其输入中的<type>tsquery</type>操作符、权重标签或前缀匹配标签:

<screen>
SELECT plainto_tsquery('english', 'The Fat &amp; Rats:C');
   plainto_tsquery
---------------------
 'fat' &amp; 'rat' &amp; 'c'
</screen>

    这里，所有输入的标点符号都被丢弃了。
   </para>
<!-- pgdoc-cn_end sig_en=03483b889f721aa0bfe2c9fbf4b3351f -->

<!-- pgdoc-cn_start sig_en=e625514fe7aaad2d3fa8c2a671b9357d sig_cn_org=None source=14.1 
   <indexterm>
    <primary>phraseto_tsquery</primary>
   </indexterm>
________________________________________________________-->
   <indexterm>
    <primary>phraseto_tsquery</primary>
   </indexterm>
<!-- pgdoc-cn_end sig_en=e625514fe7aaad2d3fa8c2a671b9357d -->

<!-- pgdoc-cn_start sig_en=90729a3f947e685933211608bd99d1ef sig_cn_org=None source=14.1 
<synopsis>
phraseto_tsquery(<optional> <replaceable class="parameter">config</replaceable> <type>regconfig</type>, </optional> <replaceable class="parameter">querytext</replaceable> <type>text</type>) returns <type>tsquery</type>
</synopsis>
________________________________________________________-->
<synopsis>
phraseto_tsquery(<optional> <replaceable class="parameter">config</replaceable> <type>regconfig</type>, </optional> <replaceable class="parameter">querytext</replaceable> <type>text</type>) returns <type>tsquery</type>
</synopsis>
<!-- pgdoc-cn_end sig_en=90729a3f947e685933211608bd99d1ef -->

<!-- pgdoc-cn_start sig_en=a8d2393a0fb57663497f684fc1bede12 sig_cn_org=None source=14.1 
   <para>
    <function>phraseto_tsquery</function> behaves much like
    <function>plainto_tsquery</function>, except that it inserts
    the <literal>&lt;-&gt;</literal> (FOLLOWED BY) operator between
    surviving words instead of the <literal>&amp;</literal> (AND) operator.
    Also, stop words are not simply discarded, but are accounted for by
    inserting <literal>&lt;<replaceable>N</replaceable>&gt;</literal> operators rather
    than <literal>&lt;-&gt;</literal> operators.  This function is useful
    when searching for exact lexeme sequences, since the FOLLOWED BY
    operators check lexeme order not just the presence of all the lexemes.
   </para>
________________________________________________________-->
   <para>
    <function>phraseto_tsquery</function>的行为很像<function>plainto_tsquery</function>，不过前者会在留下来的词之间插入<literal>&lt;-&gt;</literal>（FOLLOWED BY）操作符而不是<literal>&amp;</literal>（AND）操作符。还有，停用词也不是简单地丢弃掉，而是通过插入<literal>&lt;<replaceable>N</replaceable>&gt;</literal>操作符（而不是<literal>&lt;-&gt;</literal>操作符）来解释。在搜索准确的词位序列时这个函数很有用，因为 FOLLOWED BY 操作符不只是检查所有词位的存在性，还会检查词位的顺序。
   </para>
<!-- pgdoc-cn_end sig_en=a8d2393a0fb57663497f684fc1bede12 -->

<!-- pgdoc-cn_start sig_en=94f7218c8317b842a4ce6ad5532357de sig_cn_org=None source=14.1 
   <para>
    Example:

<screen>
SELECT phraseto_tsquery('english', 'The Fat Rats');
 phraseto_tsquery
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 'fat' &lt;-&gt; 'rat'
</screen>

    Like <function>plainto_tsquery</function>, the
    <function>phraseto_tsquery</function> function will not
    recognize <type>tsquery</type> operators, weight labels,
    or prefix-match labels in its input:

<screen>
SELECT phraseto_tsquery('english', 'The Fat &amp; Rats:C');
      phraseto_tsquery
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 'fat' &lt;-&gt; 'rat' &lt;-&gt; 'c'
</screen>
   </para>
________________________________________________________-->
   <para>
    例子：

<screen>
SELECT phraseto_tsquery('english', 'The Fat Rats');
 phraseto_tsquery
------------------
 'fat' &lt;-&gt; 'rat'
</screen>

    和<function>plainto_tsquery</function>相似，<function>phraseto_tsquery</function>函数不会识别其输入中的<type>tsquery</type>操作符、权重标签或者前缀匹配标签：

<screen>
SELECT phraseto_tsquery('english', 'The Fat &amp; Rats:C');
      phraseto_tsquery
-----------------------------
 'fat' &lt;-&gt; 'rat' &lt;-&gt; 'c'
</screen>
   </para>
<!-- pgdoc-cn_end sig_en=94f7218c8317b842a4ce6ad5532357de -->

<!-- pgdoc-cn_start sig_en=a30e5612b0659a7ca564ae375eda4173 sig_cn_org=None source=14.1 
<synopsis>
websearch_to_tsquery(<optional> <replaceable class="parameter">config</replaceable> <type>regconfig</type>, </optional> <replaceable class="parameter">querytext</replaceable> <type>text</type>) returns <type>tsquery</type>
</synopsis>
________________________________________________________-->
<synopsis>
websearch_to_tsquery(<optional> <replaceable class="parameter">config</replaceable> <type>regconfig</type>, </optional> <replaceable class="parameter">querytext</replaceable> <type>text</type>) returns <type>tsquery</type>
</synopsis>
<!-- pgdoc-cn_end sig_en=a30e5612b0659a7ca564ae375eda4173 -->

<!-- pgdoc-cn_start sig_en=c924e2908b870fe43b755ceb3feccc24 sig_cn_org=None source=14.1 
   <para>
    <function>websearch_to_tsquery</function> creates a <type>tsquery</type>
    value from <replaceable>querytext</replaceable> using an alternative
    syntax in which simple unformatted text is a valid query.
    Unlike <function>plainto_tsquery</function>
    and <function>phraseto_tsquery</function>, it also recognizes certain
    operators. Moreover, this function will never raise syntax errors,
    which makes it possible to use raw user-supplied input for search.
    The following syntax is supported:

    <itemizedlist  spacing="compact" mark="bullet">
     <listitem>
       <para>
        <literal>unquoted text</literal>: text not inside quote marks will be
        converted to terms separated by <literal>&amp;</literal> operators, as
        if processed by <function>plainto_tsquery</function>.
      </para>
     </listitem>
     <listitem>
       <para>
        <literal>"quoted text"</literal>: text inside quote marks will be
        converted to terms separated by <literal>&lt;-&gt;</literal>
        operators, as if processed by <function>phraseto_tsquery</function>.
      </para>
     </listitem>
     <listitem>
      <para>
       <literal>OR</literal>: the word <quote>or</quote> will be converted to
       the <literal>|</literal> operator.
      </para>
     </listitem>
     <listitem>
      <para>
       <literal>-</literal>: a dash will be converted to
       the <literal>!</literal> operator.
      </para>
     </listitem>
    </itemizedlist>

    Other punctuation is ignored.  So
    like <function>plainto_tsquery</function>
    and <function>phraseto_tsquery</function>,
    the <function>websearch_to_tsquery</function> function will not
    recognize <type>tsquery</type> operators, weight labels, or prefix-match
    labels in its input.
   </para>
________________________________________________________-->
   <para>
    <function>websearch_to_tsquery</function>使用一种可供选择的语法从<replaceable>querytext</replaceable>创建一个<type>tsquery</type>值，这种语法中简单的未格式化文本是一个有效的查询。和<function>plainto_tsquery</function>以及<function>phraseto_tsquery</function>不同，它还识别特定的操作符。此外，这个函数绝不会报出语法错误，这就可以把原始的用户提供的输入用于搜索。支持下列语法：

    <itemizedlist  spacing="compact" mark="bullet">
     <listitem>
       <para>
        <literal>无引号文本</literal>：不在引号中的文本将被转换成由<literal>&amp;</literal>操作符分隔的词，就像被<function>plainto_tsquery</function>处理过那样。
      </para>
     </listitem>
     <listitem>
       <para>
        <literal>"引号文本"</literal>：在引号中的文本将被转换成由<literal>&lt;-&gt;</literal>操作符分隔的词，就像被<function>phraseto_tsquery</function>处理过那样。
      </para>
     </listitem>
     <listitem>
      <para>
       <literal>OR</literal>：<quote>or</quote>将转换为<literal>|</literal>运算符。
      </para>
     </listitem>
     <listitem>
      <para>
       <literal>-</literal>：破折号将转换为 <literal>!</literal> 运算符。
      </para>
     </listitem>
    </itemizedlist>

    忽略其他标点符号。因此，与 <function>plainto_tsquery</function> 和 <function>phraseto_tsquery</function> 一样，<function>websearch_to_tsquery</function>函数在其输入中将不会识别<type>tsquery</type>运算符、权重标签或前缀匹配标签。
   </para>
<!-- pgdoc-cn_end sig_en=c924e2908b870fe43b755ceb3feccc24 -->

<!-- pgdoc-cn_start sig_en=38113bbe86110ad1f52a0bbf646abe2d sig_cn_org=None source=14.1 
   <para>
    Examples:
<screen>
SELECT websearch_to_tsquery('english', 'The fat rats');
 websearch_to_tsquery
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 'fat' &amp; 'rat'
(1 row)

SELECT websearch_to_tsquery('english', '"supernovae stars" -crab');
       websearch_to_tsquery
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 'supernova' &lt;-&gt; 'star' &amp; !'crab'
(1 row)

SELECT websearch_to_tsquery('english', '"sad cat" or "fat rat"');
       websearch_to_tsquery
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 'sad' &lt;-&gt; 'cat' | 'fat' &lt;-&gt; 'rat'
(1 row)

SELECT websearch_to_tsquery('english', 'signal -"segmentation fault"');
         websearch_to_tsquery
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 'signal' &amp; !( 'segment' &lt;-&gt; 'fault' )
(1 row)

SELECT websearch_to_tsquery('english', '""" )( dummy \\ query &lt;-&gt;');
 websearch_to_tsquery
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 'dummi' &amp; 'queri'
(1 row)
</screen>
    </para>
________________________________________________________-->
   <para>
    示例：
<screen>
SELECT websearch_to_tsquery('english', 'The fat rats');
 websearch_to_tsquery
----------------------
 'fat' &amp; 'rat'
(1 row)

SELECT websearch_to_tsquery('english', '"supernovae stars" -crab');
       websearch_to_tsquery
----------------------------------
 'supernova' &lt;-&gt; 'star' &amp; !'crab'
(1 row)

SELECT websearch_to_tsquery('english', '"sad cat" or "fat rat"');
       websearch_to_tsquery
-----------------------------------
 'sad' &lt;-&gt; 'cat' | 'fat' &lt;-&gt; 'rat'
(1 row)

SELECT websearch_to_tsquery('english', 'signal -"segmentation fault"');
         websearch_to_tsquery
---------------------------------------
 'signal' &amp; !( 'segment' &lt;-&gt; 'fault' )
(1 row)

SELECT websearch_to_tsquery('english', '""" )( dummy \\ query &lt;-&gt;');
 websearch_to_tsquery
----------------------
 'dummi' &amp; 'queri'
(1 row)
</screen>
    </para>
<!-- pgdoc-cn_end sig_en=38113bbe86110ad1f52a0bbf646abe2d -->
  </sect2>

  <sect2 id="textsearch-ranking">
<!-- pgdoc-cn_start sig_en=f178041b377cabc7571faf814e06c24f sig_cn_org=None source=14.1 
   <title>Ranking Search Results</title>
________________________________________________________-->
   <title>排名搜索结果</title>
<!-- pgdoc-cn_end sig_en=f178041b377cabc7571faf814e06c24f -->

<!-- pgdoc-cn_start sig_en=264f78dcd7574dede270441550078be5 sig_cn_org=None source=14.1 
   <para>
    Ranking attempts to measure how relevant documents are to a particular
    query, so that when there are many matches the most relevant ones can be
    shown first.  <productname>PostgreSQL</productname> provides two
    predefined ranking functions, which take into account lexical, proximity,
    and structural information; that is, they consider how often the query
    terms appear in the document, how close together the terms are in the
    document, and how important is the part of the document where they occur.
    However, the concept of relevancy is vague and very application-specific.
    Different applications might require additional information for ranking,
    e.g., document modification time.  The built-in ranking functions are only
    examples.  You can write your own ranking functions and/or combine their
    results with additional factors to fit your specific needs.
   </para>
________________________________________________________-->
   <para>
    排名处理尝试度量文档和一个特定查询的接近程度，这样当有很多匹配时最相关的那些可以被先显示。<productname>PostgreSQL</productname>提供了两种预定义的排名函数，它们考虑词法、临近性和结构信息；即，它们考虑查询词在文档中出现得有多频繁，文档中的词有多接近，以及词出现的文档部分有多重要。不过，相关性的概念是模糊的并且与应用非常相关。不同的应用可能要求额外的信息用于排名，例如，文档修改时间。内建的排名函数只是例子。你可以编写你自己的排名函数和/或把它们的结果与附加因素整合在一起来适应你的特定需求。
   </para>
<!-- pgdoc-cn_end sig_en=264f78dcd7574dede270441550078be5 -->

<!-- pgdoc-cn_start sig_en=a09e42dd49cf3170042717594c40ac57 sig_cn_org=None source=14.1 
   <para>
    The two ranking functions currently available are:

    <variablelist>

     <varlistentry>

      <term>
       <indexterm>
        <primary>ts_rank</primary>
       </indexterm>

       <literal>ts_rank(<optional> <replaceable class="parameter">weights</replaceable> <type>float4[]</type>, </optional> <replaceable class="parameter">vector</replaceable> <type>tsvector</type>, <replaceable class="parameter">query</replaceable> <type>tsquery</type> <optional>, <replaceable class="parameter">normalization</replaceable> <type>integer</type> </optional>) returns <type>float4</type></literal>
      </term>

      <listitem>
       <para>
        Ranks vectors based on the frequency of their matching lexemes.
       </para>
      </listitem>
     </varlistentry>

     <varlistentry>

      <term>
      <indexterm>
       <primary>ts_rank_cd</primary>
      </indexterm>

       <literal>ts_rank_cd(<optional> <replaceable class="parameter">weights</replaceable> <type>float4[]</type>, </optional> <replaceable class="parameter">vector</replaceable> <type>tsvector</type>, <replaceable class="parameter">query</replaceable> <type>tsquery</type> <optional>, <replaceable class="parameter">normalization</replaceable> <type>integer</type> </optional>) returns <type>float4</type></literal>
      </term>

      <listitem>
       <para>
        This function computes the <firstterm>cover density</firstterm>
        ranking for the given document vector and query, as described in
        Clarke, Cormack, and Tudhope's "Relevance Ranking for One to Three
        Term Queries" in the journal "Information Processing and Management",
        1999.  Cover density is similar to <function>ts_rank</function> ranking
        except that the proximity of matching lexemes to each other is
        taken into consideration.
       </para>

       <para>
        This function requires lexeme positional information to perform
        its calculation.  Therefore, it ignores any <quote>stripped</quote>
        lexemes in the <type>tsvector</type>.  If there are no unstripped
        lexemes in the input, the result will be zero.  (See <xref
        linkend="textsearch-manipulate-tsvector"/> for more information
        about the <function>strip</function> function and positional information
        in <type>tsvector</type>s.)
       </para>
      </listitem>
     </varlistentry>

    </variablelist>

   </para>
________________________________________________________-->
   <para>
    目前可用的两种排名函数是：

    <variablelist>

     <varlistentry>
     <term>
      <indexterm>
       <primary>ts_rank</primary>
      </indexterm>

       <literal>ts_rank(<optional> <replaceable class="parameter">weights</replaceable> <type>float4[]</type>, </optional> <replaceable class="parameter">vector</replaceable> <type>tsvector</type>, <replaceable class="parameter">query</replaceable> <type>tsquery</type> <optional>, <replaceable class="parameter">normalization</replaceable> <type>integer</type> </optional>) returns <type>float4</type></literal>
      </term>

      <listitem>
       <para>
        基于向量的匹配词位的频率来排名向量。
       </para>
      </listitem>
     </varlistentry>

     <varlistentry>

      <term>
      <indexterm>
       <primary>ts_rank_cd</primary>
      </indexterm>

       <literal>ts_rank_cd(<optional> <replaceable class="parameter">weights</replaceable> <type>float4[]</type>, </optional> <replaceable class="parameter">vector</replaceable> <type>tsvector</type>, <replaceable class="parameter">query</replaceable> <type>tsquery</type> <optional>, <replaceable class="parameter">normalization</replaceable> <type>integer</type> </optional>) returns <type>float4</type></literal>
      </term>

      <listitem>
       <para>
        这个函数为给定文档向量和查询计算<firstterm>覆盖密度</firstterm>排名，该方法在 Clarke、Cormack 和 Tudhope 于 1999 年在期刊 "Information Processing and Management" 上的文章  "Relevance Ranking for One to Three Term Queries" 文章中有描述。覆盖密度类似于<function>ts_rank</function>排名，不过它会考虑匹配词位相互之间的接近度。
       </para>

       <para>
        这个函数要求词位的位置信息来执行其计算。因此它会忽略<type>tsvector</type>中任何<quote>被剥离的</quote>词位。如果在输入中有未被剥离的词位，结果将会是零（<function>strip</function>函数和<type>tsvector</type>中的位置信息的更多内容请见<xref linkend="textsearch-manipulate-tsvector"/>）。
       </para>
      </listitem>
     </varlistentry>

    </variablelist>

   </para>
<!-- pgdoc-cn_end sig_en=a09e42dd49cf3170042717594c40ac57 -->

<!-- pgdoc-cn_start sig_en=3290bc2aff233d660d9d29a80e8e96db sig_cn_org=None source=14.1 
   <para>
    For both these functions,
    the optional <replaceable class="parameter">weights</replaceable>
    argument offers the ability to weigh word instances more or less
    heavily depending on how they are labeled.  The weight arrays specify
    how heavily to weigh each category of word, in the order:

<synopsis>
{D-weight, C-weight, B-weight, A-weight}
</synopsis>

    If no <replaceable class="parameter">weights</replaceable> are provided,
    then these defaults are used:

<programlisting>
{0.1, 0.2, 0.4, 1.0}
</programlisting>

    Typically weights are used to mark words from special areas of the
    document, like the title or an initial abstract, so they can be
    treated with more or less importance than words in the document body.
   </para>
________________________________________________________-->
   <para>
    对这两个函数，可选的<replaceable class="parameter">权重</replaceable>参数提供了为词实例赋予更多或更少权重的能力，这种能力是依据它们被标注的情况的。权重数组指定每一类词应该得到多重的权重，按照如下的顺序：

<synopsis>
{D-权重, C-权重, B-权重, A-权重}
</synopsis>

    如果没有提供<replaceable class="parameter">权重</replaceable>，那么将使用这些默认值：

<programlisting>
{0.1, 0.2, 0.4, 1.0}
</programlisting>

    通常权重被用来标记来自文档特别区域的词，如标题或一个初始的摘要，这样它们可以被认为比来自文档正文的词更重要或更不重要。
   </para>
<!-- pgdoc-cn_end sig_en=3290bc2aff233d660d9d29a80e8e96db -->

<!-- pgdoc-cn_start sig_en=02c1bf534d98d5c923f5937b17820a74 sig_cn_org=None source=14.1 
   <para>
    Since a longer document has a greater chance of containing a query term
    it is reasonable to take into account document size, e.g., a hundred-word
    document with five instances of a search word is probably more relevant
    than a thousand-word document with five instances.  Both ranking functions
    take an integer <replaceable>normalization</replaceable> option that
    specifies whether and how a document's length should impact its rank.
    The integer option controls several behaviors, so it is a bit mask:
    you can specify one or more behaviors using
    <literal>|</literal> (for example, <literal>2|4</literal>).

    <itemizedlist  spacing="compact" mark="bullet">
     <listitem>
      <para>
       0 (the default) ignores the document length
      </para>
     </listitem>
     <listitem>
      <para>
       1 divides the rank by 1 + the logarithm of the document length
      </para>
     </listitem>
     <listitem>
      <para>
       2 divides the rank by the document length
      </para>
     </listitem>
     <listitem>
      <para>
       4 divides the rank by the mean harmonic distance between extents
       (this is implemented only by <function>ts_rank_cd</function>)
      </para>
     </listitem>
     <listitem>
      <para>
       8 divides the rank by the number of unique words in document
      </para>
     </listitem>
     <listitem>
      <para>
       16 divides the rank by 1 + the logarithm of the number
       of unique words in document
      </para>
     </listitem>
     <listitem>
      <para>
       32 divides the rank by itself + 1
      </para>
     </listitem>
    </itemizedlist>

    If more than one flag bit is specified, the transformations are
    applied in the order listed.
   </para>
________________________________________________________-->
   <para>
    由于一个较长的文档有更多的机会包含一个查询术语，因此考虑文档的尺寸是合理的，例如一个一百个词的文档中有一个搜索词的五个实例而零一个一千个词的文档中有该搜索词的五个实例，则前者比后者更相关。两种排名函数都采用一个整数<replaceable>正规化</replaceable>选项，它指定文档长度是否影响其排名以及如何影响。该整数选项控制多个行为，因此它是一个位掩码：你可以使用<literal>|</literal>指定一个或多个行为（例如，<literal>2|4</literal>）。

    <itemizedlist  spacing="compact" mark="bullet">
     <listitem>
      <para>
       0（默认值）忽略文档长度
      </para>
     </listitem>
     <listitem>
      <para>
       1 用 1 + 文档长度的对数除排名
      </para>
     </listitem>
     <listitem>
      <para>
       2 用文档长度除排名
      </para>
     </listitem>
     <listitem>
      <para>
       4 用长度之间的平均调和距离除排名（只被<function>ts_rank_cd</function>实现）
      </para>
     </listitem>
     <listitem>
      <para>
       8 用文档中唯一词的数量除排名
      </para>
     </listitem>
     <listitem>
      <para>
       16 用 1 + 文档中唯一词数量的对数除排名
      </para>
     </listitem>
     <listitem>
      <para>
       32 用排名 + 1 除排名
      </para>
     </listitem>
    </itemizedlist>

    如果多于一个标志位被指定，转换将根据列出的顺序被应用。
   </para>
<!-- pgdoc-cn_end sig_en=02c1bf534d98d5c923f5937b17820a74 -->

<!-- pgdoc-cn_start sig_en=1bef21aeb907bec06325f22a753baaba sig_cn_org=None source=14.1 
   <para>
    It is important to note that the ranking functions do not use any global
    information, so it is impossible to produce a fair normalization to 1% or
    100% as sometimes desired.  Normalization option 32
    (<literal>rank/(rank+1)</literal>) can be applied to scale all ranks
    into the range zero to one, but of course this is just a cosmetic change;
    it will not affect the ordering of the search results.
   </para>
________________________________________________________-->
   <para>
    值得注意的是排名函数并不使用任何全局信息，因此它不可能按照某些时候期望地产生一个公平的正规化，从 1% 或 100%。正规化选项 32 （<literal>rank/(rank+1)</literal>）可以被应用来缩放所有的排名到范围零到一，但是当然这只是一个外观上的改变；它不会影响搜索结果的顺序。
   </para>
<!-- pgdoc-cn_end sig_en=1bef21aeb907bec06325f22a753baaba -->

<!-- pgdoc-cn_start sig_en=bde145f4d4d135dd420fd390e2c15bc0 sig_cn_org=None source=14.1 
   <para>
    Here is an example that selects only the ten highest-ranked matches:

<screen>
SELECT title, ts_rank_cd(textsearch, query) AS rank
FROM apod, to_tsquery('neutrino|(dark &amp; matter)') query
WHERE query @@ textsearch
ORDER BY rank DESC
LIMIT 10;
                     title                     |   rank
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;
 Neutrinos in the Sun                          |      3.1
 The Sudbury Neutrino Detector                 |      2.4
 A MACHO View of Galactic Dark Matter          |  2.01317
 Hot Gas and Dark Matter                       |  1.91171
 The Virgo Cluster: Hot Plasma and Dark Matter |  1.90953
 Rafting for Solar Neutrinos                   |      1.9
 NGC 4650A: Strange Galaxy and Dark Matter     |  1.85774
 Hot Gas and Dark Matter                       |   1.6123
 Ice Fishing for Cosmic Neutrinos              |      1.6
 Weak Lensing Distorts the Universe            | 0.818218
</screen>

    This is the same example using normalized ranking:

<screen>
SELECT title, ts_rank_cd(textsearch, query, 32 /* rank/(rank+1) */ ) AS rank
FROM apod, to_tsquery('neutrino|(dark &amp; matter)') query
WHERE  query @@ textsearch
ORDER BY rank DESC
LIMIT 10;
                     title                     |        rank
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 Neutrinos in the Sun                          | 0.756097569485493
 The Sudbury Neutrino Detector                 | 0.705882361190954
 A MACHO View of Galactic Dark Matter          | 0.668123210574724
 Hot Gas and Dark Matter                       |  0.65655958650282
 The Virgo Cluster: Hot Plasma and Dark Matter | 0.656301290640973
 Rafting for Solar Neutrinos                   | 0.655172410958162
 NGC 4650A: Strange Galaxy and Dark Matter     | 0.650072921219637
 Hot Gas and Dark Matter                       | 0.617195790024749
 Ice Fishing for Cosmic Neutrinos              | 0.615384618911517
 Weak Lensing Distorts the Universe            | 0.450010798361481
</screen>
   </para>
________________________________________________________-->
   <para>
    这里是一个例子，它只选择十个最高排名的匹配：

<screen>
SELECT title, ts_rank_cd(textsearch, query) AS rank
FROM apod, to_tsquery('neutrino|(dark &amp; matter)') query
WHERE query @@ textsearch
ORDER BY rank DESC
LIMIT 10;
                     title                     |   rank
-----------------------------------------------+----------
 Neutrinos in the Sun                          |      3.1
 The Sudbury Neutrino Detector                 |      2.4
 A MACHO View of Galactic Dark Matter          |  2.01317
 Hot Gas and Dark Matter                       |  1.91171
 The Virgo Cluster: Hot Plasma and Dark Matter |  1.90953
 Rafting for Solar Neutrinos                   |      1.9
 NGC 4650A: Strange Galaxy and Dark Matter     |  1.85774
 Hot Gas and Dark Matter                       |   1.6123
 Ice Fishing for Cosmic Neutrinos              |      1.6
 Weak Lensing Distorts the Universe            | 0.818218
</screen>

    这是相同的例子使用正规化的排名：

<screen>
SELECT title, ts_rank_cd(textsearch, query, 32 /* rank/(rank+1) */ ) AS rank
FROM apod, to_tsquery('neutrino|(dark &amp; matter)') query
WHERE  query @@ textsearch
ORDER BY rank DESC
LIMIT 10;
                     title                     |        rank
-----------------------------------------------+-------------------
 Neutrinos in the Sun                          | 0.756097569485493
 The Sudbury Neutrino Detector                 | 0.705882361190954
 A MACHO View of Galactic Dark Matter          | 0.668123210574724
 Hot Gas and Dark Matter                       |  0.65655958650282
 The Virgo Cluster: Hot Plasma and Dark Matter | 0.656301290640973
 Rafting for Solar Neutrinos                   | 0.655172410958162
 NGC 4650A: Strange Galaxy and Dark Matter     | 0.650072921219637
 Hot Gas and Dark Matter                       | 0.617195790024749
 Ice Fishing for Cosmic Neutrinos              | 0.615384618911517
 Weak Lensing Distorts the Universe            | 0.450010798361481
</screen>
   </para>
<!-- pgdoc-cn_end sig_en=bde145f4d4d135dd420fd390e2c15bc0 -->

<!-- pgdoc-cn_start sig_en=72cadff878bc2f4a564f9a3fa714f40e sig_cn_org=None source=14.1 
   <para>
    Ranking can be expensive since it requires consulting the
    <type>tsvector</type> of each matching document, which can be I/O bound and
    therefore slow. Unfortunately, it is almost impossible to avoid since
    practical queries often result in large numbers of matches.
   </para>
________________________________________________________-->
   <para>
    排名可能会非常昂贵，因为它要求查询每一个匹配文档的<type>tsvector</type>，这可能会涉及很多I/O因而很慢。不幸的是，这几乎不可能避免，因为实际查询常常导致巨大数目的匹配。
   </para>
<!-- pgdoc-cn_end sig_en=72cadff878bc2f4a564f9a3fa714f40e -->

  </sect2>

  <sect2 id="textsearch-headline">
<!-- pgdoc-cn_start sig_en=2dbad821df5601bfc1e5ce2fc4d66823 sig_cn_org=None source=14.1 
   <title>Highlighting Results</title>
________________________________________________________-->
   <title>加亮结果</title>
<!-- pgdoc-cn_end sig_en=2dbad821df5601bfc1e5ce2fc4d66823 -->

<!-- pgdoc-cn_start sig_en=832a177433b132667ba99bbbd6698132 sig_cn_org=None source=14.1 
   <para>
    To present search results it is ideal to show a part of each document and
    how it is related to the query. Usually, search engines show fragments of
    the document with marked search terms.  <productname>PostgreSQL</productname>
    provides a function <function>ts_headline</function> that
    implements this functionality.
   </para>
________________________________________________________-->
   <para>
    要表示搜索结果，理想的方式是显示每一个文档的一个部分并且显示它是怎样与查询相关的。通常，搜索引擎显示文档片段时会对其中的搜索术语进行标记。<productname>PostgreSQL</productname>提供了一个函数<function>ts_headline</function>来实现这个功能。
   </para>
<!-- pgdoc-cn_end sig_en=832a177433b132667ba99bbbd6698132 -->

<!-- pgdoc-cn_start sig_en=f3e9f550b3b2624efa55dd14a68ec3ad sig_cn_org=None source=14.1 
   <indexterm>
    <primary>ts_headline</primary>
   </indexterm>
________________________________________________________-->
   <indexterm>
    <primary>ts_headline</primary>
   </indexterm>
<!-- pgdoc-cn_end sig_en=f3e9f550b3b2624efa55dd14a68ec3ad -->

<!-- pgdoc-cn_start sig_en=f1b28a7c91d0a078528786e67cc881e8 sig_cn_org=None source=14.1 
<synopsis>
ts_headline(<optional> <replaceable class="parameter">config</replaceable> <type>regconfig</type>, </optional> <replaceable class="parameter">document</replaceable> <type>text</type>, <replaceable class="parameter">query</replaceable> <type>tsquery</type> <optional>, <replaceable class="parameter">options</replaceable> <type>text</type> </optional>) returns <type>text</type>
</synopsis>
________________________________________________________-->
<synopsis>
ts_headline(<optional> <replaceable class="parameter">config</replaceable> <type>regconfig</type>, </optional> <replaceable class="parameter">document</replaceable> <type>text</type>, <replaceable class="parameter">query</replaceable> <type>tsquery</type> <optional>, <replaceable class="parameter">options</replaceable> <type>text</type> </optional>) returns <type>text</type>
</synopsis>
<!-- pgdoc-cn_end sig_en=f1b28a7c91d0a078528786e67cc881e8 -->

<!-- pgdoc-cn_start sig_en=e84bfaf72bb88840e5be7d7100d1e7a2 sig_cn_org=None source=14.1 
   <para>
    <function>ts_headline</function> accepts a document along
    with a query, and returns an excerpt from
    the document in which terms from the query are highlighted.  The
    configuration to be used to parse the document can be specified by
    <replaceable>config</replaceable>; if <replaceable>config</replaceable>
    is omitted, the
    <varname>default_text_search_config</varname> configuration is used.
   </para>
________________________________________________________-->
   <para>
    <function>ts_headline</function>接受一个文档和一个查询，并且从该文档返回一个引用，在其中来自查询的术语会被加亮。被用来解析该文档的配置可以用<replaceable>config</replaceable>指定；如果<replaceable>config</replaceable>被忽略，将会使用<varname>default_text_search_config</varname>配置。
   </para>
<!-- pgdoc-cn_end sig_en=e84bfaf72bb88840e5be7d7100d1e7a2 -->

<!-- pgdoc-cn_start sig_en=5dcbea979f5e91083be5f88522a0bbc1 sig_cn_org=None source=14.1 
   <para>
    If an <replaceable>options</replaceable> string is specified it must
    consist of a comma-separated list of one or more
    <replaceable>option</replaceable><literal>=</literal><replaceable>value</replaceable> pairs.
    The available options are:

    <itemizedlist  spacing="compact" mark="bullet">
     <listitem>
      <para>
       <literal>MaxWords</literal>, <literal>MinWords</literal> (integers):
       these numbers determine the longest and shortest headlines to output.
       The default values are 35 and 15.
      </para>
     </listitem>
     <listitem>
      <para>
       <literal>ShortWord</literal> (integer): words of this length or less
       will be dropped at the start and end of a headline, unless they are
       query terms.  The default value of three eliminates common English
       articles.
      </para>
     </listitem>
     <listitem>
      <para>
       <literal>HighlightAll</literal> (boolean): if
       <literal>true</literal> the whole document will be used as the
       headline, ignoring the preceding three parameters.  The default
       is <literal>false</literal>.
      </para>
     </listitem>
     <listitem>
      <para>
       <literal>MaxFragments</literal> (integer): maximum number of text
       fragments to display.  The default value of zero selects a
       non-fragment-based headline generation method.  A value greater
       than zero selects fragment-based headline generation (see below).
      </para>
     </listitem>
     <listitem>
      <para>
       <literal>StartSel</literal>, <literal>StopSel</literal> (strings):
       the strings with which to delimit query words appearing in the
       document, to distinguish them from other excerpted words.  The
       default values are <quote><literal>&lt;b&gt;</literal></quote> and
       <quote><literal>&lt;/b&gt;</literal></quote>, which can be suitable
       for HTML output.
      </para>
     </listitem>
     <listitem>
      <para>
       <literal>FragmentDelimiter</literal> (string): When more than one
       fragment is displayed, the fragments will be separated by this string.
       The default is <quote><literal> ... </literal></quote>.
      </para>
     </listitem>
    </itemizedlist>

    These option names are recognized case-insensitively.
    You must double-quote string values if they contain spaces or commas.
   </para>
________________________________________________________-->
   <para>
    如果一个<replaceable>options</replaceable>字符串被指定，它必须由一个逗号分隔的列表组成，列表中是一个或多个<replaceable>option</replaceable><literal>=</literal><replaceable>value</replaceable>对。可用的选项是：

    <itemizedlist  spacing="compact" mark="bullet">
     <listitem>
      <para>
       <literal>MaxWords</literal>、<literal>MinWords</literal>（整数）：这些数字决定了要输出的最长和最短标题。 默认值为 35 和 15。
      </para>
     </listitem>
     <listitem>
      <para>
       <literal>ShortWord</literal>（整数）：此长度或更短的单词将被删除在标题的开头和结尾，除非它们是查询词。默认值为3将删除常见的英语冠词。
      </para>
     </listitem>
     <listitem>
      <para>
       <literal>HighlightAll</literal> (布尔值)：如果 <literal>true</literal> 将整个文档用作标题，忽略前面三个参数。 默认值为 <literal>false</literal>。
      </para>
     </listitem>
     <listitem>
      <para>
       <literal>MaxFragments</literal>（整数）：要显示的最大文本片段数。默认值为零选择非基于片段的标题生成方法。大于零的值选择基于片段的标题生成（见下文）。
      </para>
     </listitem>
     <listitem>
      <para>
       <literal>StartSel</literal>、<literal>StopSel</literal>（strings）：用于分隔文档中出现的查询词的字符串，以将它们与其他摘录的单词区分开来。
       默认值为<quote><literal>&lt;b&gt;</literal></quote> 和 <quote><literal>&lt;/b&gt;</literal></quote>，它可以适用于HTML输出。
      </para>
     </listitem>
     <listitem>
      <para>
       <literal>FragmentDelimiter</literal> (string)：当显示多个片段时，片段会被这个字符串分隔。 默认值为 <quote><literal> ... </literal></quote>。
      </para>
     </listitem>
    </itemizedlist>

    这些选项名称不区分大小写。 如果字符串值包含空格或逗号，则必须用双引号引起来。
   </para>
<!-- pgdoc-cn_end sig_en=5dcbea979f5e91083be5f88522a0bbc1 -->

<!-- pgdoc-cn_start sig_en=a6590502f964eea7ae6dd3e19e273b38 sig_cn_org=None source=14.1 
   <para>
    In non-fragment-based headline
    generation, <function>ts_headline</function> locates matches for the
    given <replaceable class="parameter">query</replaceable> and chooses a
    single one to display, preferring matches that have more query words
    within the allowed headline length.
    In fragment-based headline generation, <function>ts_headline</function>
    locates the query matches and splits each match
    into <quote>fragments</quote> of no more than <literal>MaxWords</literal>
    words each, preferring fragments with more query words, and when
    possible <quote>stretching</quote> fragments to include surrounding
    words.  The fragment-based mode is thus more useful when the query
    matches span large sections of the document, or when it's desirable to
    display multiple matches.
    In either mode, if no query matches can be identified, then a single
    fragment of the first <literal>MinWords</literal> words in the document
    will be displayed.
   </para>
________________________________________________________-->
   <para>
    在基于非片段的标题生成中，<function>ts_headline</function>为给定的<replaceable class="parameter">query</replaceable>查找匹配项，并选择一个要显示的匹配项，优先选择在允许标题长度内具有更多查询词的匹配项。
    在基于片段的标题生成中，<function>ts_headline</function>定位查询匹配项，并将每个匹配项拆分为<quote>fragments</quote>，每个匹配项不超过<literal>MaxWords</literal>个词，首选具有更多查询词的片段，并且在可能的情况下<quote>拉伸</quote>片段以包括周围的词。 因此，当查询匹配跨越文档的大部分时，或者当需要显示多个匹配时，基于片段的模式更有用。 在任一模式下，如果无法识别查询匹配项，则将显示文档中前 <literal>MinWords</literal> 单词的单个片段。
   </para>
<!-- pgdoc-cn_end sig_en=a6590502f964eea7ae6dd3e19e273b38 -->

<!-- pgdoc-cn_start sig_en=86b1628f99dddd8b6e679f3de5f500f1 sig_cn_org=None source=14.1 
   <para>
    For example:

<screen>
SELECT ts_headline('english',
  'The most common type of search
is to find all documents containing given query terms
and return them in order of their similarity to the
query.',
  to_tsquery('english', 'query &amp; similarity'));
                        ts_headline
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 containing given &lt;b&gt;query&lt;/b&gt; terms                       +
 and return them in order of their &lt;b&gt;similarity&lt;/b&gt; to the+
 &lt;b&gt;query&lt;/b&gt;.

SELECT ts_headline('english',
  'Search terms may occur
many times in a document,
requiring ranking of the search matches to decide which
occurrences to display in the result.',
  to_tsquery('english', 'search &amp; term'),
  'MaxFragments=10, MaxWords=7, MinWords=3, StartSel=&lt;&lt;, StopSel=&gt;&gt;');
                        ts_headline
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 &lt;&lt;Search&gt;&gt; &lt;&lt;terms&gt;&gt; may occur                            +
 many times ... ranking of the &lt;&lt;search&gt;&gt; matches to decide
</screen>
   </para>
________________________________________________________-->
   <para>
    例如：

<screen>
SELECT ts_headline('english',
  'The most common type of search
is to find all documents containing given query terms
and return them in order of their similarity to the
query.',
  to_tsquery('english', 'query &amp; similarity'));
                        ts_headline
------------------------------------------------------------
 containing given &lt;b&gt;query&lt;/b&gt; terms                       +
 and return them in order of their &lt;b&gt;similarity&lt;/b&gt; to the+
 &lt;b&gt;query&lt;/b&gt;.

SELECT ts_headline('english',
  'Search terms may occur
many times in a document,
requiring ranking of the search matches to decide which
occurrences to display in the result.',
  to_tsquery('english', 'search &amp; term'),
  'MaxFragments=10, MaxWords=7, MinWords=3, StartSel=&lt;&lt;, StopSel=&gt;&gt;');
                        ts_headline
------------------------------------------------------------
 &lt;&lt;Search&gt;&gt; &lt;&lt;terms&gt;&gt; may occur                            +
 many times ... ranking of the &lt;&lt;search&gt;&gt; matches to decide
</screen>
   </para>
<!-- pgdoc-cn_end sig_en=86b1628f99dddd8b6e679f3de5f500f1 -->

<!-- pgdoc-cn_start sig_en=5f1d096b32f684130b0f6f8054f32545 sig_cn_org=None source=14.1 
   <para>
    <function>ts_headline</function> uses the original document, not a
    <type>tsvector</type> summary, so it can be slow and should be used with
    care.
   </para>
________________________________________________________-->
   <para>
    <function>ts_headline</function>使用原始文档，而不是一个<type>tsvector</type>摘要，因此它可能很慢并且应该被小心使用。
   </para>
<!-- pgdoc-cn_end sig_en=5f1d096b32f684130b0f6f8054f32545 -->

  </sect2>

 </sect1>

 <sect1 id="textsearch-features">
<!-- pgdoc-cn_start sig_en=aba3153433d0b24c87ecc49e4dea95c1 sig_cn_org=None source=14.1 
  <title>Additional Features</title>
________________________________________________________-->
  <title>额外特性</title>
<!-- pgdoc-cn_end sig_en=aba3153433d0b24c87ecc49e4dea95c1 -->

<!-- pgdoc-cn_start sig_en=7e58fcc5efaa84d87f56f82cdfc5b345 sig_cn_org=None source=14.1 
  <para>
   This section describes additional functions and operators that are
   useful in connection with text search.
  </para>
________________________________________________________-->
  <para>
   这一节描述在文本搜索中有用的一些额外的函数和操作符。
  </para>
<!-- pgdoc-cn_end sig_en=7e58fcc5efaa84d87f56f82cdfc5b345 -->

  <sect2 id="textsearch-manipulate-tsvector">
<!-- pgdoc-cn_start sig_en=cd285342ad44a702993c963d5a70b663 sig_cn_org=None source=14.1 
   <title>Manipulating Documents</title>
________________________________________________________-->
   <title>操纵文档</title>
<!-- pgdoc-cn_end sig_en=cd285342ad44a702993c963d5a70b663 -->

<!-- pgdoc-cn_start sig_en=7222e3eb040ab40065a293a3a6443ba5 sig_cn_org=None source=14.1 
   <para>
    <xref linkend="textsearch-parsing-documents"/> showed how raw textual
    documents can be converted into <type>tsvector</type> values.
    <productname>PostgreSQL</productname> also provides functions and
    operators that can be used to manipulate documents that are already
    in <type>tsvector</type> form.
   </para>
________________________________________________________-->
   <para>
    <xref linkend="textsearch-parsing-documents"/>展示了未经处理的文本文档如何被转换成<type>tsvector</type>值。<productname>PostgreSQL</productname>也提供了用于操纵已经为<type>tsvector</type>形式的文档的函数和操作符。
   </para>
<!-- pgdoc-cn_end sig_en=7222e3eb040ab40065a293a3a6443ba5 -->

   <variablelist>

    <varlistentry>

<!-- pgdoc-cn_start sig_en=8f5c0f5ccdc39a866a14df9f37f4073a sig_cn_org=None source=14.1 
     <term>
     <indexterm>
      <primary>tsvector concatenation</primary>
     </indexterm>

      <literal><type>tsvector</type> || <type>tsvector</type></literal>
     </term>
________________________________________________________-->
     <term>
     <indexterm>
      <primary>tsvector 连接</primary>
     </indexterm>

      <literal><type>tsvector</type> || <type>tsvector</type></literal>
     </term>
<!-- pgdoc-cn_end sig_en=8f5c0f5ccdc39a866a14df9f37f4073a -->

     <listitem>
<!-- pgdoc-cn_start sig_en=59f93b73af648b2b3157b6508fc9d3f8 sig_cn_org=None source=14.1 
      <para>
       The <type>tsvector</type> concatenation operator
       returns a vector which combines the lexemes and positional information
       of the two vectors given as arguments.  Positions and weight labels
       are retained during the concatenation.
       Positions appearing in the right-hand vector are offset by the largest
       position mentioned in the left-hand vector, so that the result is
       nearly equivalent to the result of performing <function>to_tsvector</function>
       on the concatenation of the two original document strings.  (The
       equivalence is not exact, because any stop-words removed from the
       end of the left-hand argument will not affect the result, whereas
       they would have affected the positions of the lexemes in the
       right-hand argument if textual concatenation were used.)
      </para>
________________________________________________________-->
      <para>
       <type>tsvector</type>连接操作符返回一个向量，它结合了作为参数给出的两个向量的词位和位置信息。位置和权重标签在连接期间被保留。出现在右手向量中的位置被使用左手向量中提到的最大位置进行偏移，这样结果几乎等于在两个原始文档字符串的连接上执行<function>to_tsvector</function>的结果（这种等价不是完全的，因为从左手参数的尾端移除的任何停用词将会影响结果，而如果文本连接被使用它们就影响了右手参数中的词位位置）。
      </para>
<!-- pgdoc-cn_end sig_en=59f93b73af648b2b3157b6508fc9d3f8 -->

<!-- pgdoc-cn_start sig_en=238c79afb795819681971be9f49fe02e sig_cn_org=None source=14.1 
      <para>
       One advantage of using concatenation in the vector form, rather than
       concatenating text before applying <function>to_tsvector</function>, is that
       you can use different configurations to parse different sections
       of the document.  Also, because the <function>setweight</function> function
       marks all lexemes of the given vector the same way, it is necessary
       to parse the text and do <function>setweight</function> before concatenating
       if you want to label different parts of the document with different
       weights.
      </para>
________________________________________________________-->
      <para>
       使用向量形式的连接而不是在应用<function>to_tsvector</function>之前连接文本的一个优点是你可以使用不同配置来解析文档的不同小节。此外，因为<function>setweight</function>函数按照相同的方式标记给定向量的所有词位，如果你想把文档的不同部分标注不同的权重，你就有必要解析文本并且在连接之前做<function>setweight</function>。
      </para>
<!-- pgdoc-cn_end sig_en=238c79afb795819681971be9f49fe02e -->
     </listitem>
    </varlistentry>

    <varlistentry>

<!-- pgdoc-cn_start sig_en=9280cc4d49adf5a3b411092af9ac811a sig_cn_org=None source=14.1 
     <term>
     <indexterm>
      <primary>setweight</primary>
     </indexterm>

      <literal>setweight(<replaceable class="parameter">vector</replaceable> <type>tsvector</type>, <replaceable class="parameter">weight</replaceable> <type>"char"</type>) returns <type>tsvector</type></literal>
     </term>
________________________________________________________-->
     <term>
     <indexterm>
      <primary>setweight</primary>
     </indexterm>

      <literal>setweight(<replaceable class="parameter">vector</replaceable> <type>tsvector</type>, <replaceable class="parameter">weight</replaceable> <type>"char"</type>) returns <type>tsvector</type></literal>
     </term>
<!-- pgdoc-cn_end sig_en=9280cc4d49adf5a3b411092af9ac811a -->

     <listitem>
<!-- pgdoc-cn_start sig_en=8fa989fd04a938df628cd7fda8c5cb1f sig_cn_org=None source=14.1 
      <para>
       <function>setweight</function> returns a copy of the input vector in which every
       position has been labeled with the given <replaceable>weight</replaceable>, either
       <literal>A</literal>, <literal>B</literal>, <literal>C</literal>, or
       <literal>D</literal>.  (<literal>D</literal> is the default for new
       vectors and as such is not displayed on output.)  These labels are
       retained when vectors are concatenated, allowing words from different
       parts of a document to be weighted differently by ranking functions.
      </para>
________________________________________________________-->
      <para>
       <function>setweight</function>返回输入向量的一个拷贝，其中每一个位置都被标注为给定的<replaceable>权重</replaceable>：<literal>A</literal>、<literal>B</literal>、<literal>C</literal>或<literal>D</literal>（<literal>D</literal>是新向量的默认值并且并不会被显示在输出上）。向量被连接时会保留这些标签，允许来自文档的不同部分的词被排名函数给予不同的权重。
      </para>
<!-- pgdoc-cn_end sig_en=8fa989fd04a938df628cd7fda8c5cb1f -->

<!-- pgdoc-cn_start sig_en=3cd860269f4f9ff9e707fda77c7ee4e3 sig_cn_org=None source=14.1 
      <para>
       Note that weight labels apply to <emphasis>positions</emphasis>, not
       <emphasis>lexemes</emphasis>.  If the input vector has been stripped of
       positions then <function>setweight</function> does nothing.
      </para>
________________________________________________________-->
      <para>
       注意权重标签是应用到<emphasis>位置</emphasis>而不是<emphasis>词位</emphasis>。如果输入向量已经被剥离了位置，则<function>setweight</function>什么也不会做。
      </para>
<!-- pgdoc-cn_end sig_en=3cd860269f4f9ff9e707fda77c7ee4e3 -->
     </listitem>
    </varlistentry>

    <varlistentry>
<!-- pgdoc-cn_start sig_en=73c43944063d017f604c59ef855755d5 sig_cn_org=None source=14.1 
     <term>
     <indexterm>
      <primary>length(tsvector)</primary>
     </indexterm>

      <literal>length(<replaceable class="parameter">vector</replaceable> <type>tsvector</type>) returns <type>integer</type></literal>
     </term>
________________________________________________________-->
     <term>
     <indexterm>
      <primary>length(tsvector)</primary>
     </indexterm>

      <literal>length(<replaceable class="parameter">vector</replaceable> <type>tsvector</type>) returns <type>integer</type></literal>
     </term>
<!-- pgdoc-cn_end sig_en=73c43944063d017f604c59ef855755d5 -->

     <listitem>
<!-- pgdoc-cn_start sig_en=48d680edd4b193253b3c8ce0a1ca06e5 sig_cn_org=None source=14.1 
      <para>
       Returns the number of lexemes stored in the vector.
      </para>
________________________________________________________-->
      <para>
       返回存储在向量中的词位数。
      </para>
<!-- pgdoc-cn_end sig_en=48d680edd4b193253b3c8ce0a1ca06e5 -->
     </listitem>
    </varlistentry>

    <varlistentry>

<!-- pgdoc-cn_start sig_en=587613177f7db8856908420ae0051400 sig_cn_org=None source=14.1 
     <term>
     <indexterm>
      <primary>strip</primary>
     </indexterm>

      <literal>strip(<replaceable class="parameter">vector</replaceable> <type>tsvector</type>) returns <type>tsvector</type></literal>
     </term>
________________________________________________________-->
     <term>
     <indexterm>
      <primary>strip</primary>
     </indexterm>

      <literal>strip(<replaceable class="parameter">vector</replaceable> <type>tsvector</type>) returns <type>tsvector</type></literal>
     </term>
<!-- pgdoc-cn_end sig_en=587613177f7db8856908420ae0051400 -->

     <listitem>
<!-- pgdoc-cn_start sig_en=defc4355f19f7fbd84c99d3e8ccff14f sig_cn_org=None source=14.1 
      <para>
       Returns a vector that lists the same lexemes as the given vector, but
       lacks any position or weight information.  The result is usually much
       smaller than an unstripped vector, but it is also less useful.
       Relevance ranking does not work as well on stripped vectors as
       unstripped ones.  Also,
       the <literal>&lt;-&gt;</literal> (FOLLOWED BY) <type>tsquery</type> operator
       will never match stripped input, since it cannot determine the
       distance between lexeme occurrences.
      </para>
________________________________________________________-->
      <para>
       返回一个向量，其中列出了和给定向量相同的词位，不过没有任何位置或者权重信息。其结果通常比未被剥离的向量小很多，但是用处也小很多。和未被剥离的向量一样，相关度排名在已剥离的向量上也不起作用。此外，<literal>&lt;-&gt;</literal>（FOLLOWED BY）<type>tsquery</type>操作符不会匹配已剥离的输入，因为它无法确定词位之间的距离。
      </para>
<!-- pgdoc-cn_end sig_en=defc4355f19f7fbd84c99d3e8ccff14f -->
     </listitem>

    </varlistentry>

   </variablelist>

<!-- pgdoc-cn_start sig_en=644be8f9cb1e9b0e99bfef9866078d11 sig_cn_org=None source=14.1 
   <para>
    A full list of <type>tsvector</type>-related functions is available
    in <xref linkend="textsearch-functions-table"/>.
   </para>
________________________________________________________-->
   <para>
    <xref linkend="textsearch-functions-table"/>中有<type>tsvector</type>相关函数的完整列表。
   </para>
<!-- pgdoc-cn_end sig_en=644be8f9cb1e9b0e99bfef9866078d11 -->

  </sect2>

  <sect2 id="textsearch-manipulate-tsquery">
<!-- pgdoc-cn_start sig_en=ee47795d08f3985506512bc40fd9bed4 sig_cn_org=None source=14.1 
   <title>Manipulating Queries</title>
________________________________________________________-->
   <title>操纵查询</title>
<!-- pgdoc-cn_end sig_en=ee47795d08f3985506512bc40fd9bed4 -->

<!-- pgdoc-cn_start sig_en=bd8d84370678f1056dd3b1cf1ae4c8a8 sig_cn_org=None source=14.1 
   <para>
    <xref linkend="textsearch-parsing-queries"/> showed how raw textual
    queries can be converted into <type>tsquery</type> values.
    <productname>PostgreSQL</productname> also provides functions and
    operators that can be used to manipulate queries that are already
    in <type>tsquery</type> form.
   </para>
________________________________________________________-->
   <para>
    <xref linkend="textsearch-parsing-queries"/>展示了未经处理的文本形式的查询如何被转换成<type>tsquery</type>值。<productname>PostgreSQL</productname>也提供了用于操纵已经是<type>tsquery</type>形式的查询的函数和操作符。
   </para>
<!-- pgdoc-cn_end sig_en=bd8d84370678f1056dd3b1cf1ae4c8a8 -->

   <variablelist>

    <varlistentry>

     <term>
      <literal><type>tsquery</type> &amp;&amp; <type>tsquery</type></literal>
     </term>

     <listitem>
<!-- pgdoc-cn_start sig_en=2fa22b3d28c2de998c0ea8ac015914a0 sig_cn_org=None source=14.1 
      <para>
       Returns the AND-combination of the two given queries.
      </para>
________________________________________________________-->
      <para>
       返回用 AND 结合的两个给定查询。
      </para>
<!-- pgdoc-cn_end sig_en=2fa22b3d28c2de998c0ea8ac015914a0 -->
     </listitem>

    </varlistentry>

    <varlistentry>

     <term>
      <literal><type>tsquery</type> || <type>tsquery</type></literal>
     </term>

     <listitem>
<!-- pgdoc-cn_start sig_en=ce2cca52eab0a75f0e809493445cdd3b sig_cn_org=None source=14.1 
      <para>
       Returns the OR-combination of the two given queries.
      </para>
________________________________________________________-->
      <para>
       返回用 OR 结合的两个给定查询。
      </para>
<!-- pgdoc-cn_end sig_en=ce2cca52eab0a75f0e809493445cdd3b -->
     </listitem>

    </varlistentry>

    <varlistentry>

     <term>
      <literal>!! <type>tsquery</type></literal>
     </term>

     <listitem>
<!-- pgdoc-cn_start sig_en=168792db9f1e6b8d28ccfa55d6174563 sig_cn_org=None source=14.1 
      <para>
       Returns the negation (NOT) of the given query.
      </para>
________________________________________________________-->
      <para>
       返回一个给定查询的反（NOT）。
      </para>
<!-- pgdoc-cn_end sig_en=168792db9f1e6b8d28ccfa55d6174563 -->
     </listitem>

    </varlistentry>

    <varlistentry>

     <term>
      <literal><type>tsquery</type> &lt;-&gt; <type>tsquery</type></literal>
     </term>

     <listitem>
<!-- pgdoc-cn_start sig_en=ed4431ab8391cd6bd256538bc5d38e24 sig_cn_org=None source=14.1 
      <para>
       Returns a query that searches for a match to the first given query
       immediately followed by a match to the second given query, using
       the <literal>&lt;-&gt;</literal> (FOLLOWED BY)
       <type>tsquery</type> operator.  For example:

<screen>
SELECT to_tsquery('fat') &lt;-&gt; to_tsquery('cat | rat');
          ?column?
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 'fat' &lt;-&gt; ( 'cat' | 'rat' )
</screen>
      </para>
________________________________________________________-->
      <para>
       返回一个查询，它用<literal>&lt;-&gt;</literal>（FOLLOWED BY）<type>tsquery</type>操作符搜索两个紧跟的匹配，第一个匹配符合第一个给定的查询而第二个匹配符合第二个给定的查询。例如：

<screen>
SELECT to_tsquery('fat') &lt;-&gt; to_tsquery('cat | rat');
          ?column?
----------------------------
 'fat' &lt;-&gt; ( 'cat' | 'rat' )
</screen>
      </para>
<!-- pgdoc-cn_end sig_en=ed4431ab8391cd6bd256538bc5d38e24 -->
     </listitem>

    </varlistentry>

    <varlistentry>

<!-- pgdoc-cn_start sig_en=9cc772f129f822f83cf6c3f708cca888 sig_cn_org=None source=14.1 
     <term>
     <indexterm>
      <primary>tsquery_phrase</primary>
     </indexterm>

      <literal>tsquery_phrase(<replaceable class="parameter">query1</replaceable> <type>tsquery</type>, <replaceable class="parameter">query2</replaceable> <type>tsquery</type> [, <replaceable class="parameter">distance</replaceable> <type>integer</type> ]) returns <type>tsquery</type></literal>
     </term>
________________________________________________________-->
     <term>
     <indexterm>
      <primary>tsquery_phrase</primary>
     </indexterm>

      <literal>tsquery_phrase(<replaceable class="parameter">query1</replaceable> <type>tsquery</type>, <replaceable class="parameter">query2</replaceable> <type>tsquery</type> [, <replaceable class="parameter">distance</replaceable> <type>integer</type> ]) returns <type>tsquery</type></literal>
     </term>
<!-- pgdoc-cn_end sig_en=9cc772f129f822f83cf6c3f708cca888 -->

     <listitem>
<!-- pgdoc-cn_start sig_en=c0e42cc069042e5817a2aa56af9cacff sig_cn_org=None source=14.1 
      <para>
       Returns a query that searches for a match to the first given query
       followed by a match to the second given query at a distance of exactly
       <replaceable>distance</replaceable> lexemes, using
       the <literal>&lt;<replaceable>N</replaceable>&gt;</literal>
       <type>tsquery</type> operator.  For example:

<screen>
SELECT tsquery_phrase(to_tsquery('fat'), to_tsquery('cat'), 10);
  tsquery_phrase
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 'fat' &lt;10&gt; 'cat'
</screen>
      </para>
________________________________________________________-->
      <para>
       返回一个查询，它使用<literal>&lt;<replaceable>N</replaceable>&gt;</literal> <type>tsquery</type>操作符搜索两个距离为<replaceable>distance</replaceable>个词位的匹配，第一个匹配符合第一个给定的查询而第二个匹配符合第二个给定的查询。例如：

<screen>
SELECT tsquery_phrase(to_tsquery('fat'), to_tsquery('cat'), 10);
  tsquery_phrase
------------------
 'fat' &lt;10&gt; 'cat'
</screen>
      </para>
<!-- pgdoc-cn_end sig_en=c0e42cc069042e5817a2aa56af9cacff -->
     </listitem>

    </varlistentry>

    <varlistentry>

<!-- pgdoc-cn_start sig_en=b7e17359cf8298226460cd91872da755 sig_cn_org=None source=14.1 
     <term>
     <indexterm>
      <primary>numnode</primary>
     </indexterm>

      <literal>numnode(<replaceable class="parameter">query</replaceable> <type>tsquery</type>) returns <type>integer</type></literal>
     </term>
________________________________________________________-->
     <term>
     <indexterm>
      <primary>numnode</primary>
     </indexterm>

      <literal>numnode(<replaceable class="parameter">query</replaceable> <type>tsquery</type>) returns <type>integer</type></literal>
     </term>
<!-- pgdoc-cn_end sig_en=b7e17359cf8298226460cd91872da755 -->

     <listitem>
<!-- pgdoc-cn_start sig_en=1fd322cf864b360c31a1b41f5a6a87be sig_cn_org=None source=14.1 
      <para>
       Returns the number of nodes (lexemes plus operators) in a
       <type>tsquery</type>. This function is useful
       to determine if the <replaceable>query</replaceable> is meaningful
       (returns &gt; 0), or contains only stop words (returns 0).
       Examples:

<screen>
SELECT numnode(plainto_tsquery('the any'));
NOTICE:  query contains only stopword(s) or doesn't contain lexeme(s), ignored
 numnode
-&minus;-&minus;-&minus;-&minus;-
       0

SELECT numnode('foo &amp; bar'::tsquery);
 numnode
-&minus;-&minus;-&minus;-&minus;-
       3
</screen>
      </para>
________________________________________________________-->
      <para>
       返回一个<type>tsquery</type>中的结点数（词位外加操作符）。要确定<replaceable>查询</replaceable>是否有意义或者是否只包含停用词时，这个函数有用，在前一种情况它返回 &gt; 0，后一种情况返回 0。例子：

<screen>
SELECT numnode(plainto_tsquery('the any'));
NOTICE:  query contains only stopword(s) or doesn't contain lexeme(s), ignored
 numnode
---------
       0

SELECT numnode('foo &amp; bar'::tsquery);
 numnode
---------
       3
</screen>
      </para>
<!-- pgdoc-cn_end sig_en=1fd322cf864b360c31a1b41f5a6a87be -->
     </listitem>
    </varlistentry>

    <varlistentry>

<!-- pgdoc-cn_start sig_en=f4b3343cf7bc8c56fd7d3251dc5c39ac sig_cn_org=None source=14.1 
     <term>
     <indexterm>
      <primary>querytree</primary>
     </indexterm>

      <literal>querytree(<replaceable class="parameter">query</replaceable> <type>tsquery</type>) returns <type>text</type></literal>
     </term>
________________________________________________________-->
     <term>
     <indexterm>
      <primary>querytree</primary>
     </indexterm>

      <literal>querytree(<replaceable class="parameter">query</replaceable> <type>tsquery</type>) returns <type>text</type></literal>
     </term>
<!-- pgdoc-cn_end sig_en=f4b3343cf7bc8c56fd7d3251dc5c39ac -->

     <listitem>
<!-- pgdoc-cn_start sig_en=d42a26da163c31007532155da66237ee sig_cn_org=None source=14.1 
      <para>
       Returns the portion of a <type>tsquery</type> that can be used for
       searching an index.  This function is useful for detecting
       unindexable queries, for example those containing only stop words
       or only negated terms.  For example:

<screen>
SELECT querytree(to_tsquery('defined'));
 querytree
-&minus;-&minus;-&minus;-&minus;-&minus;-
 'defin'

SELECT querytree(to_tsquery('!defined'));
 querytree
-&minus;-&minus;-&minus;-&minus;-&minus;-
 T
</screen>
      </para>
________________________________________________________-->
      <para>
       返回一个<type>tsquery</type>中可以被用来搜索一个索引的部分。这个函数可用来检测不可被索引的查询，例如那些只包含停用词或者只有否定术语的查询。例如：

<screen>
SELECT querytree(to_tsquery('defined'));
 querytree
-----------
 'defin'

SELECT querytree(to_tsquery('!defined'));
 querytree
-----------
 T
</screen>
      </para>
<!-- pgdoc-cn_end sig_en=d42a26da163c31007532155da66237ee -->
     </listitem>
    </varlistentry>

   </variablelist>

   <sect3 id="textsearch-query-rewriting">
<!-- pgdoc-cn_start sig_en=638484e59fc11fd5964c9af7b6cdce03 sig_cn_org=None source=14.1 
    <title>Query Rewriting</title>
________________________________________________________-->
    <title>查询重写</title>
<!-- pgdoc-cn_end sig_en=638484e59fc11fd5964c9af7b6cdce03 -->

<!-- pgdoc-cn_start sig_en=8adde04b932e89d9bcee729ecb577f1c sig_cn_org=None source=14.1 
    <indexterm zone="textsearch-query-rewriting">
     <primary>ts_rewrite</primary>
    </indexterm>
________________________________________________________-->
    <indexterm zone="textsearch-query-rewriting">
     <primary>ts_rewrite</primary>
    </indexterm>
<!-- pgdoc-cn_end sig_en=8adde04b932e89d9bcee729ecb577f1c -->

<!-- pgdoc-cn_start sig_en=b867245a131866c2254033d74e2db889 sig_cn_org=None source=14.1 
    <para>
     The <function>ts_rewrite</function> family of functions search a
     given <type>tsquery</type> for occurrences of a target
     subquery, and replace each occurrence with a
     substitute subquery.  In essence this operation is a
     <type>tsquery</type>-specific version of substring replacement.
     A target and substitute combination can be
     thought of as a <firstterm>query rewrite rule</firstterm>.  A collection
     of such rewrite rules can be a powerful search aid.
     For example, you can expand the search using synonyms
     (e.g., <literal>new york</literal>, <literal>big apple</literal>, <literal>nyc</literal>,
     <literal>gotham</literal>) or narrow the search to direct the user to some hot
     topic.  There is some overlap in functionality between this feature
     and thesaurus dictionaries (<xref linkend="textsearch-thesaurus"/>).
     However, you can modify a set of rewrite rules on-the-fly without
     reindexing, whereas updating a thesaurus requires reindexing to be
     effective.
    </para>
________________________________________________________-->
    <para>
     <function>ts_rewrite</function>函数族在一个给定的<type>tsquery</type>中搜索一个目标子查询的出现，并且将每一次出现替换成一个替补子查询。本质上这个操作就是一个<type>tsquery</type>版本的子串替换。一个目标和替补的组合可以被看成是一个<firstterm>查询重写规则</firstterm>。一个这类重写规则的集合可以是一个强大的搜索助手。例如，你可以使用同义词扩展搜索（如，<literal>new york</literal>、<literal>big apple</literal>、<literal>nyc</literal>、<literal>gotham</literal>），或者收缩搜索来将用户导向某些特点主题。在这个特性和分类词典（<xref linkend="textsearch-thesaurus"/>）有些功能重叠。但是，你可以随时修改一组重写规则而无需重新索引，而更新一个分类词典则要求进行重新索引才能生效。
    </para>
<!-- pgdoc-cn_end sig_en=b867245a131866c2254033d74e2db889 -->

    <variablelist>

     <varlistentry>

      <term>
       <literal>ts_rewrite (<replaceable class="parameter">query</replaceable> <type>tsquery</type>, <replaceable class="parameter">target</replaceable> <type>tsquery</type>, <replaceable class="parameter">substitute</replaceable> <type>tsquery</type>) returns <type>tsquery</type></literal>
      </term>

      <listitem>
<!-- pgdoc-cn_start sig_en=bc3b03fc0488dcfd082b1b9bfd847552 sig_cn_org=None source=14.1 
       <para>
        This form of <function>ts_rewrite</function> simply applies a single
        rewrite rule: <replaceable class="parameter">target</replaceable>
        is replaced by <replaceable class="parameter">substitute</replaceable>
        wherever it appears in <replaceable
        class="parameter">query</replaceable>.  For example:

<screen>
SELECT ts_rewrite('a &amp; b'::tsquery, 'a'::tsquery, 'c'::tsquery);
 ts_rewrite
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 'b' &amp; 'c'
</screen>
       </para>
________________________________________________________-->
       <para>
        这种形式的<function>ts_rewrite</function>简单地应用一个单一重写规则：不管<replaceable class="parameter">target</replaceable>出现在<replaceable class="parameter">query</replaceable>中的那个地方，它都被<replaceable class="parameter">substitute</replaceable>替代。例如：

<screen>
SELECT ts_rewrite('a &amp; b'::tsquery, 'a'::tsquery, 'c'::tsquery);
 ts_rewrite
------------
 'b' &amp; 'c'
</screen>
       </para>
<!-- pgdoc-cn_end sig_en=bc3b03fc0488dcfd082b1b9bfd847552 -->
      </listitem>
     </varlistentry>

     <varlistentry>

      <term>
       <literal>ts_rewrite (<replaceable class="parameter">query</replaceable> <type>tsquery</type>, <replaceable class="parameter">select</replaceable> <type>text</type>) returns <type>tsquery</type></literal>
      </term>

      <listitem>
<!-- pgdoc-cn_start sig_en=8525898a92d2aaee523703a6db52e5a9 sig_cn_org=None source=14.1 
       <para>
        This form of <function>ts_rewrite</function> accepts a starting
        <replaceable>query</replaceable> and an SQL <replaceable>select</replaceable> command, which
        is given as a text string.  The <replaceable>select</replaceable> must yield two
        columns of <type>tsquery</type> type.  For each row of the
        <replaceable>select</replaceable> result, occurrences of the first column value
        (the target) are replaced by the second column value (the substitute)
        within the current <replaceable>query</replaceable> value.  For example:

<screen>
CREATE TABLE aliases (t tsquery PRIMARY KEY, s tsquery);
INSERT INTO aliases VALUES('a', 'c');

SELECT ts_rewrite('a &amp; b'::tsquery, 'SELECT t,s FROM aliases');
 ts_rewrite
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 'b' &amp; 'c'
</screen>
       </para>
________________________________________________________-->
       <para>
        这种形式的<function>ts_rewrite</function>接受一个开始<replaceable>query</replaceable>和一个 SQL <replaceable>select</replaceable>命令，它们以一个文本字符串的形式给出。<replaceable>select</replaceable>必须得到<type>tsquery</type>类型的两列。对于<replaceable>select</replaceable>结果的每一行，在当前<replaceable>query</replaceable>值中出现的第一列值（目标）被第二列值（替补）所替换。例如：

<screen>
CREATE TABLE aliases (t tsquery PRIMARY KEY, s tsquery);
INSERT INTO aliases VALUES('a', 'c');

SELECT ts_rewrite('a &amp; b'::tsquery, 'SELECT t,s FROM aliases');
 ts_rewrite
------------
 'b' &amp; 'c'
</screen>
       </para>
<!-- pgdoc-cn_end sig_en=8525898a92d2aaee523703a6db52e5a9 -->

<!-- pgdoc-cn_start sig_en=6b97fcd5b6175599c32099c4a6fab22b sig_cn_org=None source=14.1 
       <para>
        Note that when multiple rewrite rules are applied in this way,
        the order of application can be important; so in practice you will
        want the source query to <literal>ORDER BY</literal> some ordering key.
       </para>
________________________________________________________-->
       <para>
        注意当多个重写规则被以这种方式应用时，应用的顺序很重要；因此在实际中你会要求源查询按某些排序键<literal>ORDER BY</literal>。
       </para>
<!-- pgdoc-cn_end sig_en=6b97fcd5b6175599c32099c4a6fab22b -->
      </listitem>
     </varlistentry>

    </variablelist>

<!-- pgdoc-cn_start sig_en=7001cf82654cd5278ebe7cf1bbe186bf sig_cn_org=39e4e769727bb4962f0be67093c6c9dd source=15.7 
    <para>
     Let's consider a real-life astronomical example. We'll expand query
     <literal>supernovae</literal> using table-driven rewriting rules:

<screen>
CREATE TABLE aliases (t tsquery primary key, s tsquery);
INSERT INTO aliases VALUES(to_tsquery('supernovae'), to_tsquery('supernovae|sn'));

SELECT ts_rewrite(to_tsquery('supernovae &amp; crab'), 'SELECT * FROM aliases');
           ts_rewrite
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 'crab' &amp; ( 'supernova' | 'sn' )
</screen>

     We can change the rewriting rules just by updating the table:

<screen>
UPDATE aliases
SET s = to_tsquery('supernovae|sn &amp; !nebulae')
WHERE t = to_tsquery('supernovae');

SELECT ts_rewrite(to_tsquery('supernovae &amp; crab'), 'SELECT * FROM aliases');
                 ts_rewrite
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 'crab' &amp; ( 'supernova' | 'sn' &amp; !'nebula' )
</screen>
    </para>
________________________________________________________-->
    <para>
     让我们考虑一个现实生活中的天文学例子。我们将使用基于表的重写规则扩展查询<literal>supernovae</literal>：

<screen>
CREATE TABLE aliases (t tsquery primary key, s tsquery);
INSERT INTO aliases VALUES(to_tsquery('supernovae'), to_tsquery('supernovae|sn'));

SELECT ts_rewrite(to_tsquery('supernovae &amp; crab'), 'SELECT * FROM aliases');
           ts_rewrite
---------------------------------
 'crab' &amp; ( 'supernova' | 'sn' )
</screen>

     我们可以通过更新表来更改重写规则：

<screen>
UPDATE aliases
SET s = to_tsquery('supernovae|sn &amp; !nebulae')
WHERE t = to_tsquery('supernovae');

SELECT ts_rewrite(to_tsquery('supernovae &amp; crab'), 'SELECT * FROM aliases');
                 ts_rewrite
---------------------------------------------
 'crab' &amp; ( 'supernova' | 'sn' &amp; !'nebula' )
</screen>
    </para>
<!-- pgdoc-cn_end sig_en=7001cf82654cd5278ebe7cf1bbe186bf -->

<!-- pgdoc-cn_start sig_en=800ca5518a2758e2f317ea296144cdbd sig_cn_org=None source=14.1 
    <para>
     Rewriting can be slow when there are many rewriting rules, since it
     checks every rule for a possible match. To filter out obvious non-candidate
     rules we can use the containment operators for the <type>tsquery</type>
     type. In the example below, we select only those rules which might match
     the original query:

<screen>
SELECT ts_rewrite('a &amp; b'::tsquery,
                  'SELECT t,s FROM aliases WHERE ''a &amp; b''::tsquery @&gt; t');
 ts_rewrite
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 'b' &amp; 'c'
</screen>
    </para>
________________________________________________________-->
    <para>
     当有很多重写规则时，重写可能会很慢，因为它要为为每一个可能的匹配检查每一条规则。要过滤掉明显不符合的规则，我们可以为<type>tsquery</type>类型使用包含操作符。在下面的例子中，我们只选择那些可能匹配原始查询的规则：

<screen>
SELECT ts_rewrite('a &amp; b'::tsquery,
                  'SELECT t,s FROM aliases WHERE ''a &amp; b''::tsquery @&gt; t');
 ts_rewrite
------------
 'b' &amp; 'c'
</screen>
    </para>
<!-- pgdoc-cn_end sig_en=800ca5518a2758e2f317ea296144cdbd -->

   </sect3>

  </sect2>

  <sect2 id="textsearch-update-triggers">
<!-- pgdoc-cn_start sig_en=a22c024f2edac7f85c7eafd01cd49dcd sig_cn_org=None source=14.1 
   <title>Triggers for Automatic Updates</title>
________________________________________________________-->
   <title>用于自动更新的触发器</title>
<!-- pgdoc-cn_end sig_en=a22c024f2edac7f85c7eafd01cd49dcd -->

<!-- pgdoc-cn_start sig_en=cdfbcbc01d3471acae5d864e6a9c486c sig_cn_org=None source=14.1 
   <indexterm>
    <primary>trigger</primary>
    <secondary>for updating a derived tsvector column</secondary>
   </indexterm>
________________________________________________________-->
   <indexterm>
    <primary>触发器</primary>
    <secondary>用于更新一个派生的 tsvector 列</secondary>
   </indexterm>
<!-- pgdoc-cn_end sig_en=cdfbcbc01d3471acae5d864e6a9c486c -->

   <note>
<!-- pgdoc-cn_start sig_en=2c8bc937fb7fa651f196b540a9272a7e sig_cn_org=None source=14.1 
    <para>
     The method described in this section has been obsoleted by the use of
     stored generated columns, as described in <xref
     linkend="textsearch-tables-index"/>.
    </para>
________________________________________________________-->
    <para>
     本节中描述的方法已被使用存储生成的列所淘汰，如 <xref linkend="textsearch-tables-index"/>中所述。
    </para>
<!-- pgdoc-cn_end sig_en=2c8bc937fb7fa651f196b540a9272a7e -->
   </note>

<!-- pgdoc-cn_start sig_en=a35df7ad319295af4efab6f3711517b6 sig_cn_org=None source=14.1 
   <para>
    When using a separate column to store the <type>tsvector</type> representation
    of your documents, it is necessary to create a trigger to update the
    <type>tsvector</type> column when the document content columns change.
    Two built-in trigger functions are available for this, or you can write
    your own.
   </para>
________________________________________________________-->
   <para>
    当使用一个单独的列来存储你的文档的<type>tsvector</type>表示时，有必要创建一个触发器在文档内容列改变时更新<type>tsvector</type>列。两个内建触发器函数可以用于这个目的，或者你可以编写你自己的触发器函数。
   </para>
<!-- pgdoc-cn_end sig_en=a35df7ad319295af4efab6f3711517b6 -->

<!-- pgdoc-cn_start sig_en=ad3a8212d9797ba7572f0cf8c0cda559 sig_cn_org=None source=14.1 
<synopsis>
tsvector_update_trigger(<replaceable class="parameter">tsvector_column_name</replaceable>,&zwsp; <replaceable class="parameter">config_name</replaceable>, <replaceable class="parameter">text_column_name</replaceable> <optional>, ... </optional>)
tsvector_update_trigger_column(<replaceable class="parameter">tsvector_column_name</replaceable>,&zwsp; <replaceable class="parameter">config_column_name</replaceable>, <replaceable class="parameter">text_column_name</replaceable> <optional>, ... </optional>)
</synopsis>
________________________________________________________-->
<synopsis>
tsvector_update_trigger(<replaceable class="parameter">tsvector_column_name</replaceable>,&zwsp; <replaceable class="parameter">config_name</replaceable>, <replaceable class="parameter">text_column_name</replaceable> <optional>, ... </optional>)
tsvector_update_trigger_column(<replaceable class="parameter">tsvector_column_name</replaceable>,&zwsp; <replaceable class="parameter">config_column_name</replaceable>, <replaceable class="parameter">text_column_name</replaceable> <optional>, ... </optional>)
</synopsis>
<!-- pgdoc-cn_end sig_en=ad3a8212d9797ba7572f0cf8c0cda559 -->

<!-- pgdoc-cn_start sig_en=51f6bf18f7f1d6c9b55b60ac8733ccbc sig_cn_org=de9992d133f60aefae67ae591ff3d9c4 source=15.7 
   <para>
    These trigger functions automatically compute a <type>tsvector</type>
    column from one or more textual columns, under the control of
    parameters specified in the <command>CREATE TRIGGER</command> command.
    An example of their use is:

<screen>
CREATE TABLE messages (
    title       text,
    body        text,
    tsv         tsvector
);

CREATE TRIGGER tsvectorupdate BEFORE INSERT OR UPDATE
ON messages FOR EACH ROW EXECUTE FUNCTION
tsvector_update_trigger(tsv, 'pg_catalog.english', title, body);

INSERT INTO messages VALUES('title here', 'the body text is here');

SELECT * FROM messages;
   title    |         body          |            tsv
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 title here | the body text is here | 'bodi':4 'text':5 'titl':1

SELECT title, body FROM messages WHERE tsv @@ to_tsquery('title &amp; body');
   title    |         body
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 title here | the body text is here
</screen>

    Having created this trigger, any change in <structfield>title</structfield> or
    <structfield>body</structfield> will automatically be reflected into
    <structfield>tsv</structfield>, without the application having to worry about it.
   </para>
________________________________________________________-->
   <para>
    这些触发函数会自动从一个或多个文本列中计算出一个<type>tsvector</type>列，
    在<command>CREATE TRIGGER</command>命令指定的参数控制下。它们的使用示例是：

<screen>
CREATE TABLE messages (
    title       text,
    body        text,
    tsv         tsvector
);

CREATE TRIGGER tsvectorupdate BEFORE INSERT OR UPDATE
ON messages FOR EACH ROW EXECUTE FUNCTION
tsvector_update_trigger(tsv, 'pg_catalog.english', title, body);

INSERT INTO messages VALUES('title here', 'the body text is here');

SELECT * FROM messages;
   title    |         body          |            tsv
------------+-----------------------+----------------------------
 title here | the body text is here | 'bodi':4 'text':5 'titl':1

SELECT title, body FROM messages WHERE tsv @@ to_tsquery('title &amp; body');
   title    |         body
------------+-----------------------
 title here | the body text is here
</screen>

    创建了这个触发器后，任何<structfield>title</structfield>或
    <structfield>body</structfield>的更改都会自动反映到
    <structfield>tsv</structfield>中，应用程序无需担心这一点。
   </para>
<!-- pgdoc-cn_end sig_en=51f6bf18f7f1d6c9b55b60ac8733ccbc -->

<!-- pgdoc-cn_start sig_en=69bcfda8bad6464d10495c4a4a2ba140 sig_cn_org=None source=14.1 
   <para>
    The first trigger argument must be the name of the <type>tsvector</type>
    column to be updated.  The second argument specifies the text search
    configuration to be used to perform the conversion.  For
    <function>tsvector_update_trigger</function>, the configuration name is simply
    given as the second trigger argument.  It must be schema-qualified as
    shown above, so that the trigger behavior will not change with changes
    in <varname>search_path</varname>.  For
    <function>tsvector_update_trigger_column</function>, the second trigger argument
    is the name of another table column, which must be of type
    <type>regconfig</type>.  This allows a per-row selection of configuration
    to be made.  The remaining argument(s) are the names of textual columns
    (of type <type>text</type>, <type>varchar</type>, or <type>char</type>).  These
    will be included in the document in the order given.  NULL values will
    be skipped (but the other columns will still be indexed).
   </para>
________________________________________________________-->
   <para>
    第一个触发器参数必须是要被更新的<type>tsvector</type>列的名字。第二个参数指定要被用来执行转换的文本搜索配置。对于<function>tsvector_update_trigger</function>，配置名被简单地用第二个触发器参数给出。如上所示，它必须是模式限定的，因此该触发器行为不会因为<varname>search_path</varname>中的改变而改变。对于<function>tsvector_update_trigger_column</function>，第二个触发器参数是另一个表列的名称，它必须是类型<type>regconfig</type>。这允许做一种逐行的配置选择。剩下的参数是文本列的名称（类型为<type>text</type>、<type>varchar</type>或<type>char</type>）。它们将按给定的顺序被包括在文档中。NULL 值将被跳过（但是其他列仍将被索引）。
   </para>
<!-- pgdoc-cn_end sig_en=69bcfda8bad6464d10495c4a4a2ba140 -->

<!-- pgdoc-cn_start sig_en=a410d0d87921cfc7aa2e0b2aa9214cbb sig_cn_org=None source=14.1 
   <para>
    A limitation of these built-in triggers is that they treat all the
    input columns alike.  To process columns differently &mdash; for
    example, to weight title differently from body &mdash; it is necessary
    to write a custom trigger.  Here is an example using
    <application>PL/pgSQL</application> as the trigger language:

<programlisting>
CREATE FUNCTION messages_trigger() RETURNS trigger AS $$
begin
  new.tsv :=
     setweight(to_tsvector('pg_catalog.english', coalesce(new.title,'')), 'A') ||
     setweight(to_tsvector('pg_catalog.english', coalesce(new.body,'')), 'D');
  return new;
end
$$ LANGUAGE plpgsql;

CREATE TRIGGER tsvectorupdate BEFORE INSERT OR UPDATE
    ON messages FOR EACH ROW EXECUTE FUNCTION messages_trigger();
</programlisting>
   </para>
________________________________________________________-->
   <para>
    这些内建触发器的一个限制是它们将所有输入列同样对待。要对列进行不同的处理 &mdash; 例如，使标题的权重和正文的不同 &mdash; 就需要编写一个自定义触发器。下面是用<application>PL/pgSQL</application>作为触发器语言的一个例子：

<programlisting>
CREATE FUNCTION messages_trigger() RETURNS trigger AS $$
begin
  new.tsv :=
     setweight(to_tsvector('pg_catalog.english', coalesce(new.title,'')), 'A') ||
     setweight(to_tsvector('pg_catalog.english', coalesce(new.body,'')), 'D');
  return new;
end
$$ LANGUAGE plpgsql;

CREATE TRIGGER tsvectorupdate BEFORE INSERT OR UPDATE
    ON messages FOR EACH ROW EXECUTE FUNCTION messages_trigger();
</programlisting>
   </para>
<!-- pgdoc-cn_end sig_en=a410d0d87921cfc7aa2e0b2aa9214cbb -->

<!-- pgdoc-cn_start sig_en=c57cdb519da038f14ca94f5c67399930 sig_cn_org=b919cc79e42012201205919a03dac2c9 source=15.7 
   <para>
    Keep in mind that it is important to specify the configuration name
    explicitly when creating <type>tsvector</type> values inside triggers,
    so that the column's contents will not be affected by changes to
    <varname>default_text_search_config</varname>.  Failure to do this is likely to
    lead to problems such as search results changing after a dump and restore.
   </para>
________________________________________________________-->
   <para>
    要记住，在触发器中创建<type>tsvector</type>值时，明确指定配置名称是很重要的，
    这样列的内容就不会受到<varname>default_text_search_config</varname>更改的影响。
    如果不这样做，很可能会导致问题，比如在转储和恢复后搜索结果发生变化。
</para>
<!-- pgdoc-cn_end sig_en=c57cdb519da038f14ca94f5c67399930 -->

  </sect2>

  <sect2 id="textsearch-statistics">
<!-- pgdoc-cn_start sig_en=1d1150f5c3205fd9a23bc69e27805dd0 sig_cn_org=None source=14.1 
   <title>Gathering Document Statistics</title>
________________________________________________________-->
   <title>收集文档统计数据</title>
<!-- pgdoc-cn_end sig_en=1d1150f5c3205fd9a23bc69e27805dd0 -->

<!-- pgdoc-cn_start sig_en=6bdca6acb8386c0d564d09c56f77131b sig_cn_org=None source=14.1 
   <indexterm>
    <primary>ts_stat</primary>
   </indexterm>
________________________________________________________-->
   <indexterm>
    <primary>ts_stat</primary>
   </indexterm>
<!-- pgdoc-cn_end sig_en=6bdca6acb8386c0d564d09c56f77131b -->

<!-- pgdoc-cn_start sig_en=156217748bc4352627570fb07c1cca67 sig_cn_org=None source=14.1 
   <para>
    The function <function>ts_stat</function> is useful for checking your
    configuration and for finding stop-word candidates.
   </para>
________________________________________________________-->
   <para>
    <function>ts_stat</function>被用于检查你的配置以及寻找候选的停用词。
   </para>
<!-- pgdoc-cn_end sig_en=156217748bc4352627570fb07c1cca67 -->

<!-- pgdoc-cn_start sig_en=fcd9d0c049d40d1c3e22989350508589 sig_cn_org=None source=14.1 
<synopsis>
ts_stat(<replaceable class="parameter">sqlquery</replaceable> <type>text</type>, <optional> <replaceable class="parameter">weights</replaceable> <type>text</type>, </optional>
        OUT <replaceable class="parameter">word</replaceable> <type>text</type>, OUT <replaceable class="parameter">ndoc</replaceable> <type>integer</type>,
        OUT <replaceable class="parameter">nentry</replaceable> <type>integer</type>) returns <type>setof record</type>
</synopsis>
________________________________________________________-->
<synopsis>
ts_stat(<replaceable class="parameter">sqlquery</replaceable> <type>text</type>, <optional> <replaceable class="parameter">weights</replaceable> <type>text</type>, </optional>
        OUT <replaceable class="parameter">word</replaceable> <type>text</type>, OUT <replaceable class="parameter">ndoc</replaceable> <type>integer</type>,
        OUT <replaceable class="parameter">nentry</replaceable> <type>integer</type>) returns <type>setof record</type>
</synopsis>
<!-- pgdoc-cn_end sig_en=fcd9d0c049d40d1c3e22989350508589 -->

<!-- pgdoc-cn_start sig_en=4e3b42f058ce419870484d86952f254e sig_cn_org=None source=14.1 
   <para>
    <replaceable>sqlquery</replaceable> is a text value containing an SQL
    query which must return a single <type>tsvector</type> column.
    <function>ts_stat</function> executes the query and returns statistics about
    each distinct lexeme (word) contained in the <type>tsvector</type>
    data.  The columns returned are

    <itemizedlist  spacing="compact" mark="bullet">
     <listitem>
      <para>
       <replaceable>word</replaceable> <type>text</type> &mdash; the value of a lexeme
      </para>
     </listitem>
     <listitem>
      <para>
       <replaceable>ndoc</replaceable> <type>integer</type> &mdash; number of documents
       (<type>tsvector</type>s) the word occurred in
      </para>
     </listitem>
     <listitem>
      <para>
       <replaceable>nentry</replaceable> <type>integer</type> &mdash; total number of
       occurrences of the word
      </para>
     </listitem>
    </itemizedlist>

    If <replaceable>weights</replaceable> is supplied, only occurrences
    having one of those weights are counted.
   </para>
________________________________________________________-->
   <para>
    <replaceable>sqlquery</replaceable>是一个文本值，它包含一个必须返回单一<type>tsvector</type>列的 SQL 查询。<function>ts_stat</function>执行该查询并返回有关包含在该<type>tsvector</type>数据中的每一个可区分词位（词）的统计数据。返回的列是：

    <itemizedlist  spacing="compact" mark="bullet">
     <listitem>
      <para>
       <replaceable>word</replaceable> <type>text</type> &mdash; 一个词位的值
      </para>
     </listitem>
     <listitem>
      <para>
       <replaceable>ndoc</replaceable> <type>integer</type> &mdash; 词出现过的文档（<type>tsvector</type>）的数量
      </para>
     </listitem>
     <listitem>
      <para>
       <replaceable>nentry</replaceable> <type>integer</type> &mdash; 词出现的总次数
      </para>
     </listitem>
    </itemizedlist>

    如果提供了<replaceable>权重</replaceable>，只有具有其中之一权重的出现才被计算在内。
   </para>
<!-- pgdoc-cn_end sig_en=4e3b42f058ce419870484d86952f254e -->

<!-- pgdoc-cn_start sig_en=d87d42ffd98e4cef7ef86321d97a3557 sig_cn_org=None source=14.1 
   <para>
    For example, to find the ten most frequent words in a document collection:

<programlisting>
SELECT * FROM ts_stat('SELECT vector FROM apod')
ORDER BY nentry DESC, ndoc DESC, word
LIMIT 10;
</programlisting>

    The same, but counting only word occurrences with weight <literal>A</literal>
    or <literal>B</literal>:

<programlisting>
SELECT * FROM ts_stat('SELECT vector FROM apod', 'ab')
ORDER BY nentry DESC, ndoc DESC, word
LIMIT 10;
</programlisting>
   </para>
________________________________________________________-->
   <para>
    例如，要在一个文档集合中查找十个最频繁的词：

<programlisting>
SELECT * FROM ts_stat('SELECT vector FROM apod')
ORDER BY nentry DESC, ndoc DESC, word
LIMIT 10;
</programlisting>

    同样的要求，但是只计算以权重<literal>A</literal>或<literal>B</literal>出现的次数：

<programlisting>
SELECT * FROM ts_stat('SELECT vector FROM apod', 'ab')
ORDER BY nentry DESC, ndoc DESC, word
LIMIT 10;
</programlisting>
   </para>
<!-- pgdoc-cn_end sig_en=d87d42ffd98e4cef7ef86321d97a3557 -->

  </sect2>

 </sect1>

 <sect1 id="textsearch-parsers">
<!-- pgdoc-cn_start sig_en=a42673cc1d8e1024187ba49ed2c6ac3c sig_cn_org=None source=14.1 
  <title>Parsers</title>
________________________________________________________-->
  <title>解析器</title>
<!-- pgdoc-cn_end sig_en=a42673cc1d8e1024187ba49ed2c6ac3c -->

<!-- pgdoc-cn_start sig_en=181b570d4f624679637602797c58da0c sig_cn_org=None source=14.1 
  <para>
   Text search parsers are responsible for splitting raw document text
   into <firstterm>tokens</firstterm> and identifying each token's type, where
   the set of possible types is defined by the parser itself.
   Note that a parser does not modify the text at all &mdash; it simply
   identifies plausible word boundaries.  Because of this limited scope,
   there is less need for application-specific custom parsers than there is
   for custom dictionaries.  At present <productname>PostgreSQL</productname>
   provides just one built-in parser, which has been found to be useful for a
   wide range of applications.
  </para>
________________________________________________________-->
  <para>
   文本搜索解析器负责把未处理的文档文本划分成<firstterm>记号</firstterm>并且标识每一个记号的类型，而可能的类型集合由解析器本身定义。注意一个解析器完全不会修改文本 &mdash; 它简单地标识看似有理的词边界。因为这种有限的视野，对于应用相关的自定义解析器的需求就没有自定义字典那么强烈。目前<productname>PostgreSQL</productname>只提供了一种内建解析器，它已经被证实对很多种应用都适用。
  </para>
<!-- pgdoc-cn_end sig_en=181b570d4f624679637602797c58da0c -->

<!-- pgdoc-cn_start sig_en=bcb42dc6604398377ca1d8c5fecdadc0 sig_cn_org=None source=14.1 
  <para>
   The built-in parser is named <literal>pg_catalog.default</literal>.
   It recognizes 23 token types, shown in <xref linkend="textsearch-default-parser"/>.
  </para>
________________________________________________________-->
  <para>
   内建解析器被称为<literal>pg_catalog.default</literal>。它识别 23 种记号类型，如<xref linkend="textsearch-default-parser"/>所示。
  </para>
<!-- pgdoc-cn_end sig_en=bcb42dc6604398377ca1d8c5fecdadc0 -->

  <table id="textsearch-default-parser">
<!-- pgdoc-cn_start sig_en=90be513caaf39061f526f6b526beb68f sig_cn_org=None source=14.1 
   <title>Default Parser's Token Types</title>
________________________________________________________-->
   <title>默认解析器的记号类型</title>
<!-- pgdoc-cn_end sig_en=90be513caaf39061f526f6b526beb68f -->
   <tgroup cols="3">
    <colspec colname="col1" colwidth="2*"/>
    <colspec colname="col2" colwidth="2*"/>
    <colspec colname="col3" colwidth="3*"/>
    <thead>
<!-- pgdoc-cn_start sig_en=57d63ca304fa3d92e5bdfc876f52af0c sig_cn_org=None source=14.1 
     <row>
      <entry>Alias</entry>
      <entry>Description</entry>
      <entry>Example</entry>
     </row>
________________________________________________________-->
     <row>
      <entry>别名</entry>
      <entry>描述</entry>
      <entry>例子</entry>
     </row>
<!-- pgdoc-cn_end sig_en=57d63ca304fa3d92e5bdfc876f52af0c -->
    </thead>
    <tbody>
<!-- pgdoc-cn_start sig_en=6960ee054c3be2fc5f5e33b75cbdbd42 sig_cn_org=None source=14.1 
     <row>
      <entry><literal>asciiword</literal></entry>
      <entry>Word, all ASCII letters</entry>
      <entry><literal>elephant</literal></entry>
     </row>
________________________________________________________-->
     <row>
      <entry><literal>asciiword</literal></entry>
      <entry>单词，所有 ASCII 字母</entry>
      <entry><literal>elephant</literal></entry>
     </row>
<!-- pgdoc-cn_end sig_en=6960ee054c3be2fc5f5e33b75cbdbd42 -->
<!-- pgdoc-cn_start sig_en=6d25fea63159edb7d1c2e4bf08e700f6 sig_cn_org=None source=14.1 
     <row>
      <entry><literal>word</literal></entry>
      <entry>Word, all letters</entry>
      <entry><literal>ma&ntilde;ana</literal></entry>
     </row>
________________________________________________________-->
     <row>
      <entry><literal>word</literal></entry>
      <entry>单词，所有字母</entry>
      <entry><literal>ma&ntilde;ana</literal></entry>
     </row>
<!-- pgdoc-cn_end sig_en=6d25fea63159edb7d1c2e4bf08e700f6 -->
<!-- pgdoc-cn_start sig_en=e520591fd6758def2a0f813f8962d415 sig_cn_org=None source=14.1 
     <row>
      <entry><literal>numword</literal></entry>
      <entry>Word, letters and digits</entry>
      <entry><literal>beta1</literal></entry>
     </row>
________________________________________________________-->
     <row>
      <entry><literal>numword</literal></entry>
      <entry>单词，字母和数字</entry>
      <entry><literal>beta1</literal></entry>
     </row>
<!-- pgdoc-cn_end sig_en=e520591fd6758def2a0f813f8962d415 -->
<!-- pgdoc-cn_start sig_en=a912296a73d450575c4dcc21d22bafb2 sig_cn_org=None source=14.1 
     <row>
      <entry><literal>asciihword</literal></entry>
      <entry>Hyphenated word, all ASCII</entry>
      <entry><literal>up-to-date</literal></entry>
     </row>
________________________________________________________-->
     <row>
      <entry><literal>asciihword</literal></entry>
      <entry>带连字符的单词，所有 ASCII</entry>
      <entry><literal>up-to-date</literal></entry>
     </row>
<!-- pgdoc-cn_end sig_en=a912296a73d450575c4dcc21d22bafb2 -->
<!-- pgdoc-cn_start sig_en=9ae7f23fb3dcbcfc44f2ff412d5180cb sig_cn_org=None source=14.1 
     <row>
      <entry><literal>hword</literal></entry>
      <entry>Hyphenated word, all letters</entry>
      <entry><literal>l&oacute;gico-matem&aacute;tica</literal></entry>
     </row>
________________________________________________________-->
     <row>
      <entry><literal>hword</literal></entry>
      <entry>带连字符的单词，所有字母</entry>
      <entry><literal>l&oacute;gico-matem&aacute;tica</literal></entry>
     </row>
<!-- pgdoc-cn_end sig_en=9ae7f23fb3dcbcfc44f2ff412d5180cb -->
<!-- pgdoc-cn_start sig_en=a4df715ebed4bbaac5c6339b542242f3 sig_cn_org=None source=14.1 
     <row>
      <entry><literal>numhword</literal></entry>
      <entry>Hyphenated word, letters and digits</entry>
      <entry><literal>postgresql-beta1</literal></entry>
     </row>
________________________________________________________-->
     <row>
      <entry><literal>numhword</literal></entry>
      <entry>带连字符的单词，字母和数字</entry>
      <entry><literal>postgresql-beta1</literal></entry>
     </row>
<!-- pgdoc-cn_end sig_en=a4df715ebed4bbaac5c6339b542242f3 -->
<!-- pgdoc-cn_start sig_en=ccd72980888cd002cb23663a4d95c555 sig_cn_org=None source=14.1 
     <row>
      <entry><literal>hword_asciipart</literal></entry>
      <entry>Hyphenated word part, all ASCII</entry>
      <entry><literal>postgresql</literal> in the context <literal>postgresql-beta1</literal></entry>
     </row>
________________________________________________________-->
     <row>
      <entry><literal>hword_asciipart</literal></entry>
      <entry>带连字符的单词部分，所有 ASCII</entry>
      <entry><literal>postgresql</literal> in the context <literal>postgresql-beta1</literal></entry>
     </row>
<!-- pgdoc-cn_end sig_en=ccd72980888cd002cb23663a4d95c555 -->
<!-- pgdoc-cn_start sig_en=14cafc83866960fc87862d65601e310c sig_cn_org=None source=14.1 
     <row>
      <entry><literal>hword_part</literal></entry>
      <entry>Hyphenated word part, all letters</entry>
      <entry><literal>l&oacute;gico</literal> or <literal>matem&aacute;tica</literal>
       in the context <literal>l&oacute;gico-matem&aacute;tica</literal></entry>
     </row>
________________________________________________________-->
     <row>
      <entry><literal>hword_part</literal></entry>
      <entry>带连字符的单词部分，所有字母</entry>
      <entry><literal>l&oacute;gico</literal> or <literal>matem&aacute;tica</literal>
       in the context <literal>l&oacute;gico-matem&aacute;tica</literal></entry>
     </row>
<!-- pgdoc-cn_end sig_en=14cafc83866960fc87862d65601e310c -->
<!-- pgdoc-cn_start sig_en=3d6f15620a7445116021a8de575456ca sig_cn_org=None source=14.1 
     <row>
      <entry><literal>hword_numpart</literal></entry>
      <entry>Hyphenated word part, letters and digits</entry>
      <entry><literal>beta1</literal> in the context
       <literal>postgresql-beta1</literal></entry>
     </row>
________________________________________________________-->
     <row>
      <entry><literal>hword_numpart</literal></entry>
      <entry>带连字符的单词部分，字母和数字</entry>
      <entry><literal>beta1</literal> in the context
       <literal>postgresql-beta1</literal></entry>
     </row>
<!-- pgdoc-cn_end sig_en=3d6f15620a7445116021a8de575456ca -->
<!-- pgdoc-cn_start sig_en=775859c4b71a0da98afd25d50c5b51d7 sig_cn_org=None source=14.1 
     <row>
      <entry><literal>email</literal></entry>
      <entry>Email address</entry>
      <entry><literal>foo@example.com</literal></entry>
     </row>
________________________________________________________-->
     <row>
      <entry><literal>email</literal></entry>
      <entry>Email 地址</entry>
      <entry><literal>foo@example.com</literal></entry>
     </row>
<!-- pgdoc-cn_end sig_en=775859c4b71a0da98afd25d50c5b51d7 -->
<!-- pgdoc-cn_start sig_en=61631ec83b3844d1802dbba5d856ea6e sig_cn_org=None source=14.1 
     <row>
      <entry><literal>protocol</literal></entry>
      <entry>Protocol head</entry>
      <entry><literal>http://</literal></entry>
     </row>
________________________________________________________-->
     <row>
      <entry><literal>protocol</literal></entry>
      <entry>协议头部</entry>
      <entry><literal>http://</literal></entry>
     </row>
<!-- pgdoc-cn_end sig_en=61631ec83b3844d1802dbba5d856ea6e -->
<!-- pgdoc-cn_start sig_en=f6f47108c09453b59c263f264e3c77bd sig_cn_org=None source=14.1 
     <row>
      <entry><literal>url</literal></entry>
      <entry>URL</entry>
      <entry><literal>example.com/stuff/index.html</literal></entry>
     </row>
________________________________________________________-->
     <row>
      <entry><literal>url</literal></entry>
      <entry>URL</entry>
      <entry><literal>example.com/stuff/index.html</literal></entry>
     </row>
<!-- pgdoc-cn_end sig_en=f6f47108c09453b59c263f264e3c77bd -->
<!-- pgdoc-cn_start sig_en=b64051441b824eebfb85e7f97667ac06 sig_cn_org=None source=14.1 
     <row>
      <entry><literal>host</literal></entry>
      <entry>Host</entry>
      <entry><literal>example.com</literal></entry>
     </row>
________________________________________________________-->
     <row>
      <entry><literal>host</literal></entry>
      <entry>主机</entry>
      <entry><literal>example.com</literal></entry>
     </row>
<!-- pgdoc-cn_end sig_en=b64051441b824eebfb85e7f97667ac06 -->
<!-- pgdoc-cn_start sig_en=4548bd4918df2b2c1a1376a8e9628708 sig_cn_org=None source=14.1 
     <row>
      <entry><literal>url_path</literal></entry>
      <entry>URL path</entry>
      <entry><literal>/stuff/index.html</literal>, in the context of a URL</entry>
     </row>
________________________________________________________-->
     <row>
      <entry><literal>url_path</literal></entry>
      <entry>URL 路径</entry>
      <entry><literal>/stuff/index.html</literal>, in the context of a URL</entry>
     </row>
<!-- pgdoc-cn_end sig_en=4548bd4918df2b2c1a1376a8e9628708 -->
<!-- pgdoc-cn_start sig_en=d2523fbfc15bf608bddcaa8d5d6f047a sig_cn_org=None source=14.1 
     <row>
      <entry><literal>file</literal></entry>
      <entry>File or path name</entry>
      <entry><literal>/usr/local/foo.txt</literal>, if not within a URL</entry>
     </row>
________________________________________________________-->
     <row>
      <entry><literal>file</literal></entry>
      <entry>文件或路径名</entry>
      <entry><literal>/usr/local/foo.txt</literal>, if not within a URL</entry>
     </row>
<!-- pgdoc-cn_end sig_en=d2523fbfc15bf608bddcaa8d5d6f047a -->
<!-- pgdoc-cn_start sig_en=2e9dcce38adaf47b61caf92518d9f353 sig_cn_org=None source=14.1 
     <row>
      <entry><literal>sfloat</literal></entry>
      <entry>Scientific notation</entry>
      <entry><literal>-1.234e56</literal></entry>
     </row>
________________________________________________________-->
     <row>
      <entry><literal>sfloat</literal></entry>
      <entry>科学记数法</entry>
      <entry><literal>-1.234e56</literal></entry>
     </row>
<!-- pgdoc-cn_end sig_en=2e9dcce38adaf47b61caf92518d9f353 -->
<!-- pgdoc-cn_start sig_en=ac5fc5a442a151ca374dbbc6cf88888d sig_cn_org=None source=14.1 
     <row>
      <entry><literal>float</literal></entry>
      <entry>Decimal notation</entry>
      <entry><literal>-1.234</literal></entry>
     </row>
________________________________________________________-->
     <row>
      <entry><literal>float</literal></entry>
      <entry>十进制记数法</entry>
      <entry><literal>-1.234</literal></entry>
     </row>
<!-- pgdoc-cn_end sig_en=ac5fc5a442a151ca374dbbc6cf88888d -->
<!-- pgdoc-cn_start sig_en=b1398ecf85f8b66143998c0be4bdae41 sig_cn_org=None source=14.1 
     <row>
      <entry><literal>int</literal></entry>
      <entry>Signed integer</entry>
      <entry><literal>-1234</literal></entry>
     </row>
________________________________________________________-->
     <row>
      <entry><literal>int</literal></entry>
      <entry>有符号整数</entry>
      <entry><literal>-1234</literal></entry>
     </row>
<!-- pgdoc-cn_end sig_en=b1398ecf85f8b66143998c0be4bdae41 -->
<!-- pgdoc-cn_start sig_en=1bdbf7842a503f03771ef387b32166d3 sig_cn_org=None source=14.1 
     <row>
      <entry><literal>uint</literal></entry>
      <entry>Unsigned integer</entry>
      <entry><literal>1234</literal></entry>
     </row>
________________________________________________________-->
     <row>
      <entry><literal>uint</literal></entry>
      <entry>无符号整数</entry>
      <entry><literal>1234</literal></entry>
     </row>
<!-- pgdoc-cn_end sig_en=1bdbf7842a503f03771ef387b32166d3 -->
<!-- pgdoc-cn_start sig_en=38a9c044782d40b9082884d8b153cdba sig_cn_org=None source=14.1 
     <row>
      <entry><literal>version</literal></entry>
      <entry>Version number</entry>
      <entry><literal>8.3.0</literal></entry>
     </row>
________________________________________________________-->
     <row>
      <entry><literal>version</literal></entry>
      <entry>版本号</entry>
      <entry><literal>8.3.0</literal></entry>
     </row>
<!-- pgdoc-cn_end sig_en=38a9c044782d40b9082884d8b153cdba -->
<!-- pgdoc-cn_start sig_en=73e0a00e6628c993419f42edaf086a61 sig_cn_org=None source=14.1 
     <row>
      <entry><literal>tag</literal></entry>
      <entry>XML tag</entry>
      <entry><literal>&lt;a href="dictionaries.html"&gt;</literal></entry>
     </row>
________________________________________________________-->
     <row>
      <entry><literal>tag</literal></entry>
      <entry>XML 标签</entry>
      <entry><literal>&lt;a href="dictionaries.html"&gt;</literal></entry>
     </row>
<!-- pgdoc-cn_end sig_en=73e0a00e6628c993419f42edaf086a61 -->
<!-- pgdoc-cn_start sig_en=a6a94ac0998cc536a8e8f53cf44640e3 sig_cn_org=None source=14.1 
     <row>
      <entry><literal>entity</literal></entry>
      <entry>XML entity</entry>
      <entry><literal>&amp;amp;</literal></entry>
     </row>
________________________________________________________-->
     <row>
      <entry><literal>entity</literal></entry>
      <entry>XML 实体</entry>
      <entry><literal>&amp;amp;</literal></entry>
     </row>
<!-- pgdoc-cn_end sig_en=a6a94ac0998cc536a8e8f53cf44640e3 -->
<!-- pgdoc-cn_start sig_en=1daa1c801cabc0f404d1458c87d11d60 sig_cn_org=None source=14.1 
     <row>
      <entry><literal>blank</literal></entry>
      <entry>Space symbols</entry>
      <entry>(any whitespace or punctuation not otherwise recognized)</entry>
     </row>
________________________________________________________-->
     <row>
      <entry><literal>blank</literal></entry>
      <entry>空格符号</entry>
      <entry>（其他不识别的任意空白或标点符号）</entry>
     </row>
<!-- pgdoc-cn_end sig_en=1daa1c801cabc0f404d1458c87d11d60 -->
    </tbody>
   </tgroup>
  </table>

  <note>
<!-- pgdoc-cn_start sig_en=4681c244b25dafbd4e4f41a830cf090c sig_cn_org=None source=14.1 
   <para>
    The parser's notion of a <quote>letter</quote> is determined by the database's
    locale setting, specifically <varname>lc_ctype</varname>.  Words containing
    only the basic ASCII letters are reported as a separate token type,
    since it is sometimes useful to distinguish them.  In most European
    languages, token types <literal>word</literal> and <literal>asciiword</literal>
    should be treated alike.
   </para>
________________________________________________________-->
   <para>
    解析器的一个<quote>字母</quote>的概念由数据库的区域设置决定，具体是<varname>lc_ctype</varname>。只包含基本 ASCII 字母的词被报告为一个单独的记号类型，因为有时可以用来区别它们。在大部分欧洲语言中，记号类型<literal>word</literal>和<literal>asciiword</literal>应该被同样对待。
   </para>
<!-- pgdoc-cn_end sig_en=4681c244b25dafbd4e4f41a830cf090c -->

<!-- pgdoc-cn_start sig_en=e53f0946071a68d2fdaea2ad3bd2e87c sig_cn_org=07319c371817e658c376fe0e6f921792 source=15.7 
   <para>
    <literal>email</literal> does not support all valid email characters as
    defined by <ulink url="https://datatracker.ietf.org/doc/html/rfc5322">RFC 5322</ulink>.
    Specifically, the only non-alphanumeric characters supported for
    email user names are period, dash, and underscore.
   </para>
________________________________________________________-->
   <para>
    <literal>email</literal>不支持所有由<ulink url="https://datatracker.ietf.org/doc/html/rfc5322">RFC 5322</ulink>定义的有效电子邮件字符。
    具体来说，电子邮件用户名仅支持句号、短横线和下划线这些非字母数字字符。
   </para>
<!-- pgdoc-cn_end sig_en=e53f0946071a68d2fdaea2ad3bd2e87c -->
  </note>

<!-- pgdoc-cn_start sig_en=49c7270a8aa0aab27ed0f3c5abda2baf sig_cn_org=8ac0a33151bfab5be1aa7db7adec2503 source=15.7 
  <para>
   It is possible for the parser to produce overlapping tokens from the same
   piece of text.  As an example, a hyphenated word will be reported both
   as the entire word and as each component:

<screen>
SELECT alias, description, token FROM ts_debug('foo-bar-beta1');
      alias      |               description                |     token
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 numhword        | Hyphenated word, letters and digits      | foo-bar-beta1
 hword_asciipart | Hyphenated word part, all ASCII          | foo
 blank           | Space symbols                            | -
 hword_asciipart | Hyphenated word part, all ASCII          | bar
 blank           | Space symbols                            | -
 hword_numpart   | Hyphenated word part, letters and digits | beta1
</screen>

   This behavior is desirable since it allows searches to work for both
   the whole compound word and for components.  Here is another
   instructive example:

<screen>
SELECT alias, description, token FROM ts_debug('http://example.com/stuff/index.html');
  alias   |  description  |            token
-&minus;-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 protocol | Protocol head | http://
 url      | URL           | example.com/stuff/index.html
 host     | Host          | example.com
 url_path | URL path      | /stuff/index.html
</screen>
  </para>
________________________________________________________-->
  <para>
   解析器有可能从同一段文本中生成重叠的标记。例如，一个连字符单词将被报告为整个单词和每个组成部分：

<screen>
SELECT alias, description, token FROM ts_debug('foo-bar-beta1');
      alias      |               description                |     token
-----------------+------------------------------------------+---------------
 numhword        | Hyphenated word, letters and digits      | foo-bar-beta1
 hword_asciipart | Hyphenated word part, all ASCII          | foo
 blank           | Space symbols                            | -
 hword_asciipart | Hyphenated word part, all ASCII          | bar
 blank           | Space symbols                            | -
 hword_numpart   | Hyphenated word part, letters and digits | beta1
</screen>

   这种行为是可取的，因为它允许搜索同时适用于整个复合词和组件。这里是另一个有启发性的例子：

<screen>
SELECT alias, description, token FROM ts_debug('http://example.com/stuff/index.html');
  alias   |  description  |            token
----------+---------------+------------------------------
 protocol | Protocol head | http://
 url      | URL           | example.com/stuff/index.html
 host     | Host          | example.com
 url_path | URL path      | /stuff/index.html
</screen>
  </para>
<!-- pgdoc-cn_end sig_en=49c7270a8aa0aab27ed0f3c5abda2baf -->

 </sect1>

 <sect1 id="textsearch-dictionaries">
<!-- pgdoc-cn_start sig_en=0f7a18b06c7228492c68cd5c6946fb4d sig_cn_org=None source=14.1 
  <title>Dictionaries</title>
________________________________________________________-->
  <title>词典</title>
<!-- pgdoc-cn_end sig_en=0f7a18b06c7228492c68cd5c6946fb4d -->

<!-- pgdoc-cn_start sig_en=355c78a91776e0b98530902054a33b6a sig_cn_org=None source=14.1 
  <para>
   Dictionaries are used to eliminate words that should not be considered in a
   search (<firstterm>stop words</firstterm>), and to <firstterm>normalize</firstterm> words so
   that different derived forms of the same word will match.  A successfully
   normalized word is called a <firstterm>lexeme</firstterm>.  Aside from
   improving search quality, normalization and removal of stop words reduce the
   size of the <type>tsvector</type> representation of a document, thereby
   improving performance.  Normalization does not always have linguistic meaning
   and usually depends on application semantics.
  </para>
________________________________________________________-->
  <para>
   词典被用来消除不被搜索考虑的词（<firstterm>stop words</firstterm>）、并被用来<firstterm>正规化</firstterm>词这样同一个词的不同派生形式将会匹配。一个被成功地正规化的词被称为一个<firstterm>词位</firstterm>。除了提高搜索质量，正规化和移除停用词减小了文档的<type>tsvector</type>表示的尺寸，因而提高了性能。正规化不会总是有语言上的意义并且通常依赖于应用的语义。
  </para>
<!-- pgdoc-cn_end sig_en=355c78a91776e0b98530902054a33b6a -->

<!-- pgdoc-cn_start sig_en=1af9838ee1c9b5cfdda51797dfb7c4e8 sig_cn_org=None source=14.1 
  <para>
   Some examples of normalization:

   <itemizedlist  spacing="compact" mark="bullet">

    <listitem>
     <para>
      Linguistic &mdash; Ispell dictionaries try to reduce input words to a
      normalized form; stemmer dictionaries remove word endings
     </para>
    </listitem>
    <listitem>
     <para>
      <acronym>URL</acronym> locations can be canonicalized to make
      equivalent URLs match:

      <itemizedlist  spacing="compact" mark="bullet">
       <listitem>
        <para>
         http://www.pgsql.ru/db/mw/index.html
        </para>
       </listitem>
       <listitem>
        <para>
         http://www.pgsql.ru/db/mw/
        </para>
       </listitem>
       <listitem>
        <para>
         http://www.pgsql.ru/db/../db/mw/index.html
        </para>
       </listitem>
      </itemizedlist>
     </para>
    </listitem>
    <listitem>
     <para>
      Color names can be replaced by their hexadecimal values, e.g.,
      <literal>red, green, blue, magenta -> FF0000, 00FF00, 0000FF, FF00FF</literal>
     </para>
    </listitem>
    <listitem>
     <para>
      If indexing numbers, we can
      remove some fractional digits to reduce the range of possible
      numbers, so for example <emphasis>3.14</emphasis>159265359,
      <emphasis>3.14</emphasis>15926, <emphasis>3.14</emphasis> will be the same
      after normalization if only two digits are kept after the decimal point.
     </para>
    </listitem>
   </itemizedlist>

  </para>
________________________________________________________-->
  <para>
   一些正规化的例子：

   <itemizedlist  spacing="compact" mark="bullet">

    <listitem>
     <para>
      语言学的 &mdash; Ispell 词典尝试将输入词缩减为一种正规化的形式；词干分析器词典移除词的结尾
     </para>
    </listitem>
    <listitem>
     <para>
      <acronym>URL</acronym>位置可以被规范化来得到等效的 URL 匹配：

      <itemizedlist  spacing="compact" mark="bullet">
       <listitem>
        <para>
         http://www.pgsql.ru/db/mw/index.html
        </para>
       </listitem>
       <listitem>
        <para>
         http://www.pgsql.ru/db/mw/
        </para>
       </listitem>
       <listitem>
        <para>
         http://www.pgsql.ru/db/../db/mw/index.html
        </para>
       </listitem>
      </itemizedlist>
     </para>
    </listitem>
    <listitem>
     <para>
      颜色名可以被它们的十六进制值替换，例如<literal>red, green, blue, magenta -> FF0000, 00FF00, 0000FF, FF00FF</literal>
     </para>
    </listitem>
    <listitem>
     <para>
      如果索引数字，我们可以移除某些小数位来缩减可能的数字的范围，因此如果只保留小数点后两位，例如<emphasis>3.14</emphasis>159265359、<emphasis>3.14</emphasis>15926、<emphasis>3.14</emphasis>在正规化后会变得相同。
     </para>
    </listitem>
   </itemizedlist>

  </para>
<!-- pgdoc-cn_end sig_en=1af9838ee1c9b5cfdda51797dfb7c4e8 -->

<!-- pgdoc-cn_start sig_en=00e878e78e3c571df124293cd18afc67 sig_cn_org=None source=14.1 
  <para>
   A dictionary is a program that accepts a token as
   input and returns:
   <itemizedlist  spacing="compact" mark="bullet">
    <listitem>
     <para>
      an array of lexemes if the input token is known to the dictionary
      (notice that one token can produce more than one lexeme)
     </para>
    </listitem>
    <listitem>
     <para>
      a single lexeme with the <literal>TSL_FILTER</literal> flag set, to replace
      the original token with a new token to be passed to subsequent
      dictionaries (a dictionary that does this is called a
      <firstterm>filtering dictionary</firstterm>)
     </para>
    </listitem>
    <listitem>
     <para>
      an empty array if the dictionary knows the token, but it is a stop word
     </para>
    </listitem>
    <listitem>
     <para>
      <literal>NULL</literal> if the dictionary does not recognize the input token
     </para>
    </listitem>
   </itemizedlist>
  </para>
________________________________________________________-->
  <para>
   一个词典是一个程序，它接受一个记号作为输入，并返回：
   <itemizedlist  spacing="compact" mark="bullet">
    <listitem>
     <para>
      如果输入的记号对词典是已知的，则返回一个词位数组（注意一个记号可能产生多于一个词位）
     </para>
    </listitem>
    <listitem>
     <para>
      一个<literal>TSL_FILTER</literal>标志被设置的单一词位，用一个新记号来替换要被传递给后续字典的原始记号（做这件事的一个字典被称为一个<firstterm>过滤字典</firstterm>）
     </para>
    </listitem>
    <listitem>
     <para>
      如果字典知道该记号但它是一个停用词，则返回一个空数组
     </para>
    </listitem>
    <listitem>
     <para>
      如果字典不识别该输入记号，则返回<literal>NULL</literal>
     </para>
    </listitem>
   </itemizedlist>
  </para>
<!-- pgdoc-cn_end sig_en=00e878e78e3c571df124293cd18afc67 -->

<!-- pgdoc-cn_start sig_en=1b40fff867eb876ba39742ef99cd0fd7 sig_cn_org=None source=14.1 
  <para>
   <productname>PostgreSQL</productname> provides predefined dictionaries for
   many languages.  There are also several predefined templates that can be
   used to create new dictionaries with custom parameters.  Each predefined
   dictionary template is described below.  If no existing
   template is suitable, it is possible to create new ones; see the
   <filename>contrib/</filename> area of the <productname>PostgreSQL</productname> distribution
   for examples.
  </para>
________________________________________________________-->
  <para>
   <productname>PostgreSQL</productname>为许多语言提供了预定义的字典。也有多种预定义模板可以被用于创建带自定义参数的新词典。每一种预定义词典模板在下面描述。如果没有合适的现有模板，可以创建新的；例子见<productname>PostgreSQL</productname>发布的<filename>contrib/</filename>区域。
  </para>
<!-- pgdoc-cn_end sig_en=1b40fff867eb876ba39742ef99cd0fd7 -->

<!-- pgdoc-cn_start sig_en=d23c10c5aceac17ac15fadcfa8d8d421 sig_cn_org=None source=14.1 
  <para>
   A text search configuration binds a parser together with a set of
   dictionaries to process the parser's output tokens.  For each token
   type that the parser can return, a separate list of dictionaries is
   specified by the configuration.  When a token of that type is found
   by the parser, each dictionary in the list is consulted in turn,
   until some dictionary recognizes it as a known word.  If it is identified
   as a stop word, or if no dictionary recognizes the token, it will be
   discarded and not indexed or searched for.
   Normally, the first dictionary that returns a non-<literal>NULL</literal>
   output determines the result, and any remaining dictionaries are not
   consulted; but a filtering dictionary can replace the given word
   with a modified word, which is then passed to subsequent dictionaries.
  </para>
________________________________________________________-->
  <para>
   一个文本搜索配置把一个解析器和一组处理解析器输出记号的词典绑定在一起。对于每一中解析器能返回的记号类型，配置都指定了一个单独的词典列表。当该类型的一个记号被解析器找到时，每一个词典都被按照顺序查询，知道某个词典将其识别为一个已知词。如果它被标识为一个停用词或者没有一个词典识别它，它将被丢弃并且不会被索引和用于搜索。通常，第一个返回非<literal>NULL</literal>输出的词典决定结果，并且任何剩下的词典都不会被查找；但是一个过滤词典可以将给定词替换为一个被修改的词，它再被传递给后续的词典。
  </para>
<!-- pgdoc-cn_end sig_en=d23c10c5aceac17ac15fadcfa8d8d421 -->

<!-- pgdoc-cn_start sig_en=0d3f93607cd239123f74bf2137b55e4f sig_cn_org=None source=14.1 
  <para>
   The general rule for configuring a list of dictionaries
   is to place first the most narrow, most specific dictionary, then the more
   general dictionaries, finishing with a very general dictionary, like
   a <application>Snowball</application> stemmer or <literal>simple</literal>, which
   recognizes everything.  For example, for an astronomy-specific search
   (<literal>astro_en</literal> configuration) one could bind token type
   <type>asciiword</type> (ASCII word) to a synonym dictionary of astronomical
   terms, a general English dictionary and a <application>Snowball</application> English
   stemmer:

<programlisting>
ALTER TEXT SEARCH CONFIGURATION astro_en
    ADD MAPPING FOR asciiword WITH astrosyn, english_ispell, english_stem;
</programlisting>
  </para>
________________________________________________________-->
  <para>
   配置一个词典列表的通用规则是将最狭窄、最特定的词典放在第一位，然后是更加通用的词典，以一个非常通用的词典结尾，像一个<application>Snowball</application>词干分析器或什么都识别的<literal>simple</literal>。例如，对于一个天文学相关的搜索（<literal>astro_en</literal> 配置）我们可以把记号类型<type>asciiword</type>（ASCII 词）绑定到一个天文学术语的分类词典、一个通用英语词典和一个<application>Snowball</application>英语词干分析器：

<programlisting>
ALTER TEXT SEARCH CONFIGURATION astro_en
    ADD MAPPING FOR asciiword WITH astrosyn, english_ispell, english_stem;
</programlisting>
  </para>
<!-- pgdoc-cn_end sig_en=0d3f93607cd239123f74bf2137b55e4f -->

<!-- pgdoc-cn_start sig_en=c8470843579609a04b33afa3ceadd76b sig_cn_org=None source=14.1 
  <para>
   A filtering dictionary can be placed anywhere in the list, except at the
   end where it'd be useless.  Filtering dictionaries are useful to partially
   normalize words to simplify the task of later dictionaries.  For example,
   a filtering dictionary could be used to remove accents from accented
   letters, as is done by the <xref linkend="unaccent"/> module.
  </para>
________________________________________________________-->
  <para>
   一个过滤词典可以被放置在列表中的任意位置，除了在最后，因为过滤词典放在最后就等于无用。过滤词典可用于部分正规化词来简化后续词典的工作。例如，一个过滤词典可以被用来从音标字母中移除重音符号，就像<xref linkend="unaccent"/>模块所做的。
  </para>
<!-- pgdoc-cn_end sig_en=c8470843579609a04b33afa3ceadd76b -->

  <sect2 id="textsearch-stopwords">
<!-- pgdoc-cn_start sig_en=f0733b9d11db5994b8a430b6ff08a39a sig_cn_org=None source=14.1 
   <title>Stop Words</title>
________________________________________________________-->
   <title>停用词</title>
<!-- pgdoc-cn_end sig_en=f0733b9d11db5994b8a430b6ff08a39a -->

<!-- pgdoc-cn_start sig_en=0870f14e9d324253480ca65212b1911f sig_cn_org=None source=14.1 
   <para>
    Stop words are words that are very common, appear in almost every
    document, and have no discrimination value. Therefore, they can be ignored
    in the context of full text searching. For example, every English text
    contains words like <literal>a</literal> and <literal>the</literal>, so it is
    useless to store them in an index.  However, stop words do affect the
    positions in <type>tsvector</type>, which in turn affect ranking:

<screen>
SELECT to_tsvector('english', 'in the list of stop words');
        to_tsvector
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 'list':3 'stop':5 'word':6
</screen>

    The missing positions 1,2,4 are because of stop words.  Ranks
    calculated for documents with and without stop words are quite different:

<screen>
SELECT ts_rank_cd (to_tsvector('english', 'in the list of stop words'), to_tsquery('list &amp; stop'));
 ts_rank_cd
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
       0.05

SELECT ts_rank_cd (to_tsvector('english', 'list stop words'), to_tsquery('list &amp; stop'));
 ts_rank_cd
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
        0.1
</screen>

   </para>
________________________________________________________-->
   <para>
    停用词是非常常用、在几乎每一个文档中出现并且没有任何区分度的词。因此，在全文搜索的环境中它们可以被忽略。例如，每一段英语文本都包含<literal>a</literal>和<literal>the</literal>等次，因此把它们存储在一个索引中是没有用处的。但是，停用词确实会影响在<type>tsvector</type>中的位置，这进而会影响排名：

<screen>
SELECT to_tsvector('english', 'in the list of stop words');
        to_tsvector
----------------------------
 'list':3 'stop':5 'word':6
</screen>

    缺失的位置 1、2、4 是因为停用词。文档的排名计算在使用和不使用停用词的情况下是很不同的：

<screen>
SELECT ts_rank_cd (to_tsvector('english', 'in the list of stop words'), to_tsquery('list &amp; stop'));
 ts_rank_cd
------------
       0.05

SELECT ts_rank_cd (to_tsvector('english', 'list stop words'), to_tsquery('list &amp; stop'));
 ts_rank_cd
------------
        0.1
</screen>

   </para>
<!-- pgdoc-cn_end sig_en=0870f14e9d324253480ca65212b1911f -->

<!-- pgdoc-cn_start sig_en=5e546425c9438c9e9ae208b26411501d sig_cn_org=None source=14.1 
   <para>
    It is up to the specific dictionary how it treats stop words. For example,
    <literal>ispell</literal> dictionaries first normalize words and then
    look at the list of stop words, while <literal>Snowball</literal> stemmers
    first check the list of stop words. The reason for the different
    behavior is an attempt to decrease noise.
   </para>
________________________________________________________-->
   <para>
    如何对待停用词是由指定词典决定的。例如，<literal>ispell</literal>词典首先正规化词并且查看停用词列表，而<literal>Snowball</literal>词干分析器首先检查停用词的列表。这种不同行为的原因是一冲降低噪声的尝试。
   </para>
<!-- pgdoc-cn_end sig_en=5e546425c9438c9e9ae208b26411501d -->

  </sect2>

  <sect2 id="textsearch-simple-dictionary">
<!-- pgdoc-cn_start sig_en=6f92669df52a02201866c38db42027df sig_cn_org=None source=14.1 
   <title>Simple Dictionary</title>
________________________________________________________-->
   <title>简单词典</title>
<!-- pgdoc-cn_end sig_en=6f92669df52a02201866c38db42027df -->

<!-- pgdoc-cn_start sig_en=5ad9acf4abb500cdf6ac9dd522bd854f sig_cn_org=None source=14.1 
   <para>
    The <literal>simple</literal> dictionary template operates by converting the
    input token to lower case and checking it against a file of stop words.
    If it is found in the file then an empty array is returned, causing
    the token to be discarded.  If not, the lower-cased form of the word
    is returned as the normalized lexeme.  Alternatively, the dictionary
    can be configured to report non-stop-words as unrecognized, allowing
    them to be passed on to the next dictionary in the list.
   </para>
________________________________________________________-->
   <para>
    <literal>simple</literal>词典模板的操作是将输入记号转换为小写形式并且根据一个停用词文件检查它。如果该记号在该文件中被找到，则返回一个空数组，导致该记号被丢弃。否则，该词的小写形式被返回作为正规化的词位。作为一种选择，该词典可以被配置为将非停用词报告为未识别，允许它们被传递给列表中的下一个词典。
   </para>
<!-- pgdoc-cn_end sig_en=5ad9acf4abb500cdf6ac9dd522bd854f -->

<!-- pgdoc-cn_start sig_en=e1c69ae562451cf41d39ef8a4a5533d0 sig_cn_org=None source=14.1 
   <para>
    Here is an example of a dictionary definition using the <literal>simple</literal>
    template:

<programlisting>
CREATE TEXT SEARCH DICTIONARY public.simple_dict (
    TEMPLATE = pg_catalog.simple,
    STOPWORDS = english
);
</programlisting>

    Here, <literal>english</literal> is the base name of a file of stop words.
    The file's full name will be
    <filename>$SHAREDIR/tsearch_data/english.stop</filename>,
    where <literal>$SHAREDIR</literal> means the
    <productname>PostgreSQL</productname> installation's shared-data directory,
    often <filename>/usr/local/share/postgresql</filename> (use <command>pg_config
    -&minus;sharedir</command> to determine it if you're not sure).
    The file format is simply a list
    of words, one per line.  Blank lines and trailing spaces are ignored,
    and upper case is folded to lower case, but no other processing is done
    on the file contents.
   </para>
________________________________________________________-->
   <para>
    下面是一个使用<literal>simple</literal>模板的词典定义的例子：

<programlisting>
CREATE TEXT SEARCH DICTIONARY public.simple_dict (
    TEMPLATE = pg_catalog.simple,
    STOPWORDS = english
);
</programlisting>

    这里，<literal>english</literal>是一个停用词文件的基本名称。该文件的全名将是<filename>$SHAREDIR/tsearch_data/english.stop</filename>，其中<literal>$SHAREDIR</literal>表示<productname>PostgreSQL</productname>安装的共享数据目录，通常是<filename>/usr/local/share/postgresql</filename>（如果不确定，使用<command>pg_config --sharedir</command>）。该文件格式是一个词的列表，每行一个。空行和尾部的空格都被忽略，并且大写也被折叠成小写，但是没有其他对该文件内容的处理。
   </para>
<!-- pgdoc-cn_end sig_en=e1c69ae562451cf41d39ef8a4a5533d0 -->

<!-- pgdoc-cn_start sig_en=97d6f216df7b56e1721df006d50d4de6 sig_cn_org=None source=14.1 
   <para>
    Now we can test our dictionary:

<screen>
SELECT ts_lexize('public.simple_dict', 'YeS');
 ts_lexize
-&minus;-&minus;-&minus;-&minus;-&minus;-
 {yes}

SELECT ts_lexize('public.simple_dict', 'The');
 ts_lexize
-&minus;-&minus;-&minus;-&minus;-&minus;-
 {}
</screen>
   </para>
________________________________________________________-->
   <para>
    现在我们能够测试我们的词典：

<screen>
SELECT ts_lexize('public.simple_dict', 'YeS');
 ts_lexize
-----------
 {yes}

SELECT ts_lexize('public.simple_dict', 'The');
 ts_lexize
-----------
 {}
</screen>
   </para>
<!-- pgdoc-cn_end sig_en=97d6f216df7b56e1721df006d50d4de6 -->

<!-- pgdoc-cn_start sig_en=f03a3945ba27191951533f20d20fca7e sig_cn_org=None source=14.1 
   <para>
    We can also choose to return <literal>NULL</literal>, instead of the lower-cased
    word, if it is not found in the stop words file.  This behavior is
    selected by setting the dictionary's <literal>Accept</literal> parameter to
    <literal>false</literal>.  Continuing the example:

<screen>
ALTER TEXT SEARCH DICTIONARY public.simple_dict ( Accept = false );

SELECT ts_lexize('public.simple_dict', 'YeS');
 ts_lexize
-&minus;-&minus;-&minus;-&minus;-&minus;-


SELECT ts_lexize('public.simple_dict', 'The');
 ts_lexize
-&minus;-&minus;-&minus;-&minus;-&minus;-
 {}
</screen>
   </para>
________________________________________________________-->
   <para>
    如果没有在停用词文件中找到，我们也可以选择返回<literal>NULL</literal>而不是小写形式的词。这种行为可以通过设置词典的<literal>Accept</literal>参数为<literal>false</literal>来选择。继续该例子：

<screen>
ALTER TEXT SEARCH DICTIONARY public.simple_dict ( Accept = false );

SELECT ts_lexize('public.simple_dict', 'YeS');
 ts_lexize
-----------


SELECT ts_lexize('public.simple_dict', 'The');
 ts_lexize
-----------
 {}
</screen>
   </para>
<!-- pgdoc-cn_end sig_en=f03a3945ba27191951533f20d20fca7e -->

<!-- pgdoc-cn_start sig_en=e94384495012705be86bd4a782004afa sig_cn_org=None source=14.1 
   <para>
    With the default setting of <literal>Accept</literal> = <literal>true</literal>,
    it is only useful to place a <literal>simple</literal> dictionary at the end
    of a list of dictionaries, since it will never pass on any token to
    a following dictionary.  Conversely, <literal>Accept</literal> = <literal>false</literal>
    is only useful when there is at least one following dictionary.
   </para>
________________________________________________________-->
   <para>
    在使用默认值<literal>Accept</literal> = <literal>true</literal>，只有把一个<literal>simple</literal>词典放在词典列表的尾部才有用，因为它将不会传递任何记号给后续的词典。相反，<literal>Accept</literal> = <literal>false</literal>只有当至少有一个后续词典的情况下才有用。
   </para>
<!-- pgdoc-cn_end sig_en=e94384495012705be86bd4a782004afa -->

   <caution>
<!-- pgdoc-cn_start sig_en=878a7ae236fac3e5200e3a1c51222f8f sig_cn_org=None source=14.1 
    <para>
     Most types of dictionaries rely on configuration files, such as files of
     stop words.  These files <emphasis>must</emphasis> be stored in UTF-8 encoding.
     They will be translated to the actual database encoding, if that is
     different, when they are read into the server.
    </para>
________________________________________________________-->
    <para>
     大部分类型的词典依赖于配置文件，例如停用词文件。这些文件<emphasis>必须</emphasis>被存储为 UTF-8 编码。当它们被读入服务器时，如果存在不同，它们将被翻译成真实的数据库编码。
    </para>
<!-- pgdoc-cn_end sig_en=878a7ae236fac3e5200e3a1c51222f8f -->
   </caution>

   <caution>
<!-- pgdoc-cn_start sig_en=e92ef2483719d0635051c5a6657dd97d sig_cn_org=None source=14.1 
    <para>
     Normally, a database session will read a dictionary configuration file
     only once, when it is first used within the session.  If you modify a
     configuration file and want to force existing sessions to pick up the
     new contents, issue an <command>ALTER TEXT SEARCH DICTIONARY</command> command
     on the dictionary.  This can be a <quote>dummy</quote> update that doesn't
     actually change any parameter values.
    </para>
________________________________________________________-->
    <para>
     通常，当一个词典配置文件第一次在数据库会话中使用时，数据库会话将只读取它一次。如果你修改了一个配置文件并且想强迫现有的会话取得新内容，可以在该词典上发出一个<command>ALTER TEXT SEARCH DICTIONARY</command>命令。这可以是一次<quote>假</quote>更新，它并不实际修改任何参数值。
    </para>
<!-- pgdoc-cn_end sig_en=e92ef2483719d0635051c5a6657dd97d -->
   </caution>

  </sect2>

  <sect2 id="textsearch-synonym-dictionary">
<!-- pgdoc-cn_start sig_en=2c197fd9b5bb475e74a56d43f7203026 sig_cn_org=None source=14.1 
   <title>Synonym Dictionary</title>
________________________________________________________-->
   <title>同义词词典</title>
<!-- pgdoc-cn_end sig_en=2c197fd9b5bb475e74a56d43f7203026 -->

<!-- pgdoc-cn_start sig_en=1d64f04962f7373fe5af30163d1c89dd sig_cn_org=34329cee06b2cf313d5dd262a049a88c source=15.7 
   <para>
    This dictionary template is used to create dictionaries that replace a
    word with a synonym. Phrases are not supported (use the thesaurus
    template (<xref linkend="textsearch-thesaurus"/>) for that).  A synonym
    dictionary can be used to overcome linguistic problems, for example, to
    prevent an English stemmer dictionary from reducing the word <quote>Paris</quote> to
    <quote>pari</quote>.  It is enough to have a <literal>Paris paris</literal> line in the
    synonym dictionary and put it before the <literal>english_stem</literal>
    dictionary.  For example:

<screen>
SELECT * FROM ts_debug('english', 'Paris');
   alias   |   description   | token |  dictionaries  |  dictionary  | lexemes
-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-
 asciiword | Word, all ASCII | Paris | {english_stem} | english_stem | {pari}

CREATE TEXT SEARCH DICTIONARY my_synonym (
    TEMPLATE = synonym,
    SYNONYMS = my_synonyms
);

ALTER TEXT SEARCH CONFIGURATION english
    ALTER MAPPING FOR asciiword
    WITH my_synonym, english_stem;

SELECT * FROM ts_debug('english', 'Paris');
   alias   |   description   | token |       dictionaries        | dictionary | lexemes
-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-
 asciiword | Word, all ASCII | Paris | {my_synonym,english_stem} | my_synonym | {paris}
</screen>
   </para>
________________________________________________________-->
   <para>
    这个字典模板用于创建将单词替换为同义词的字典。不支持短语（请使用词典模板<xref linkend="textsearch-thesaurus"/>）。同义词字典可用于解决语言问题，例如，防止英语词干字典将单词<quote>Paris</quote>减少为<quote>pari</quote>。在同义词字典中只需有一行<literal>Paris paris</literal>，并将其放在<literal>english_stem</literal>字典之前。例如：

<screen>
SELECT * FROM ts_debug('english', 'Paris');
   alias   |   description   | token |  dictionaries  |  dictionary  | lexemes
-----------+-----------------+-------+----------------+--------------+---------
 asciiword | Word, all ASCII | Paris | {english_stem} | english_stem | {pari}

CREATE TEXT SEARCH DICTIONARY my_synonym (
    TEMPLATE = synonym,
    SYNONYMS = my_synonyms
);

ALTER TEXT SEARCH CONFIGURATION english
    ALTER MAPPING FOR asciiword
    WITH my_synonym, english_stem;

SELECT * FROM ts_debug('english', 'Paris');
   alias   |   description   | token |       dictionaries        | dictionary | lexemes
-----------+-----------------+-------+---------------------------+------------+---------
 asciiword | Word, all ASCII | Paris | {my_synonym,english_stem} | my_synonym | {paris}
</screen>
   </para>
<!-- pgdoc-cn_end sig_en=1d64f04962f7373fe5af30163d1c89dd -->

<!-- pgdoc-cn_start sig_en=50a087c4b3d49067dfffa7de5f914764 sig_cn_org=None source=14.1 
   <para>
    The only parameter required by the <literal>synonym</literal> template is
    <literal>SYNONYMS</literal>, which is the base name of its configuration file
    &mdash; <literal>my_synonyms</literal> in the above example.
    The file's full name will be
    <filename>$SHAREDIR/tsearch_data/my_synonyms.syn</filename>
    (where <literal>$SHAREDIR</literal> means the
    <productname>PostgreSQL</productname> installation's shared-data directory).
    The file format is just one line
    per word to be substituted, with the word followed by its synonym,
    separated by white space.  Blank lines and trailing spaces are ignored.
   </para>
________________________________________________________-->
   <para>
    <literal>synonym</literal>模板要求的唯一参数是<literal>SYNONYMS</literal>，它是其配置文件的基本名 &mdash; 上例中的<literal>my_synonyms</literal>。该文件的完整名称将是<filename>$SHAREDIR/tsearch_data/my_synonyms.syn</filename>（其中<literal>$SHAREDIR</literal>表示<productname>PostgreSQL</productname>安装的共享数据目录）。该文件格式是每行一个要被替换的词，后面跟着它的同义词，用空白分隔。空行和结尾的空格会被忽略。
   </para>
<!-- pgdoc-cn_end sig_en=50a087c4b3d49067dfffa7de5f914764 -->

<!-- pgdoc-cn_start sig_en=297a635ed783de7cf42177d21c446ef8 sig_cn_org=None source=14.1 
   <para>
    The <literal>synonym</literal> template also has an optional parameter
    <literal>CaseSensitive</literal>, which defaults to <literal>false</literal>.  When
    <literal>CaseSensitive</literal> is <literal>false</literal>, words in the synonym file
    are folded to lower case, as are input tokens.  When it is
    <literal>true</literal>, words and tokens are not folded to lower case,
    but are compared as-is.
   </para>
________________________________________________________-->
   <para>
    <literal>synonym</literal>模板还有一个可选的参数<literal>CaseSensitive</literal>，其默认值为<literal>false</literal>。当<literal>CaseSensitive</literal>为<literal>false</literal>时，同义词文件中的词被折叠成小写，这和输入记号一样。当它为<literal>true</literal>时，词和记号将不会被折叠成小写，但是比较时就好像被折叠过一样。
   </para>
<!-- pgdoc-cn_end sig_en=297a635ed783de7cf42177d21c446ef8 -->

<!-- pgdoc-cn_start sig_en=2f1e0e79922a59fa8afa06b5a29a1673 sig_cn_org=0dfca308cf853a996df350c90b0e14fa source=15.7 
   <para>
    An asterisk (<literal>*</literal>) can be placed at the end of a synonym
    in the configuration file.  This indicates that the synonym is a prefix.
    The asterisk is ignored when the entry is used in
    <function>to_tsvector()</function>, but when it is used in
    <function>to_tsquery()</function>, the result will be a query item with
    the prefix match marker (see
    <xref linkend="textsearch-parsing-queries"/>).
    For example, suppose we have these entries in
    <filename>$SHAREDIR/tsearch_data/synonym_sample.syn</filename>:
<programlisting>
postgres        pgsql
postgresql      pgsql
postgre pgsql
gogle   googl
indices index*
</programlisting>
    Then we will get these results:
<screen>
mydb=# CREATE TEXT SEARCH DICTIONARY syn (template=synonym, synonyms='synonym_sample');
mydb=# SELECT ts_lexize('syn', 'indices');
 ts_lexize
-&minus;-&minus;-&minus;-&minus;-&minus;-
 {index}
(1 row)

mydb=# CREATE TEXT SEARCH CONFIGURATION tst (copy=simple);
mydb=# ALTER TEXT SEARCH CONFIGURATION tst ALTER MAPPING FOR asciiword WITH syn;
mydb=# SELECT to_tsvector('tst', 'indices');
 to_tsvector
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 'index':1
(1 row)

mydb=# SELECT to_tsquery('tst', 'indices');
 to_tsquery
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 'index':*
(1 row)

mydb=# SELECT 'indexes are very useful'::tsvector;
            tsvector
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 'are' 'indexes' 'useful' 'very'
(1 row)

mydb=# SELECT 'indexes are very useful'::tsvector @@ to_tsquery('tst', 'indices');
 ?column?
-&minus;-&minus;-&minus;-&minus;-&minus;
 t
(1 row)
</screen>
   </para>
________________________________________________________-->
   <para>
    在配置文件中，同义词的末尾可以放置一个星号（<literal>*</literal>）。
    这表示该同义词是一个前缀。当在<function>to_tsvector()</function>中使用该条目时，星号会被忽略，
    但当在<function>to_tsquery()</function>中使用时，结果将是一个带有前缀匹配标记的查询项（参见
    <xref linkend="textsearch-parsing-queries"/>）。
    例如，假设我们在<filename>$SHAREDIR/tsearch_data/synonym_sample.syn</filename>中有以下条目：
<programlisting>
postgres        pgsql
postgresql      pgsql
postgre pgsql
gogle   googl
indices index*
</programlisting>
    那么我们将得到以下结果：
<screen>
mydb=# CREATE TEXT SEARCH DICTIONARY syn (template=synonym, synonyms='synonym_sample');
mydb=# SELECT ts_lexize('syn', 'indices');
 ts_lexize
-----------
 {index}
(1 row)

mydb=# CREATE TEXT SEARCH CONFIGURATION tst (copy=simple);
mydb=# ALTER TEXT SEARCH CONFIGURATION tst ALTER MAPPING FOR asciiword WITH syn;
mydb=# SELECT to_tsvector('tst', 'indices');
 to_tsvector
-------------
 'index':1
(1 row)

mydb=# SELECT to_tsquery('tst', 'indices');
 to_tsquery
------------
 'index':*
(1 row)

mydb=# SELECT 'indexes are very useful'::tsvector;
            tsvector
---------------------------------
 'are' 'indexes' 'useful' 'very'
(1 row)

mydb=# SELECT 'indexes are very useful'::tsvector @@ to_tsquery('tst', 'indices');
 ?column?
----------
 t
(1 row)
</screen>
   </para>
<!-- pgdoc-cn_end sig_en=2f1e0e79922a59fa8afa06b5a29a1673 -->
  </sect2>

  <sect2 id="textsearch-thesaurus">
<!-- pgdoc-cn_start sig_en=df44c836be38c46ed65064aa13ea0715 sig_cn_org=None source=14.1 
   <title>Thesaurus Dictionary</title>
________________________________________________________-->
   <title>分类词典</title>
<!-- pgdoc-cn_end sig_en=df44c836be38c46ed65064aa13ea0715 -->

<!-- pgdoc-cn_start sig_en=683dac9f7dbf7eaa49d0cc70b8ba9f3c sig_cn_org=None source=14.1 
   <para>
    A thesaurus dictionary (sometimes abbreviated as <acronym>TZ</acronym>) is
    a collection of words that includes information about the relationships
    of words and phrases, i.e., broader terms (<acronym>BT</acronym>), narrower
    terms (<acronym>NT</acronym>), preferred terms, non-preferred terms, related
    terms, etc.
   </para>
________________________________________________________-->
   <para>
    一个分类词典（有时被简写成<acronym>TZ</acronym>）是一个词的集合，其中包括了词与短语之间的联系，即广义词（<acronym>BT</acronym>）、狭义词（<acronym>NT</acronym>）、首选词、非首选词、相关词等。
   </para>
<!-- pgdoc-cn_end sig_en=683dac9f7dbf7eaa49d0cc70b8ba9f3c -->

<!-- pgdoc-cn_start sig_en=b3012d07c1cb59e0bcfb21d29ae54812 sig_cn_org=None source=14.1 
   <para>
    Basically a thesaurus dictionary replaces all non-preferred terms by one
    preferred term and, optionally, preserves the original terms for indexing
    as well.  <productname>PostgreSQL</productname>'s current implementation of the
    thesaurus dictionary is an extension of the synonym dictionary with added
    <firstterm>phrase</firstterm> support.  A thesaurus dictionary requires
    a configuration file of the following format:

<programlisting>
# this is a comment
sample word(s) : indexed word(s)
more sample word(s) : more indexed word(s)
...
</programlisting>

    where  the colon (<symbol>:</symbol>) symbol acts as a delimiter between a
    phrase and its replacement.
   </para>
________________________________________________________-->
   <para>
    基本上一个分类词典会用一个首选词替换所有非首选词，并且也可选择地保留原始术语用于索引。<productname>PostgreSQL</productname>的分类词典的当前实现是同义词词典的一个扩展，并增加了<firstterm>短语</firstterm>支持。一个分类词典要求一个下列格式的配置文件：

<programlisting>
# this is a comment
sample word(s) : indexed word(s)
more sample word(s) : more indexed word(s)
...
</programlisting>

    其中冒号（<symbol>:</symbol>）符号扮演了一个短语及其替换之间的定界符。
   </para>
<!-- pgdoc-cn_end sig_en=b3012d07c1cb59e0bcfb21d29ae54812 -->

<!-- pgdoc-cn_start sig_en=af6647707eb67c9fcd815893af1185f0 sig_cn_org=None source=14.1 
   <para>
    A thesaurus dictionary uses a <firstterm>subdictionary</firstterm> (which
    is specified in the dictionary's configuration) to normalize the input
    text before checking for phrase matches. It is only possible to select one
    subdictionary.  An error is reported if the subdictionary fails to
    recognize a word. In that case, you should remove the use of the word or
    teach the subdictionary about it.  You can place an asterisk
    (<symbol>*</symbol>) at the beginning of an indexed word to skip applying
    the subdictionary to it, but all sample words <emphasis>must</emphasis> be known
    to the subdictionary.
   </para>
________________________________________________________-->
   <para>
    一个分类词典使用一个<firstterm>子词典</firstterm>（在词典的配置中指定）在检查短语匹配之前正规化输入文本。只能选择一个子词典。如果子词典无法识别一个词，将报告一个错误。在这种情况下，你应该移除该词的使用或者让子词典学会这个词。你可以在一个被索引词的开头放上一个星号（<symbol>*</symbol>）来跳过在其上应用子词典，但是所有采样词<emphasis>必须</emphasis>被子词典知道。
   </para>
<!-- pgdoc-cn_end sig_en=af6647707eb67c9fcd815893af1185f0 -->

<!-- pgdoc-cn_start sig_en=ddbd13979da8c3c2f729275d25996810 sig_cn_org=None source=14.1 
   <para>
    The thesaurus dictionary chooses the longest match if there are multiple
    phrases matching the input, and ties are broken by using the last
    definition.
   </para>
________________________________________________________-->
   <para>
    如果有多个短语匹配输入，则分类词典选择最长的那一个，并且使用最后的定义打破连结。
   </para>
<!-- pgdoc-cn_end sig_en=ddbd13979da8c3c2f729275d25996810 -->

<!-- pgdoc-cn_start sig_en=aa1d8ccfaa54043fcc10c71be9bafd98 sig_cn_org=None source=14.1 
   <para>
    Specific stop words recognized by the subdictionary cannot be
    specified;  instead use <literal>?</literal> to mark the location where any
    stop word can appear.  For example, assuming that <literal>a</literal> and
    <literal>the</literal> are stop words according to the subdictionary:

<programlisting>
? one ? two : swsw
</programlisting>

    matches <literal>a one the two</literal> and <literal>the one a two</literal>;
    both would be replaced by <literal>swsw</literal>.
   </para>
________________________________________________________-->
   <para>
    由子词典识别的特定停用词不能够被指定；改用<literal>?</literal>标记任何可以出现停用词的地方。例如，假定根据子词典<literal>a</literal>和<literal>the</literal>是停用词：

<programlisting>
? one ? two : swsw
</programlisting>

    匹配<literal>a one the two</literal>和<literal>the one a two</literal>；两者都将被<literal>swsw</literal>替换。
   </para>
<!-- pgdoc-cn_end sig_en=aa1d8ccfaa54043fcc10c71be9bafd98 -->

<!-- pgdoc-cn_start sig_en=fb83d8ab4b2adea1ef33801e5ce7d86d sig_cn_org=None source=14.1 
   <para>
    Since a thesaurus dictionary has the capability to recognize phrases it
    must remember its state and interact with the parser. A thesaurus dictionary
    uses these assignments to check if it should handle the next word or stop
    accumulation.  The thesaurus dictionary must be configured
    carefully. For example, if the thesaurus dictionary is assigned to handle
    only the <literal>asciiword</literal> token, then a thesaurus dictionary
    definition like <literal>one 7</literal> will not work since token type
    <literal>uint</literal> is not assigned to the thesaurus dictionary.
   </para>
________________________________________________________-->
   <para>
    由于一个分类词典具有识别短语的能力，它必须记住它的状态并与解析器交互。一个分类词典使用这些任务来检查它是否应当处理下一个词或者停止累积。分类词典必须被小心地配置。例如，如果分类词典被分配只处理<literal>asciiword</literal>记号，则一个形如<literal>one 7</literal>的分类词典定义将不会工作，因为记号类型<literal>uint</literal>没有被分配给该分类词典。
   </para>
<!-- pgdoc-cn_end sig_en=fb83d8ab4b2adea1ef33801e5ce7d86d -->

   <caution>
<!-- pgdoc-cn_start sig_en=8ac54fa523f54c379d0855e0d5197ccc sig_cn_org=None source=14.1 
    <para>
     Thesauruses are used during indexing so any change in the thesaurus
     dictionary's parameters <emphasis>requires</emphasis> reindexing.
     For most other dictionary types, small changes such as adding or
     removing stopwords does not force reindexing.
    </para>
________________________________________________________-->
    <para>
     在索引期间要用到分类词典，因此分类词典参数中的任何变化都<emphasis>要求</emphasis>重新索引。对于大多数其他索引类型，例如增加或移除停用词等小改动都不会强制重新索引。
    </para>
<!-- pgdoc-cn_end sig_en=8ac54fa523f54c379d0855e0d5197ccc -->
   </caution>

  <sect3 id="textsearch-thesaurus-config">
<!-- pgdoc-cn_start sig_en=c6b94ddff4b3eaca82997014780175e6 sig_cn_org=None source=14.1 
   <title>Thesaurus Configuration</title>
________________________________________________________-->
   <title>分类词典配置</title>
<!-- pgdoc-cn_end sig_en=c6b94ddff4b3eaca82997014780175e6 -->

<!-- pgdoc-cn_start sig_en=c8655f15aa76d5f66bbd95f6c6df653f sig_cn_org=None source=14.1 
   <para>
    To define a new thesaurus dictionary, use the <literal>thesaurus</literal>
    template.  For example:

<programlisting>
CREATE TEXT SEARCH DICTIONARY thesaurus_simple (
    TEMPLATE = thesaurus,
    DictFile = mythesaurus,
    Dictionary = pg_catalog.english_stem
);
</programlisting>

    Here:
    <itemizedlist  spacing="compact" mark="bullet">
     <listitem>
      <para>
       <literal>thesaurus_simple</literal> is the new dictionary's name
      </para>
     </listitem>
     <listitem>
      <para>
       <literal>mythesaurus</literal> is the base name of the thesaurus
       configuration file.
       (Its full name will be <filename>$SHAREDIR/tsearch_data/mythesaurus.ths</filename>,
       where <literal>$SHAREDIR</literal> means the installation shared-data
       directory.)
      </para>
     </listitem>
     <listitem>
      <para>
       <literal>pg_catalog.english_stem</literal> is the subdictionary (here,
       a Snowball English stemmer) to use for thesaurus normalization.
       Notice that the subdictionary will have its own
       configuration (for example, stop words), which is not shown here.
      </para>
     </listitem>
    </itemizedlist>

    Now it is possible to bind the thesaurus dictionary <literal>thesaurus_simple</literal>
    to the desired token types in a configuration, for example:

<programlisting>
ALTER TEXT SEARCH CONFIGURATION russian
    ALTER MAPPING FOR asciiword, asciihword, hword_asciipart
    WITH thesaurus_simple;
</programlisting>
   </para>
________________________________________________________-->
   <para>
    要定义一个新的分类词典，可使用<literal>thesaurus</literal>模板。例如：

<programlisting>
CREATE TEXT SEARCH DICTIONARY thesaurus_simple (
    TEMPLATE = thesaurus,
    DictFile = mythesaurus,
    Dictionary = pg_catalog.english_stem
);
</programlisting>

    这里：
    <itemizedlist  spacing="compact" mark="bullet">
     <listitem>
      <para>
       <literal>thesaurus_simple</literal>是新词典的名称
      </para>
     </listitem>
     <listitem>
      <para>
       <literal>mythesaurus</literal>是分类词典配置文件的基础名称（它的全名将是<filename>$SHAREDIR/tsearch_data/mythesaurus.ths</filename>，其中<literal>$SHAREDIR</literal>表示安装的共享数据目录）。
      </para>
     </listitem>
     <listitem>
      <para>
       <literal>pg_catalog.english_stem</literal>是要用于分类词典正规化的子词典（这里是一个 Snowball 英语词干分析器）。注意子词典将拥有它自己的配置（例如停用词），但这里没有展示。
      </para>
     </listitem>
    </itemizedlist>

    现在可以在配置中把分类词典<literal>thesaurus_simple</literal>绑定到想要的记号类型上，例如：

<programlisting>
ALTER TEXT SEARCH CONFIGURATION russian
    ALTER MAPPING FOR asciiword, asciihword, hword_asciipart
    WITH thesaurus_simple;
</programlisting>
   </para>
<!-- pgdoc-cn_end sig_en=c8655f15aa76d5f66bbd95f6c6df653f -->

  </sect3>

  <sect3 id="textsearch-thesaurus-examples">
<!-- pgdoc-cn_start sig_en=1dec1e46e0d8cf2371474b6d660cf227 sig_cn_org=None source=14.1 
   <title>Thesaurus Example</title>
________________________________________________________-->
   <title>分类词典例子</title>
<!-- pgdoc-cn_end sig_en=1dec1e46e0d8cf2371474b6d660cf227 -->

<!-- pgdoc-cn_start sig_en=341aae504955fa42723e98928be719b8 sig_cn_org=None source=14.1 
   <para>
    Consider a simple astronomical thesaurus <literal>thesaurus_astro</literal>,
    which contains some astronomical word combinations:

<programlisting>
supernovae stars : sn
crab nebulae : crab
</programlisting>

    Below we create a dictionary and bind some token types to
    an astronomical thesaurus and English stemmer:

<programlisting>
CREATE TEXT SEARCH DICTIONARY thesaurus_astro (
    TEMPLATE = thesaurus,
    DictFile = thesaurus_astro,
    Dictionary = english_stem
);

ALTER TEXT SEARCH CONFIGURATION russian
    ALTER MAPPING FOR asciiword, asciihword, hword_asciipart
    WITH thesaurus_astro, english_stem;
</programlisting>

    Now we can see how it works.
    <function>ts_lexize</function> is not very useful for testing a thesaurus,
    because it treats its input as a single token.  Instead we can use
    <function>plainto_tsquery</function> and <function>to_tsvector</function>
    which will break their input strings into multiple tokens:

<screen>
SELECT plainto_tsquery('supernova star');
 plainto_tsquery
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 'sn'

SELECT to_tsvector('supernova star');
 to_tsvector
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 'sn':1
</screen>

    In principle, one can use <function>to_tsquery</function> if you quote
    the argument:

<screen>
SELECT to_tsquery('''supernova star''');
 to_tsquery
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 'sn'
</screen>

    Notice that <literal>supernova star</literal> matches <literal>supernovae
    stars</literal> in <literal>thesaurus_astro</literal> because we specified
    the <literal>english_stem</literal> stemmer in the thesaurus definition.
    The stemmer removed the <literal>e</literal> and <literal>s</literal>.
   </para>
________________________________________________________-->
   <para>
    考虑一个简单的天文学分类词典<literal>thesaurus_astro</literal>，它包含一些天文学词组合：

<programlisting>
supernovae stars : sn
crab nebulae : crab
</programlisting>

    下面我们创建一个词典并绑定一些记号类型到一个天文学分类词典以及英语词干分析器：

<programlisting>
CREATE TEXT SEARCH DICTIONARY thesaurus_astro (
    TEMPLATE = thesaurus,
    DictFile = thesaurus_astro,
    Dictionary = english_stem
);

ALTER TEXT SEARCH CONFIGURATION russian
    ALTER MAPPING FOR asciiword, asciihword, hword_asciipart
    WITH thesaurus_astro, english_stem;
</programlisting>

    现在我们可以看看它如何工作。<function>ts_lexize</function>对于测试一个分类词典用处不大，因为它把它的输入看成是一个单一记号。我们可以用<function>plainto_tsquery</function>和<function>to_tsvector</function>，它们将把其输入字符串打断成多个记号：

<screen>
SELECT plainto_tsquery('supernova star');
 plainto_tsquery
-----------------
 'sn'

SELECT to_tsvector('supernova star');
 to_tsvector
-------------
 'sn':1
</screen>

    原则上，如果你对参数加了引号，你可以使用<function>to_tsquery</function>：

<screen>
SELECT to_tsquery('''supernova star''');
 to_tsquery
------------
 'sn'
</screen>

    注意在<literal>thesaurus_astro</literal>中<literal>supernova star</literal>匹配<literal>supernovae stars</literal>，因为我们在分类词典定义中指定了<literal>english_stem</literal>词干分析器。该词干分析器移除了<literal>e</literal>和<literal>s</literal>。
   </para>
<!-- pgdoc-cn_end sig_en=341aae504955fa42723e98928be719b8 -->

<!-- pgdoc-cn_start sig_en=84f865b0fb4c71010aca7ea6e50f2dbc sig_cn_org=None source=14.1 
   <para>
    To index the original phrase as well as the substitute, just include it
    in the right-hand part of the definition:

<screen>
supernovae stars : sn supernovae stars

SELECT plainto_tsquery('supernova star');
       plainto_tsquery
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 'sn' &amp; 'supernova' &amp; 'star'
</screen>
   </para>
________________________________________________________-->
   <para>
    要和替补一样也索引原始短语，只要将它包含在定义的右手部分中：

<screen>
supernovae stars : sn supernovae stars

SELECT plainto_tsquery('supernova star');
       plainto_tsquery
-----------------------------
 'sn' &amp; 'supernova' &amp; 'star'
</screen>
   </para>
<!-- pgdoc-cn_end sig_en=84f865b0fb4c71010aca7ea6e50f2dbc -->

  </sect3>

  </sect2>

  <sect2 id="textsearch-ispell-dictionary">
<!-- pgdoc-cn_start sig_en=96cc941a0a1ff5c99fa4ec4568944454 sig_cn_org=None source=14.1 
   <title><application>Ispell</application> Dictionary</title>
________________________________________________________-->
   <title><application>Ispell</application> 词典</title>
<!-- pgdoc-cn_end sig_en=96cc941a0a1ff5c99fa4ec4568944454 -->

<!-- pgdoc-cn_start sig_en=69d719a4dd079b70d2aa7ca434117dc9 sig_cn_org=None source=14.1 
   <para>
    The <application>Ispell</application> dictionary template supports
    <firstterm>morphological dictionaries</firstterm>, which can normalize many
    different linguistic forms of a word into the same lexeme.  For example,
    an English <application>Ispell</application> dictionary can match all declensions and
    conjugations of the search term <literal>bank</literal>, e.g.,
    <literal>banking</literal>, <literal>banked</literal>, <literal>banks</literal>,
    <literal>banks'</literal>, and <literal>bank's</literal>.
   </para>
________________________________________________________-->
   <para>
    <application>Ispell</application>词典模板支持<firstterm>词法词典</firstterm>，它可以把一个词的很多不同语言学的形式正规化成相同的词位。例如，一个英语<application>Ispell</application>词典可以匹配搜索词<literal>bank</literal>的词尾变化和词形变化，例如<literal>banking</literal>、<literal>banked</literal>、<literal>banks</literal>、<literal>banks'</literal>和<literal>bank's</literal>。
   </para>
<!-- pgdoc-cn_end sig_en=69d719a4dd079b70d2aa7ca434117dc9 -->

<!-- pgdoc-cn_start sig_en=9e12998b0c6fee695e702e8764cf0fcd sig_cn_org=a04468cbbafc91c2b5989c391adca0d5 source=15.7 
   <para>
    The standard <productname>PostgreSQL</productname> distribution does
    not include any <application>Ispell</application> configuration files.
    Dictionaries for a large number of languages are available from <ulink
    url="https://www.cs.hmc.edu/~geoff/ispell.html">Ispell</ulink>.
    Also, some more modern dictionary file formats are supported &mdash; <ulink
    url="https://en.wikipedia.org/wiki/MySpell">MySpell</ulink> (OO &lt; 2.0.1)
    and <ulink url="https://hunspell.github.io/">Hunspell</ulink>
    (OO &gt;= 2.0.2).  A large list of dictionaries is available on the <ulink
    url="https://wiki.openoffice.org/wiki/Dictionaries">OpenOffice
    Wiki</ulink>.
   </para>
________________________________________________________-->
   <para>
    标准<productname>PostgreSQL</productname>发行版不包含任何<application>Ispell</application>配置文件。
    大量语言的词典可从<ulink url="https://www.cs.hmc.edu/~geoff/ispell.html">Ispell</ulink>获取。
    此外，还支持一些更现代的词典文件格式 &mdash; <ulink url="https://en.wikipedia.org/wiki/MySpell">MySpell</ulink> (OO &lt; 2.0.1)
    和<ulink url="https://hunspell.github.io/">Hunspell</ulink>(OO &gt;= 2.0.2)。在<ulink url="https://wiki.openoffice.org/wiki/Dictionaries">OpenOffice
    Wiki</ulink>上有大量词典可用。
   </para>
<!-- pgdoc-cn_end sig_en=9e12998b0c6fee695e702e8764cf0fcd -->

<!-- pgdoc-cn_start sig_en=30280774555557f9a84cb98b57067dff sig_cn_org=None source=14.1 
   <para>
    To create an <application>Ispell</application> dictionary perform these steps:
   </para>
________________________________________________________-->
   <para>
    要创建一个<application>Ispell</application>词典，执行这三步：
   </para>
<!-- pgdoc-cn_end sig_en=30280774555557f9a84cb98b57067dff -->
   <itemizedlist spacing="compact" mark="bullet">
    <listitem>
<!-- pgdoc-cn_start sig_en=49c0730e0930a26461c2be61896873c0 sig_cn_org=None source=14.1 
     <para>
      download dictionary configuration files. <productname>OpenOffice</productname>
      extension files have the <filename>.oxt</filename> extension. It is necessary
      to extract <filename>.aff</filename> and <filename>.dic</filename> files, change
      extensions to <filename>.affix</filename> and <filename>.dict</filename>. For some
      dictionary files it is also needed to convert characters to the UTF-8
      encoding with commands (for example, for a Norwegian language dictionary):
<programlisting>
iconv -f ISO_8859-1 -t UTF-8 -o nn_no.affix nn_NO.aff
iconv -f ISO_8859-1 -t UTF-8 -o nn_no.dict nn_NO.dic
</programlisting>
     </para>
________________________________________________________-->
     <para>
      下载词典配置文件。<productname>OpenOffice</productname>扩展文件的扩展名是<filename>.oxt</filename>。有必要抽取<filename>.aff</filename>和<filename>.dic</filename>文件，把扩展改为<filename>.affix</filename>和<filename>.dict</filename>。对于某些词典文件，还需要使用下面的命令把字符转换成 UTF-8 编码（例如挪威语词典）：
<programlisting>
iconv -f ISO_8859-1 -t UTF-8 -o nn_no.affix nn_NO.aff
iconv -f ISO_8859-1 -t UTF-8 -o nn_no.dict nn_NO.dic
</programlisting>
     </para>
<!-- pgdoc-cn_end sig_en=49c0730e0930a26461c2be61896873c0 -->
    </listitem>
    <listitem>
<!-- pgdoc-cn_start sig_en=2856ad7c4d25b12563be2cab334f6d86 sig_cn_org=None source=14.1 
     <para>
      copy files to the <filename>$SHAREDIR/tsearch_data</filename> directory
     </para>
________________________________________________________-->
     <para>
      拷贝文件到<filename>$SHAREDIR/tsearch_data</filename>目录
     </para>
<!-- pgdoc-cn_end sig_en=2856ad7c4d25b12563be2cab334f6d86 -->
    </listitem>
    <listitem>
<!-- pgdoc-cn_start sig_en=196ecec0b3e306134082363f192455df sig_cn_org=None source=14.1 
     <para>
      load files into PostgreSQL with the following command:
<programlisting>
CREATE TEXT SEARCH DICTIONARY english_hunspell (
    TEMPLATE = ispell,
    DictFile = en_us,
    AffFile = en_us,
    Stopwords = english);
</programlisting>
     </para>
________________________________________________________-->
     <para>
      用下面的命令把文件载入到 PostgreSQL：
<programlisting>
CREATE TEXT SEARCH DICTIONARY english_hunspell (
    TEMPLATE = ispell,
    DictFile = en_us,
    AffFile = en_us,
    Stopwords = english);
</programlisting>
     </para>
<!-- pgdoc-cn_end sig_en=196ecec0b3e306134082363f192455df -->
    </listitem>
   </itemizedlist>

<!-- pgdoc-cn_start sig_en=2a12e2a27dfdf42fcad72ff2cca3629c sig_cn_org=None source=14.1 
   <para>
    Here, <literal>DictFile</literal>, <literal>AffFile</literal>, and <literal>StopWords</literal>
    specify the base names of the dictionary, affixes, and stop-words files.
    The stop-words file has the same format explained above for the
    <literal>simple</literal> dictionary type.  The format of the other files is
    not specified here but is available from the above-mentioned web sites.
   </para>
________________________________________________________-->
   <para>
    这里，<literal>DictFile</literal>、<literal>AffFile</literal>和<literal>StopWords</literal>指定词典、词缀和停用词文件的基础名称。停用词文件的格式和前面解释的<literal>simple</literal>词典类型相同。其他文件的格式在这里没有指定，但是也可以从上面提到的网站获得。
   </para>
<!-- pgdoc-cn_end sig_en=2a12e2a27dfdf42fcad72ff2cca3629c -->

<!-- pgdoc-cn_start sig_en=c952e36c8deb7c980a9053456f79b76f sig_cn_org=None source=14.1 
   <para>
    Ispell dictionaries usually recognize a limited set of words, so they
    should be followed by another broader dictionary; for
    example, a Snowball dictionary, which recognizes everything.
   </para>
________________________________________________________-->
   <para>
    Ispell 词典通常识别一个有限集合的词，这样它们后面应该跟着另一个更广义的词典；例如，一个 Snowball 词典，它可以识别所有东西。
   </para>
<!-- pgdoc-cn_end sig_en=c952e36c8deb7c980a9053456f79b76f -->

<!-- pgdoc-cn_start sig_en=ae17c43818dd8742617d32c92a9875e5 sig_cn_org=None source=14.1 
   <para>
    The <filename>.affix</filename> file of <application>Ispell</application> has the following
    structure:
<programlisting>
prefixes
flag *A:
    .           >   RE      # As in enter > reenter
suffixes
flag T:
    E           >   ST      # As in late > latest
    [^AEIOU]Y   >   -Y,IEST # As in dirty > dirtiest
    [AEIOU]Y    >   EST     # As in gray > grayest
    [^EY]       >   EST     # As in small > smallest
</programlisting>
   </para>
________________________________________________________-->
   <para>
    <application>Ispell</application>的<filename>.affix</filename>文件具有下面的结构：
<programlisting>
prefixes
flag *A:
    .           >   RE      # As in enter > reenter
suffixes
flag T:
    E           >   ST      # As in late > latest
    [^AEIOU]Y   >   -Y,IEST # As in dirty > dirtiest
    [AEIOU]Y    >   EST     # As in gray > grayest
    [^EY]       >   EST     # As in small > smallest
</programlisting>
   </para>
<!-- pgdoc-cn_end sig_en=ae17c43818dd8742617d32c92a9875e5 -->
<!-- pgdoc-cn_start sig_en=ef50e6a836f88f30a03cf4c93d55ae4e sig_cn_org=None source=14.1 
   <para>
    And the <filename>.dict</filename> file has the following structure:
<programlisting>
lapse/ADGRS
lard/DGRS
large/PRTY
lark/MRS
</programlisting>
   </para>
________________________________________________________-->
   <para>
    <filename>.dict</filename>文件具有下面的结构：
<programlisting>
lapse/ADGRS
lard/DGRS
large/PRTY
lark/MRS
</programlisting>
   </para>
<!-- pgdoc-cn_end sig_en=ef50e6a836f88f30a03cf4c93d55ae4e -->

<!-- pgdoc-cn_start sig_en=f8a1cefb28e1da63371a799e518547fb sig_cn_org=None source=14.1 
   <para>
    Format of the <filename>.dict</filename> file is:
<programlisting>
basic_form/affix_class_name
</programlisting>
   </para>
________________________________________________________-->
   <para>
    <filename>.dict</filename>文件的格式是：
<programlisting>
basic_form/affix_class_name
</programlisting>
   </para>
<!-- pgdoc-cn_end sig_en=f8a1cefb28e1da63371a799e518547fb -->

<!-- pgdoc-cn_start sig_en=8478f8f6a1e993a400f7d776da4cc784 sig_cn_org=None source=14.1 
   <para>
    In the <filename>.affix</filename> file every affix flag is described in the
    following format:
<programlisting>
condition > [-stripping_letters,] adding_affix
</programlisting>
   </para>
________________________________________________________-->
   <para>
    在<filename>.affix</filename>文件中，每一个词缀标志以下面的格式描述：
<programlisting>
condition > [-stripping_letters,] adding_affix
</programlisting>
   </para>
<!-- pgdoc-cn_end sig_en=8478f8f6a1e993a400f7d776da4cc784 -->

<!-- pgdoc-cn_start sig_en=475331e9d7de12a65006459d1ff54d40 sig_cn_org=None source=14.1 
   <para>
    Here, condition has a format similar to the format of regular expressions.
    It can use groupings <literal>[...]</literal> and <literal>[^...]</literal>.
    For example, <literal>[AEIOU]Y</literal> means that the last letter of the word
    is <literal>"y"</literal> and the penultimate letter is <literal>"a"</literal>,
    <literal>"e"</literal>, <literal>"i"</literal>, <literal>"o"</literal> or <literal>"u"</literal>.
    <literal>[^EY]</literal> means that the last letter is neither <literal>"e"</literal>
    nor <literal>"y"</literal>.
   </para>
________________________________________________________-->
   <para>
    这里的条件具有和正则表达式相似的格式。它可以使用分组<literal>[...]</literal>和<literal>[^...]</literal>。例如，<literal>[AEIOU]Y</literal>表示词的最后一个字母是<literal>"y"</literal>并且倒数第二个字母是<literal>"a"</literal>、<literal>"e"</literal>、<literal>"i"</literal>、<literal>"o"</literal>或者<literal>"u"</literal>。<literal>[^EY]</literal>表示最后一个字母既不是<literal>"e"</literal>也不是<literal>"y"</literal>。
   </para>
<!-- pgdoc-cn_end sig_en=475331e9d7de12a65006459d1ff54d40 -->

<!-- pgdoc-cn_start sig_en=abff2abedcf5f0fd87ade6eedb5bd18b sig_cn_org=None source=14.1 
   <para>
    Ispell dictionaries support splitting compound words;
    a useful feature.
    Notice that the affix file should specify a special flag using the
    <literal>compoundwords controlled</literal> statement that marks dictionary
    words that can participate in compound formation:

<programlisting>
compoundwords  controlled z
</programlisting>

    Here are some examples for the Norwegian language:

<programlisting>
SELECT ts_lexize('norwegian_ispell', 'overbuljongterningpakkmesterassistent');
   {over,buljong,terning,pakk,mester,assistent}
SELECT ts_lexize('norwegian_ispell', 'sjokoladefabrikk');
   {sjokoladefabrikk,sjokolade,fabrikk}
</programlisting>
   </para>
________________________________________________________-->
   <para>
    Ispell 词典支持划分复合词，这是一个有用的特性。注意词缀文件应该用<literal>compoundwords controlled</literal>语句指定一个特殊标志，它标记可以参与到复合格式中的词典词：

<programlisting>
compoundwords  controlled z
</programlisting>

    下面是挪威语的一些例子：

<programlisting>
SELECT ts_lexize('norwegian_ispell', 'overbuljongterningpakkmesterassistent');
   {over,buljong,terning,pakk,mester,assistent}
SELECT ts_lexize('norwegian_ispell', 'sjokoladefabrikk');
   {sjokoladefabrikk,sjokolade,fabrikk}
</programlisting>
   </para>
<!-- pgdoc-cn_end sig_en=abff2abedcf5f0fd87ade6eedb5bd18b -->

<!-- pgdoc-cn_start sig_en=3e6addf95a7265b73dcfa3a640041f46 sig_cn_org=None source=14.1 
   <para>
    <application>MySpell</application> format is a subset of <application>Hunspell</application>.
    The <filename>.affix</filename> file of <application>Hunspell</application> has the following
    structure:
<programlisting>
PFX A Y 1
PFX A   0     re         .
SFX T N 4
SFX T   0     st         e
SFX T   y     iest       [^aeiou]y
SFX T   0     est        [aeiou]y
SFX T   0     est        [^ey]
</programlisting>
   </para>
________________________________________________________-->
   <para>
    <application>MySpell</application>格式是<application>Hunspell</application>格式的一个子集。<application>Hunspell</application>的<filename>.affix</filename>文件具有下面的结构：
<programlisting>
PFX A Y 1
PFX A   0     re         .
SFX T N 4
SFX T   0     st         e
SFX T   y     iest       [^aeiou]y
SFX T   0     est        [aeiou]y
SFX T   0     est        [^ey]
</programlisting>
   </para>
<!-- pgdoc-cn_end sig_en=3e6addf95a7265b73dcfa3a640041f46 -->

<!-- pgdoc-cn_start sig_en=763d0f3226f188fa1f1411d21254ea8a sig_cn_org=None source=14.1 
   <para>
    The first line of an affix class is the header. Fields of an affix rules are
    listed after the header:
   </para>
________________________________________________________-->
   <para>
    一个词缀类的第一行是头部。头部后面列出了词缀规则的域：
   </para>
<!-- pgdoc-cn_end sig_en=763d0f3226f188fa1f1411d21254ea8a -->
   <itemizedlist spacing="compact" mark="bullet">
    <listitem>
<!-- pgdoc-cn_start sig_en=a1fca2a8e6fb18de5036cf7fa6e8de3e sig_cn_org=None source=14.1 
     <para>
      parameter name (PFX or SFX)
     </para>
________________________________________________________-->
     <para>
      参数名（PFX 或者 SFX）
     </para>
<!-- pgdoc-cn_end sig_en=a1fca2a8e6fb18de5036cf7fa6e8de3e -->
    </listitem>
    <listitem>
<!-- pgdoc-cn_start sig_en=d0eb9094bad92ecc2c874a823d48d993 sig_cn_org=None source=14.1 
     <para>
      flag (name of the affix class)
     </para>
________________________________________________________-->
     <para>
      标志（词缀类的名称）
     </para>
<!-- pgdoc-cn_end sig_en=d0eb9094bad92ecc2c874a823d48d993 -->
    </listitem>
    <listitem>
<!-- pgdoc-cn_start sig_en=e8ad2190a807953cca0e2dd532e1d88f sig_cn_org=None source=14.1 
     <para>
      stripping characters from beginning (at prefix) or end (at suffix) of the
      word
     </para>
________________________________________________________-->
     <para>
      从该词的开始（前缀）或者结尾（后缀）剥离字符
     </para>
<!-- pgdoc-cn_end sig_en=e8ad2190a807953cca0e2dd532e1d88f -->
    </listitem>
    <listitem>
<!-- pgdoc-cn_start sig_en=bf80aa206a5f12b61c76bd7492c14bcf sig_cn_org=None source=14.1 
     <para>
      adding affix
     </para>
________________________________________________________-->
     <para>
      增加词缀
     </para>
<!-- pgdoc-cn_end sig_en=bf80aa206a5f12b61c76bd7492c14bcf -->
    </listitem>
    <listitem>
<!-- pgdoc-cn_start sig_en=7b70c4c3272b1d73c44b4549b9c4e394 sig_cn_org=None source=14.1 
     <para>
      condition that has a format similar to the format of regular expressions.
     </para>
________________________________________________________-->
     <para>
      和正则表达式格式类似的条件。
     </para>
<!-- pgdoc-cn_end sig_en=7b70c4c3272b1d73c44b4549b9c4e394 -->
    </listitem>
   </itemizedlist>

<!-- pgdoc-cn_start sig_en=cb3c75708a1c6a4c0cad48af52a60828 sig_cn_org=None source=14.1 
   <para>
    The <filename>.dict</filename> file looks like the <filename>.dict</filename> file of
    <application>Ispell</application>:
<programlisting>
larder/M
lardy/RT
large/RSPMYT
largehearted
</programlisting>
   </para>
________________________________________________________-->
   <para>
    <filename>.dict</filename>文件看起来和<application>Ispell</application>的<filename>.dict</filename>文件相似：
<programlisting>
larder/M
lardy/RT
large/RSPMYT
largehearted
</programlisting>
   </para>
<!-- pgdoc-cn_end sig_en=cb3c75708a1c6a4c0cad48af52a60828 -->

   <note>
<!-- pgdoc-cn_start sig_en=82c2129e23bcd94d49bc83b34cb0427e sig_cn_org=None source=14.1 
    <para>
     <application>MySpell</application> does not support compound words.
     <application>Hunspell</application> has sophisticated support for compound words. At
     present, <productname>PostgreSQL</productname> implements only the basic
     compound word operations of Hunspell.
    </para>
________________________________________________________-->
    <para>
     <application>MySpell</application> 不支持复合词。<application>Hunspell</application>则对复合词有更好的支持。当前，<productname>PostgreSQL</productname>只实现了 Hunspell 中基本的复合词操作。
    </para>
<!-- pgdoc-cn_end sig_en=82c2129e23bcd94d49bc83b34cb0427e -->
   </note>

  </sect2>

  <sect2 id="textsearch-snowball-dictionary">
<!-- pgdoc-cn_start sig_en=59efeaf64a5cdb8fdae0a093f7e295b3 sig_cn_org=None source=14.1 
   <title><application>Snowball</application> Dictionary</title>
________________________________________________________-->
   <title><application>Snowball</application> 词典</title>
<!-- pgdoc-cn_end sig_en=59efeaf64a5cdb8fdae0a093f7e295b3 -->

<!-- pgdoc-cn_start sig_en=d7801623873e9ba5a98474b36b00a9d6 sig_cn_org=None source=14.1 
   <para>
    The <application>Snowball</application> dictionary template is based on a project
    by Martin Porter, inventor of the popular Porter's stemming algorithm
    for the English language.  Snowball now provides stemming algorithms for
    many languages (see the <ulink url="https://snowballstem.org/">Snowball
    site</ulink> for more information).  Each algorithm understands how to
    reduce common variant forms of words to a base, or stem, spelling within
    its language.  A Snowball dictionary requires a <literal>language</literal>
    parameter to identify which stemmer to use, and optionally can specify a
    <literal>stopword</literal> file name that gives a list of words to eliminate.
    (<productname>PostgreSQL</productname>'s standard stopword lists are also
    provided by the Snowball project.)
    For example, there is a built-in definition equivalent to

<programlisting>
CREATE TEXT SEARCH DICTIONARY english_stem (
    TEMPLATE = snowball,
    Language = english,
    StopWords = english
);
</programlisting>

    The stopword file format is the same as already explained.
   </para>
________________________________________________________-->
   <para>
    <application>Snowball</application>词典模板基于 Martin Porter 的一个项目，他是流行的英语 Porter 词干分析算法的发明者。Snowball 现在对许多语言提供词干分析算法（详见<ulink url="https://snowballstem.org/">Snowball 站点</ulink>）。每一个算法懂得按照其语言中的拼写，如何缩减词的常见变体形式为一个基础或词干。一个 Snowball 词典要求一个<literal>language</literal>参数来标识要用哪种词干分析器，并且可以选择地指定一个<literal>stopword</literal>文件名来给出一个要被消除的词列表（<productname>PostgreSQL</productname>的标准停用词列表也是由 Snowball 项目提供的）。例如，有一个内建的定义等效于

<programlisting>
CREATE TEXT SEARCH DICTIONARY english_stem (
    TEMPLATE = snowball,
    Language = english,
    StopWords = english
);
</programlisting>

    停用词文件格式和已经解释的一样。
   </para>
<!-- pgdoc-cn_end sig_en=d7801623873e9ba5a98474b36b00a9d6 -->

<!-- pgdoc-cn_start sig_en=b55fb7f8e989509a1a777e0e2c08fdf9 sig_cn_org=None source=14.1 
   <para>
    A <application>Snowball</application> dictionary recognizes everything, whether
    or not it is able to simplify the word, so it should be placed
    at the end of the dictionary list. It is useless to have it
    before any other dictionary because a token will never pass through it to
    the next dictionary.
   </para>
________________________________________________________-->
   <para>
    一个<application>Snowball</application>词典识别所有的东西，不管它能不能简化该词，因此它应当被放置在词典列表的最后。把它放在任何其他词典前面是没有用处的，因为一个记号永远不会穿过它而进入到下一个词典。
   </para>
<!-- pgdoc-cn_end sig_en=b55fb7f8e989509a1a777e0e2c08fdf9 -->

  </sect2>

 </sect1>

 <sect1 id="textsearch-configuration">
<!-- pgdoc-cn_start sig_en=5dd92c17cdc9ea1b9dd7c900c50abe57 sig_cn_org=None source=14.1 
  <title>Configuration Example</title>
________________________________________________________-->
  <title>配置例子</title>
<!-- pgdoc-cn_end sig_en=5dd92c17cdc9ea1b9dd7c900c50abe57 -->

<!-- pgdoc-cn_start sig_en=21c857fae83863204cb789556692ce00 sig_cn_org=None source=14.1 
   <para>
    A text search configuration specifies all options necessary to transform a
    document into a <type>tsvector</type>: the parser to use to break text
    into tokens, and the dictionaries to use to transform each token into a
    lexeme.  Every call of
    <function>to_tsvector</function> or <function>to_tsquery</function>
    needs a text search configuration to perform its processing.
    The configuration parameter
    <xref linkend="guc-default-text-search-config"/>
    specifies the name of the default configuration, which is the
    one used by text search functions if an explicit configuration
    parameter is omitted.
    It can be set in <filename>postgresql.conf</filename>, or set for an
    individual session using the <command>SET</command> command.
   </para>
________________________________________________________-->
   <para>
    一个文本搜索配置指定了将一个文档转换成一个<type>tsvector</type>所需的所有选项：用于把文本分解成记号的解析器，以及用于将每一个记号转换成词位的词典。每一次<function>to_tsvector</function>或<function>to_tsquery</function>的调用都需要一个文本搜索配置来执行其处理。配置参数<xref linkend="guc-default-text-search-config"/>指定了默认配置的名称，如果忽略了显式的配置参数，文本搜索函数将会使用它。它可以在<filename>postgresql.conf</filename>中设置，或者使用<command>SET</command>命令为一个单独的会话设置。
   </para>
<!-- pgdoc-cn_end sig_en=21c857fae83863204cb789556692ce00 -->

<!-- pgdoc-cn_start sig_en=f8d1fc3b4cf3be4b5960f0aaf5f20626 sig_cn_org=None source=14.1 
   <para>
    Several predefined text search configurations are available, and
    you can create custom configurations easily.  To facilitate management
    of text search objects, a set of <acronym>SQL</acronym> commands
    is available, and there are several <application>psql</application> commands that display information
    about text search objects (<xref linkend="textsearch-psql"/>).
   </para>
________________________________________________________-->
   <para>
    有一些预定义的文本搜索配置可用，并且你可以容易地创建自定义的配置。为了便于管理文本搜索对象，可以使用一组<acronym>SQL</acronym>命令，并且有多个<application>psql</application>命令可以显示有关文本搜索对象（<xref linkend="textsearch-psql"/>）的信息。
   </para>
<!-- pgdoc-cn_end sig_en=f8d1fc3b4cf3be4b5960f0aaf5f20626 -->

<!-- pgdoc-cn_start sig_en=7d96516ff3b64e84d4e8ba3d55ef4613 sig_cn_org=None source=14.1 
   <para>
    As an example we will create a configuration
    <literal>pg</literal>, starting by duplicating the built-in
    <literal>english</literal> configuration:

<programlisting>
CREATE TEXT SEARCH CONFIGURATION public.pg ( COPY = pg_catalog.english );
</programlisting>
   </para>
________________________________________________________-->
   <para>
    作为一个例子，我们将创建一个配置<literal>pg</literal>，从复制内建的<literal>english</literal>配置开始：

<programlisting>
CREATE TEXT SEARCH CONFIGURATION public.pg ( COPY = pg_catalog.english );
</programlisting>
   </para>
<!-- pgdoc-cn_end sig_en=7d96516ff3b64e84d4e8ba3d55ef4613 -->

<!-- pgdoc-cn_start sig_en=50fa8b5b8d77188151f38c0d3e9f7506 sig_cn_org=None source=14.1 
   <para>
    We will use a PostgreSQL-specific synonym list
    and store it in <filename>$SHAREDIR/tsearch_data/pg_dict.syn</filename>.
    The file contents look like:

<programlisting>
postgres    pg
pgsql       pg
postgresql  pg
</programlisting>

    We define the synonym dictionary like this:

<programlisting>
CREATE TEXT SEARCH DICTIONARY pg_dict (
    TEMPLATE = synonym,
    SYNONYMS = pg_dict
);
</programlisting>

    Next we register the <productname>Ispell</productname> dictionary
    <literal>english_ispell</literal>, which has its own configuration files:

<programlisting>
CREATE TEXT SEARCH DICTIONARY english_ispell (
    TEMPLATE = ispell,
    DictFile = english,
    AffFile = english,
    StopWords = english
);
</programlisting>

    Now we can set up the mappings for words in configuration
    <literal>pg</literal>:

<programlisting>
ALTER TEXT SEARCH CONFIGURATION pg
    ALTER MAPPING FOR asciiword, asciihword, hword_asciipart,
                      word, hword, hword_part
    WITH pg_dict, english_ispell, english_stem;
</programlisting>

    We choose not to index or search some token types that the built-in
    configuration does handle:

<programlisting>
ALTER TEXT SEARCH CONFIGURATION pg
    DROP MAPPING FOR email, url, url_path, sfloat, float;
</programlisting>
   </para>
________________________________________________________-->
   <para>
    我们将使用一个 PostgreSQL 相关的同义词列表，并将它存储在<filename>$SHAREDIR/tsearch_data/pg_dict.syn</filename>中。文件内容看起来像：

<programlisting>
postgres    pg
pgsql       pg
postgresql  pg
</programlisting>

    我们定义同义词词典如下：

<programlisting>
CREATE TEXT SEARCH DICTIONARY pg_dict (
    TEMPLATE = synonym,
    SYNONYMS = pg_dict
);
</programlisting>

    接下来我们注册<productname>Ispell</productname>词典<literal>english_ispell</literal>，它有其自己的配置文件：

<programlisting>
CREATE TEXT SEARCH DICTIONARY english_ispell (
    TEMPLATE = ispell,
    DictFile = english,
    AffFile = english,
    StopWords = english
);
</programlisting>

    现在我们可以在配置<literal>pg</literal>中建立词的映射：

<programlisting>
ALTER TEXT SEARCH CONFIGURATION pg
    ALTER MAPPING FOR asciiword, asciihword, hword_asciipart,
                      word, hword, hword_part
    WITH pg_dict, english_ispell, english_stem;
</programlisting>

    我们选择不索引或搜索某些内建配置确实处理的记号类型：

<programlisting>
ALTER TEXT SEARCH CONFIGURATION pg
    DROP MAPPING FOR email, url, url_path, sfloat, float;
</programlisting>
   </para>
<!-- pgdoc-cn_end sig_en=50fa8b5b8d77188151f38c0d3e9f7506 -->

<!-- pgdoc-cn_start sig_en=54ac9b06c3c88abbd60d57577377de76 sig_cn_org=None source=14.1 
   <para>
    Now we can test our configuration:

<programlisting>
SELECT * FROM ts_debug('public.pg', '
PostgreSQL, the highly scalable, SQL compliant, open source object-relational
database management system, is now undergoing beta testing of the next
version of our software.
');
</programlisting>
   </para>
________________________________________________________-->
   <para>
    现在我们可以测试我们的配置：

<programlisting>
SELECT * FROM ts_debug('public.pg', '
PostgreSQL, the highly scalable, SQL compliant, open source object-relational
database management system, is now undergoing beta testing of the next
version of our software.
');
</programlisting>
   </para>
<!-- pgdoc-cn_end sig_en=54ac9b06c3c88abbd60d57577377de76 -->

<!-- pgdoc-cn_start sig_en=c5eff9e2fdb983dc402db453b014786b sig_cn_org=None source=14.1 
   <para>
    The next step is to set the session to use the new configuration, which was
    created in the <literal>public</literal> schema:

<screen>
=&gt; \dF
   List of text search configurations
 Schema  | Name | Description
-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 public  | pg   |

SET default_text_search_config = 'public.pg';
SET

SHOW default_text_search_config;
 default_text_search_config
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 public.pg
</screen>
  </para>
________________________________________________________-->
   <para>
    下一个步骤是设置会话让它使用新配置，它被创建在<literal>public</literal>模式中：

<screen>
=&gt; \dF
   List of text search configurations
 Schema  | Name | Description
---------+------+-------------
 public  | pg   |

SET default_text_search_config = 'public.pg';
SET

SHOW default_text_search_config;
 default_text_search_config
----------------------------
 public.pg
</screen>
  </para>
<!-- pgdoc-cn_end sig_en=c5eff9e2fdb983dc402db453b014786b -->

 </sect1>

 <sect1 id="textsearch-debugging">
<!-- pgdoc-cn_start sig_en=97a93e15cba90969f59587af9f8b8350 sig_cn_org=None source=14.1 
  <title>Testing and Debugging Text Search</title>
________________________________________________________-->
  <title>测试和调试文本搜索</title>
<!-- pgdoc-cn_end sig_en=97a93e15cba90969f59587af9f8b8350 -->

<!-- pgdoc-cn_start sig_en=a0dc042bfba6390c074df28644cf76f6 sig_cn_org=None source=14.1 
  <para>
   The behavior of a custom text search configuration can easily become
   confusing.  The functions described
   in this section are useful for testing text search objects.  You can
   test a complete configuration, or test parsers and dictionaries separately.
  </para>
________________________________________________________-->
  <para>
   一个自定义文本搜索配置的行为很容易变得混乱。本节中描述的函数对于测试文本搜索对象有用。你可以测试一个完整的配置，或者独立测试解析器和词典。
  </para>
<!-- pgdoc-cn_end sig_en=a0dc042bfba6390c074df28644cf76f6 -->

  <sect2 id="textsearch-configuration-testing">
<!-- pgdoc-cn_start sig_en=fcad2b2d4899ee50e591bd18adbab863 sig_cn_org=None source=14.1 
   <title>Configuration Testing</title>
________________________________________________________-->
   <title>配置测试</title>
<!-- pgdoc-cn_end sig_en=fcad2b2d4899ee50e591bd18adbab863 -->

<!-- pgdoc-cn_start sig_en=bdd71c4dc2e10d2b80ae6886addf9234 sig_cn_org=None source=14.1 
  <para>
   The function <function>ts_debug</function> allows easy testing of a
   text search configuration.
  </para>
________________________________________________________-->
  <para>
   函数<function>ts_debug</function>允许简单地测试一个文本搜索配置。
  </para>
<!-- pgdoc-cn_end sig_en=bdd71c4dc2e10d2b80ae6886addf9234 -->

<!-- pgdoc-cn_start sig_en=d254fb055b6e3827dd800203b05e1639 sig_cn_org=None source=14.1 
  <indexterm>
   <primary>ts_debug</primary>
  </indexterm>
________________________________________________________-->
  <indexterm>
   <primary>ts_debug</primary>
  </indexterm>
<!-- pgdoc-cn_end sig_en=d254fb055b6e3827dd800203b05e1639 -->

<!-- pgdoc-cn_start sig_en=18f87f8c379751b3a339eccc06fbd63a sig_cn_org=None source=14.1 
<synopsis>
ts_debug(<optional> <replaceable class="parameter">config</replaceable> <type>regconfig</type>, </optional> <replaceable class="parameter">document</replaceable> <type>text</type>,
         OUT <replaceable class="parameter">alias</replaceable> <type>text</type>,
         OUT <replaceable class="parameter">description</replaceable> <type>text</type>,
         OUT <replaceable class="parameter">token</replaceable> <type>text</type>,
         OUT <replaceable class="parameter">dictionaries</replaceable> <type>regdictionary[]</type>,
         OUT <replaceable class="parameter">dictionary</replaceable> <type>regdictionary</type>,
         OUT <replaceable class="parameter">lexemes</replaceable> <type>text[]</type>)
         returns setof record
</synopsis>
________________________________________________________-->
<synopsis>
ts_debug(<optional> <replaceable class="parameter">config</replaceable> <type>regconfig</type>, </optional> <replaceable class="parameter">document</replaceable> <type>text</type>,
         OUT <replaceable class="parameter">alias</replaceable> <type>text</type>,
         OUT <replaceable class="parameter">description</replaceable> <type>text</type>,
         OUT <replaceable class="parameter">token</replaceable> <type>text</type>,
         OUT <replaceable class="parameter">dictionaries</replaceable> <type>regdictionary[]</type>,
         OUT <replaceable class="parameter">dictionary</replaceable> <type>regdictionary</type>,
         OUT <replaceable class="parameter">lexemes</replaceable> <type>text[]</type>)
         returns setof record
</synopsis>
<!-- pgdoc-cn_end sig_en=18f87f8c379751b3a339eccc06fbd63a -->

<!-- pgdoc-cn_start sig_en=4af3af60dcf4b91fd9d486b80c5ba4d5 sig_cn_org=None source=14.1 
  <para>
   <function>ts_debug</function> displays information about every token of
   <replaceable class="parameter">document</replaceable> as produced by the
   parser and processed by the configured dictionaries.  It uses the
   configuration specified by <replaceable
   class="parameter">config</replaceable>,
   or <varname>default_text_search_config</varname> if that argument is
   omitted.
  </para>
________________________________________________________-->
  <para>
   <function>ts_debug</function>显示<replaceable class="parameter">document</replaceable>的每一个记号的信息，记号由解析器产生并由配置的词典处理过。该函数使用由<replaceable class="parameter">config</replaceable>指定的配置，如果该参数被忽略则使用<varname>default_text_search_config</varname>指定的配置。
  </para>
<!-- pgdoc-cn_end sig_en=4af3af60dcf4b91fd9d486b80c5ba4d5 -->

<!-- pgdoc-cn_start sig_en=e549555c52daeb3615c5707574c27d93 sig_cn_org=None source=14.1 
  <para>
   <function>ts_debug</function> returns one row for each token identified in the text
   by the parser.  The columns returned are

    <itemizedlist  spacing="compact" mark="bullet">
     <listitem>
      <para>
       <replaceable>alias</replaceable> <type>text</type> &mdash; short name of the token type
      </para>
     </listitem>
     <listitem>
      <para>
       <replaceable>description</replaceable> <type>text</type> &mdash; description of the
       token type
      </para>
     </listitem>
     <listitem>
      <para>
       <replaceable>token</replaceable> <type>text</type> &mdash; text of the token
      </para>
     </listitem>
     <listitem>
      <para>
       <replaceable>dictionaries</replaceable> <type>regdictionary[]</type> &mdash; the
       dictionaries selected by the configuration for this token type
      </para>
     </listitem>
     <listitem>
      <para>
       <replaceable>dictionary</replaceable> <type>regdictionary</type> &mdash; the dictionary
       that recognized the token, or <literal>NULL</literal> if none did
      </para>
     </listitem>
     <listitem>
      <para>
       <replaceable>lexemes</replaceable> <type>text[]</type> &mdash; the lexeme(s) produced
       by the dictionary that recognized the token, or <literal>NULL</literal> if
       none did; an empty array (<literal>{}</literal>) means it was recognized as a
       stop word
      </para>
     </listitem>
    </itemizedlist>
  </para>
________________________________________________________-->
  <para>
   <function>ts_debug</function>为解析器在文本中标识的每一个记号返回一行。被返回的列是：

    <itemizedlist  spacing="compact" mark="bullet">
     <listitem>
      <para>
       <replaceable>alias</replaceable> <type>text</type> &mdash; 记号类型的短名称
      </para>
     </listitem>
     <listitem>
      <para>
       <replaceable>description</replaceable> <type>text</type> &mdash; 记号类型的描述
      </para>
     </listitem>
     <listitem>
      <para>
       <replaceable>token</replaceable> <type>text</type> &mdash; 记号的文本
      </para>
     </listitem>
     <listitem>
      <para>
       <replaceable>dictionaries</replaceable> <type>regdictionary[]</type> &mdash; 配置为这种记号类型选择的词典
      </para>
     </listitem>
     <listitem>
      <para>
       <replaceable>dictionary</replaceable> <type>regdictionary</type> &mdash; 识别该记号的词典，如果没有词典能识别则为<literal>NULL</literal>
      </para>
     </listitem>
     <listitem>
      <para>
       <replaceable>lexemes</replaceable> <type>text[]</type> &mdash; 识别该记号的词典产生的词位，如果没有词典能识别则为<literal>NULL</literal>；一个空数组（<literal>{}</literal>）表示该记号被识别为一个停用词
      </para>
     </listitem>
    </itemizedlist>
  </para>
<!-- pgdoc-cn_end sig_en=e549555c52daeb3615c5707574c27d93 -->

<!-- pgdoc-cn_start sig_en=083e0e026048e0d1a9e6b9fc332874f2 sig_cn_org=109dcf20da0e003aee2b39dba07e3f88 source=15.7 
  <para>
   Here is a simple example:

<screen>
SELECT * FROM ts_debug('english', 'a fat  cat sat on a mat - it ate a fat rats');
   alias   |   description   | token |  dictionaries  |  dictionary  | lexemes
-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-
 asciiword | Word, all ASCII | a     | {english_stem} | english_stem | {}
 blank     | Space symbols   |       | {}             |              |
 asciiword | Word, all ASCII | fat   | {english_stem} | english_stem | {fat}
 blank     | Space symbols   |       | {}             |              |
 asciiword | Word, all ASCII | cat   | {english_stem} | english_stem | {cat}
 blank     | Space symbols   |       | {}             |              |
 asciiword | Word, all ASCII | sat   | {english_stem} | english_stem | {sat}
 blank     | Space symbols   |       | {}             |              |
 asciiword | Word, all ASCII | on    | {english_stem} | english_stem | {}
 blank     | Space symbols   |       | {}             |              |
 asciiword | Word, all ASCII | a     | {english_stem} | english_stem | {}
 blank     | Space symbols   |       | {}             |              |
 asciiword | Word, all ASCII | mat   | {english_stem} | english_stem | {mat}
 blank     | Space symbols   |       | {}             |              |
 blank     | Space symbols   | -     | {}             |              |
 asciiword | Word, all ASCII | it    | {english_stem} | english_stem | {}
 blank     | Space symbols   |       | {}             |              |
 asciiword | Word, all ASCII | ate   | {english_stem} | english_stem | {ate}
 blank     | Space symbols   |       | {}             |              |
 asciiword | Word, all ASCII | a     | {english_stem} | english_stem | {}
 blank     | Space symbols   |       | {}             |              |
 asciiword | Word, all ASCII | fat   | {english_stem} | english_stem | {fat}
 blank     | Space symbols   |       | {}             |              |
 asciiword | Word, all ASCII | rats  | {english_stem} | english_stem | {rat}
</screen>
  </para>
________________________________________________________-->
  <para>
   这是一个简单的例子：

<screen>
SELECT * FROM ts_debug('english', 'a fat  cat sat on a mat - it ate a fat rats');
   alias   |   description   | token |  dictionaries  |  dictionary  | lexemes
-----------+-----------------+-------+----------------+--------------+---------
 asciiword | Word, all ASCII | a     | {english_stem} | english_stem | {}
 blank     | Space symbols   |       | {}             |              |
 asciiword | Word, all ASCII | fat   | {english_stem} | english_stem | {fat}
 blank     | Space symbols   |       | {}             |              |
 asciiword | Word, all ASCII | cat   | {english_stem} | english_stem | {cat}
 blank     | Space symbols   |       | {}             |              |
 asciiword | Word, all ASCII | sat   | {english_stem} | english_stem | {sat}
 blank     | Space symbols   |       | {}             |              |
 asciiword | Word, all ASCII | on    | {english_stem} | english_stem | {}
 blank     | Space symbols   |       | {}             |              |
 asciiword | Word, all ASCII | a     | {english_stem} | english_stem | {}
 blank     | Space symbols   |       | {}             |              |
 asciiword | Word, all ASCII | mat   | {english_stem} | english_stem | {mat}
 blank     | Space symbols   |       | {}             |              |
 blank     | Space symbols   | -     | {}             |              |
 asciiword | Word, all ASCII | it    | {english_stem} | english_stem | {}
 blank     | Space symbols   |       | {}             |              |
 asciiword | Word, all ASCII | ate   | {english_stem} | english_stem | {ate}
 blank     | Space symbols   |       | {}             |              |
 asciiword | Word, all ASCII | a     | {english_stem} | english_stem | {}
 blank     | Space symbols   |       | {}             |              |
 asciiword | Word, all ASCII | fat   | {english_stem} | english_stem | {fat}
 blank     | Space symbols   |       | {}             |              |
 asciiword | Word, all ASCII | rats  | {english_stem} | english_stem | {rat}
</screen>
  </para>
<!-- pgdoc-cn_end sig_en=083e0e026048e0d1a9e6b9fc332874f2 -->

<!-- pgdoc-cn_start sig_en=5123bab27b2b3c4a5ed96aea9e23f706 sig_cn_org=None source=14.1 
  <para>
   For a more extensive demonstration, we
   first create a <literal>public.english</literal> configuration and
   Ispell dictionary for the English language:
  </para>
________________________________________________________-->
  <para>
   为了一个更广泛的示范，我们先为英语语言创建一个<literal>public.english</literal>配置和 Ispell 词典：
  </para>
<!-- pgdoc-cn_end sig_en=5123bab27b2b3c4a5ed96aea9e23f706 -->

<!-- pgdoc-cn_start sig_en=b19cc246e0cc7a64332d524590430651 sig_cn_org=None source=14.1 
<programlisting>
CREATE TEXT SEARCH CONFIGURATION public.english ( COPY = pg_catalog.english );

CREATE TEXT SEARCH DICTIONARY english_ispell (
    TEMPLATE = ispell,
    DictFile = english,
    AffFile = english,
    StopWords = english
);

ALTER TEXT SEARCH CONFIGURATION public.english
   ALTER MAPPING FOR asciiword WITH english_ispell, english_stem;
</programlisting>
________________________________________________________-->
<programlisting>
CREATE TEXT SEARCH CONFIGURATION public.english ( COPY = pg_catalog.english );

CREATE TEXT SEARCH DICTIONARY english_ispell (
    TEMPLATE = ispell,
    DictFile = english,
    AffFile = english,
    StopWords = english
);

ALTER TEXT SEARCH CONFIGURATION public.english
   ALTER MAPPING FOR asciiword WITH english_ispell, english_stem;
</programlisting>
<!-- pgdoc-cn_end sig_en=b19cc246e0cc7a64332d524590430651 -->

<!-- pgdoc-cn_start sig_en=33c10c89311303d8550fd642e58ff754 sig_cn_org=33c10c89311303d8550fd642e58ff754 source=15.7 
<screen>
SELECT * FROM ts_debug('public.english', 'The Brightest supernovaes');
   alias   |   description   |    token    |         dictionaries          |   dictionary   |   lexemes
-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 asciiword | Word, all ASCII | The         | {english_ispell,english_stem} | english_ispell | {}
 blank     | Space symbols   |             | {}                            |                |
 asciiword | Word, all ASCII | Brightest   | {english_ispell,english_stem} | english_ispell | {bright}
 blank     | Space symbols   |             | {}                            |                |
 asciiword | Word, all ASCII | supernovaes | {english_ispell,english_stem} | english_stem   | {supernova}
</screen>
________________________________________________________-->
<screen>
SELECT * FROM ts_debug('public.english', 'The Brightest supernovaes');
   alias   |   description   |    token    |         dictionaries          |   dictionary   |   lexemes
-----------+-----------------+-------------+-------------------------------+----------------+-------------
 asciiword | Word, all ASCII | The         | {english_ispell,english_stem} | english_ispell | {}
 blank     | Space symbols   |             | {}                            |                |
 asciiword | Word, all ASCII | Brightest   | {english_ispell,english_stem} | english_ispell | {bright}
 blank     | Space symbols   |             | {}                            |                |
 asciiword | Word, all ASCII | supernovaes | {english_ispell,english_stem} | english_stem   | {supernova}
</screen>
<!-- pgdoc-cn_end sig_en=33c10c89311303d8550fd642e58ff754 -->

<!-- pgdoc-cn_start sig_en=536a26bf668c01bec919a7e852fcb269 sig_cn_org=None source=14.1 
  <para>
   In this example, the word <literal>Brightest</literal> was recognized by the
   parser as an <literal>ASCII word</literal> (alias <literal>asciiword</literal>).
   For this token type the dictionary list is
   <literal>english_ispell</literal> and
   <literal>english_stem</literal>. The word was recognized by
   <literal>english_ispell</literal>, which reduced it to the noun
   <literal>bright</literal>. The word <literal>supernovaes</literal> is
   unknown to the <literal>english_ispell</literal> dictionary so it
   was passed to the next dictionary, and, fortunately, was recognized (in
   fact, <literal>english_stem</literal> is a Snowball dictionary which
   recognizes everything; that is why it was placed at the end of the
   dictionary list).
  </para>
________________________________________________________-->
  <para>
   在这个例子中，词<literal>Brightest</literal>被解析器识别为一个<literal>ASCII 词</literal>（别名<literal>asciiword</literal>）。对于这种记号类型，词典列表是<literal>english_ispell</literal>和<literal>english_stem</literal>。该词被<literal>english_ispell</literal>识别，这个词典将它缩减为名词<literal>bright</literal>。词<literal>supernovaes</literal>对于<literal>english_ispell</literal>词典是未知的，因此它被传递给下一个词典，并且幸运地是，它被识别了（实际上，<literal>english_stem</literal>是一个 Snowball 词典，它识别所有的东西；这也是为什么它被放置在词典列表的尾部）。
  </para>
<!-- pgdoc-cn_end sig_en=536a26bf668c01bec919a7e852fcb269 -->

<!-- pgdoc-cn_start sig_en=e1ec71463e5034a8ff3a0dd3345866c1 sig_cn_org=None source=14.1 
  <para>
   The word <literal>The</literal> was recognized by the
   <literal>english_ispell</literal> dictionary as a stop word (<xref
   linkend="textsearch-stopwords"/>) and will not be indexed.
   The spaces are discarded too, since the configuration provides no
   dictionaries at all for them.
  </para>
________________________________________________________-->
  <para>
   词<literal>The</literal>被<literal>english_ispell</literal>词典识别为一个停用词（<xref linkend="textsearch-stopwords"/>）并且将不会被索引。空格也被丢弃，因为该配置没有为它们提供词典。
  </para>
<!-- pgdoc-cn_end sig_en=e1ec71463e5034a8ff3a0dd3345866c1 -->

<!-- pgdoc-cn_start sig_en=316198085d8bf890771de82eb47b36f1 sig_cn_org=29cb4d57b556b8f20ccc4b6b945f4b7e source=15.7 
  <para>
   You can reduce the width of the output by explicitly specifying which columns
   you want to see:

<screen>
SELECT alias, token, dictionary, lexemes
FROM ts_debug('public.english', 'The Brightest supernovaes');
   alias   |    token    |   dictionary   |   lexemes
-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 asciiword | The         | english_ispell | {}
 blank     |             |                |
 asciiword | Brightest   | english_ispell | {bright}
 blank     |             |                |
 asciiword | supernovaes | english_stem   | {supernova}
</screen>
  </para>
________________________________________________________-->
  <para>
   你可以通过明确指定要查看的列来减少输出的宽度：

<screen>
SELECT alias, token, dictionary, lexemes
FROM ts_debug('public.english', 'The Brightest supernovaes');
   alias   |    token    |   dictionary   |   lexemes
-----------+-------------+----------------+-------------
 asciiword | The         | english_ispell | {}
 blank     |             |                |
 asciiword | Brightest   | english_ispell | {bright}
 blank     |             |                |
 asciiword | supernovaes | english_stem   | {supernova}
</screen>
  </para>
<!-- pgdoc-cn_end sig_en=316198085d8bf890771de82eb47b36f1 -->

  </sect2>

  <sect2 id="textsearch-parser-testing">
<!-- pgdoc-cn_start sig_en=bb7ff165218d2329221b5a1b6418e6c5 sig_cn_org=None source=14.1 
   <title>Parser Testing</title>
________________________________________________________-->
   <title>解析器测试</title>
<!-- pgdoc-cn_end sig_en=bb7ff165218d2329221b5a1b6418e6c5 -->

<!-- pgdoc-cn_start sig_en=ce5062d160439269ac51a81b6ba45816 sig_cn_org=None source=14.1 
  <para>
   The following functions allow direct testing of a text search parser.
  </para>
________________________________________________________-->
  <para>
   下列函数允许直接测试一个文本搜索解析器。
  </para>
<!-- pgdoc-cn_end sig_en=ce5062d160439269ac51a81b6ba45816 -->

<!-- pgdoc-cn_start sig_en=e5a4b261952e44ed7fc0403d8102ee24 sig_cn_org=None source=14.1 
  <indexterm>
   <primary>ts_parse</primary>
  </indexterm>
________________________________________________________-->
  <indexterm>
   <primary>ts_parse</primary>
  </indexterm>
<!-- pgdoc-cn_end sig_en=e5a4b261952e44ed7fc0403d8102ee24 -->

<!-- pgdoc-cn_start sig_en=2f8036a7228528c2e300e0b96c53ebd1 sig_cn_org=None source=14.1 
<synopsis>
ts_parse(<replaceable class="parameter">parser_name</replaceable> <type>text</type>, <replaceable class="parameter">document</replaceable> <type>text</type>,
         OUT <replaceable class="parameter">tokid</replaceable> <type>integer</type>, OUT <replaceable class="parameter">token</replaceable> <type>text</type>) returns <type>setof record</type>
ts_parse(<replaceable class="parameter">parser_oid</replaceable> <type>oid</type>, <replaceable class="parameter">document</replaceable> <type>text</type>,
         OUT <replaceable class="parameter">tokid</replaceable> <type>integer</type>, OUT <replaceable class="parameter">token</replaceable> <type>text</type>) returns <type>setof record</type>
</synopsis>
________________________________________________________-->
<synopsis>
ts_parse(<replaceable class="parameter">parser_name</replaceable> <type>text</type>, <replaceable class="parameter">document</replaceable> <type>text</type>,
         OUT <replaceable class="parameter">tokid</replaceable> <type>integer</type>, OUT <replaceable class="parameter">token</replaceable> <type>text</type>) returns <type>setof record</type>
ts_parse(<replaceable class="parameter">parser_oid</replaceable> <type>oid</type>, <replaceable class="parameter">document</replaceable> <type>text</type>,
         OUT <replaceable class="parameter">tokid</replaceable> <type>integer</type>, OUT <replaceable class="parameter">token</replaceable> <type>text</type>) returns <type>setof record</type>
</synopsis>
<!-- pgdoc-cn_end sig_en=2f8036a7228528c2e300e0b96c53ebd1 -->

<!-- pgdoc-cn_start sig_en=e98dc435632e14e003ef95ccea7d32ec sig_cn_org=None source=14.1 
  <para>
   <function>ts_parse</function> parses the given <replaceable>document</replaceable>
   and returns a series of records, one for each token produced by
   parsing. Each record includes a <varname>tokid</varname> showing the
   assigned token type and a <varname>token</varname> which is the text of the
   token.  For example:

<screen>
SELECT * FROM ts_parse('default', '123 - a number');
 tokid | token
-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;
    22 | 123
    12 |
    12 | -
     1 | a
    12 |
     1 | number
</screen>
  </para>
________________________________________________________-->
  <para>
   <function>ts_parse</function>解析给定的<replaceable>document</replaceable>并返回一系列记录，每一个记录对应一个由解析产生的记号。每一个记录包括一个<varname>tokid</varname>展示分配给记号的类型以及一个<varname>token</varname>展示记号的文本。例如：

<screen>
SELECT * FROM ts_parse('default', '123 - a number');
 tokid | token
-------+--------
    22 | 123
    12 |
    12 | -
     1 | a
    12 |
     1 | number
</screen>
  </para>
<!-- pgdoc-cn_end sig_en=e98dc435632e14e003ef95ccea7d32ec -->

<!-- pgdoc-cn_start sig_en=a1d6c36a9b9650e951672370aa53ad5f sig_cn_org=None source=14.1 
  <indexterm>
   <primary>ts_token_type</primary>
  </indexterm>
________________________________________________________-->
  <indexterm>
   <primary>ts_token_type</primary>
  </indexterm>
<!-- pgdoc-cn_end sig_en=a1d6c36a9b9650e951672370aa53ad5f -->

<!-- pgdoc-cn_start sig_en=2d0c781514621c4755be5a53ce92a1c8 sig_cn_org=None source=14.1 
<synopsis>
ts_token_type(<replaceable class="parameter">parser_name</replaceable> <type>text</type>, OUT <replaceable class="parameter">tokid</replaceable> <type>integer</type>,
              OUT <replaceable class="parameter">alias</replaceable> <type>text</type>, OUT <replaceable class="parameter">description</replaceable> <type>text</type>) returns <type>setof record</type>
ts_token_type(<replaceable class="parameter">parser_oid</replaceable> <type>oid</type>, OUT <replaceable class="parameter">tokid</replaceable> <type>integer</type>,
              OUT <replaceable class="parameter">alias</replaceable> <type>text</type>, OUT <replaceable class="parameter">description</replaceable> <type>text</type>) returns <type>setof record</type>
</synopsis>
________________________________________________________-->
<synopsis>
ts_token_type(<replaceable class="parameter">parser_name</replaceable> <type>text</type>, OUT <replaceable class="parameter">tokid</replaceable> <type>integer</type>,
              OUT <replaceable class="parameter">alias</replaceable> <type>text</type>, OUT <replaceable class="parameter">description</replaceable> <type>text</type>) returns <type>setof record</type>
ts_token_type(<replaceable class="parameter">parser_oid</replaceable> <type>oid</type>, OUT <replaceable class="parameter">tokid</replaceable> <type>integer</type>,
              OUT <replaceable class="parameter">alias</replaceable> <type>text</type>, OUT <replaceable class="parameter">description</replaceable> <type>text</type>) returns <type>setof record</type>
</synopsis>
<!-- pgdoc-cn_end sig_en=2d0c781514621c4755be5a53ce92a1c8 -->

<!-- pgdoc-cn_start sig_en=db447d31084d73215bad013b32964eba sig_cn_org=5a9d6538d7a6393c81cf11f2aa7ac549 source=15.7 
  <para>
   <function>ts_token_type</function> returns a table which describes each type of
   token the specified parser can recognize.  For each token type, the table
   gives the integer <varname>tokid</varname> that the parser uses to label a
   token of that type, the <varname>alias</varname> that names the token type
   in configuration commands, and a short <varname>description</varname>.  For
   example:

<screen>
SELECT * FROM ts_token_type('default');
 tokid |      alias      |               description
-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
     1 | asciiword       | Word, all ASCII
     2 | word            | Word, all letters
     3 | numword         | Word, letters and digits
     4 | email           | Email address
     5 | url             | URL
     6 | host            | Host
     7 | sfloat          | Scientific notation
     8 | version         | Version number
     9 | hword_numpart   | Hyphenated word part, letters and digits
    10 | hword_part      | Hyphenated word part, all letters
    11 | hword_asciipart | Hyphenated word part, all ASCII
    12 | blank           | Space symbols
    13 | tag             | XML tag
    14 | protocol        | Protocol head
    15 | numhword        | Hyphenated word, letters and digits
    16 | asciihword      | Hyphenated word, all ASCII
    17 | hword           | Hyphenated word, all letters
    18 | url_path        | URL path
    19 | file            | File or path name
    20 | float           | Decimal notation
    21 | int             | Signed integer
    22 | uint            | Unsigned integer
    23 | entity          | XML entity
</screen>
   </para>
________________________________________________________-->
  <para>
   <function>ts_token_type</function>返回一个表，描述指定解析器可以识别的每种类型的标记。
   对于每种标记类型，表给出解析器用于标记该类型标记的整数<varname>tokid</varname>，
   在配置命令中命名标记类型的<varname>alias</varname>，以及简短的<varname>description</varname>。
   例如：

<screen>
SELECT * FROM ts_token_type('default');
 tokid |      alias      |               description
-------+-----------------+------------------------------------------
     1 | asciiword       | Word, all ASCII
     2 | word            | Word, all letters
     3 | numword         | Word, letters and digits
     4 | email           | Email address
     5 | url             | URL
     6 | host            | Host
     7 | sfloat          | Scientific notation
     8 | version         | Version number
     9 | hword_numpart   | Hyphenated word part, letters and digits
    10 | hword_part      | Hyphenated word part, all letters
    11 | hword_asciipart | Hyphenated word part, all ASCII
    12 | blank           | Space symbols
    13 | tag             | XML tag
    14 | protocol        | Protocol head
    15 | numhword        | Hyphenated word, letters and digits
    16 | asciihword      | Hyphenated word, all ASCII
    17 | hword           | Hyphenated word, all letters
    18 | url_path        | URL path
    19 | file            | File or path name
    20 | float           | Decimal notation
    21 | int             | Signed integer
    22 | uint            | Unsigned integer
    23 | entity          | XML entity
</screen>
   </para>
<!-- pgdoc-cn_end sig_en=db447d31084d73215bad013b32964eba -->

  </sect2>

  <sect2 id="textsearch-dictionary-testing">
<!-- pgdoc-cn_start sig_en=02a0dd5160d8d5acc1de8e071bc6f6fb sig_cn_org=None source=14.1 
   <title>Dictionary Testing</title>
________________________________________________________-->
   <title>词典测试</title>
<!-- pgdoc-cn_end sig_en=02a0dd5160d8d5acc1de8e071bc6f6fb -->

<!-- pgdoc-cn_start sig_en=0b2b969cb518111c18ed5b17616e29e1 sig_cn_org=None source=14.1 
   <para>
    The <function>ts_lexize</function> function facilitates dictionary testing.
   </para>
________________________________________________________-->
   <para>
    <function>ts_lexize</function>函数帮助词典测试。
   </para>
<!-- pgdoc-cn_end sig_en=0b2b969cb518111c18ed5b17616e29e1 -->

<!-- pgdoc-cn_start sig_en=33c879b709e6b39613f674cd153faa31 sig_cn_org=None source=14.1 
   <indexterm>
    <primary>ts_lexize</primary>
   </indexterm>
________________________________________________________-->
   <indexterm>
    <primary>ts_lexize</primary>
   </indexterm>
<!-- pgdoc-cn_end sig_en=33c879b709e6b39613f674cd153faa31 -->

<!-- pgdoc-cn_start sig_en=cae2dd16c7c10618ff325bdea6150c51 sig_cn_org=None source=14.1 
<synopsis>
ts_lexize(<replaceable class="parameter">dict</replaceable> <type>regdictionary</type>, <replaceable class="parameter">token</replaceable> <type>text</type>) returns <type>text[]</type>
</synopsis>
________________________________________________________-->
<synopsis>
ts_lexize(<replaceable class="parameter">dict</replaceable> <type>regdictionary</type>, <replaceable class="parameter">token</replaceable> <type>text</type>) returns <type>text[]</type>
</synopsis>
<!-- pgdoc-cn_end sig_en=cae2dd16c7c10618ff325bdea6150c51 -->

<!-- pgdoc-cn_start sig_en=bd00984e70d617685678971279781946 sig_cn_org=None source=14.1 
   <para>
    <function>ts_lexize</function> returns an array of lexemes if the input
    <replaceable>token</replaceable> is known to the dictionary,
    or an empty array if the token
    is known to the dictionary but it is a stop word, or
    <literal>NULL</literal> if it is an unknown word.
   </para>
________________________________________________________-->
   <para>
    如果输入的<replaceable>token</replaceable>是该词典已知的，则<function>ts_lexize</function>返回一个词位数组；如果记号是词典已知的但是它是一个停用词，则返回一个空数组；或者如果它对词典是未知词，则返回<literal>NULL</literal>。
   </para>
<!-- pgdoc-cn_end sig_en=bd00984e70d617685678971279781946 -->

<!-- pgdoc-cn_start sig_en=298bed9eb33483c1de96848015747e5a sig_cn_org=None source=14.1 
   <para>
    Examples:

<screen>
SELECT ts_lexize('english_stem', 'stars');
 ts_lexize
-&minus;-&minus;-&minus;-&minus;-&minus;-
 {star}

SELECT ts_lexize('english_stem', 'a');
 ts_lexize
-&minus;-&minus;-&minus;-&minus;-&minus;-
 {}
</screen>
   </para>
________________________________________________________-->
   <para>
    例子：

<screen>
SELECT ts_lexize('english_stem', 'stars');
 ts_lexize
-----------
 {star}

SELECT ts_lexize('english_stem', 'a');
 ts_lexize
-----------
 {}
</screen>
   </para>
<!-- pgdoc-cn_end sig_en=298bed9eb33483c1de96848015747e5a -->

   <note>
<!-- pgdoc-cn_start sig_en=12d1435f9c8bcb8dd81ebb800b70a284 sig_cn_org=None source=14.1 
    <para>
     The <function>ts_lexize</function> function expects a single
     <emphasis>token</emphasis>, not text. Here is a case
     where this can be confusing:

<screen>
SELECT ts_lexize('thesaurus_astro', 'supernovae stars') is null;
 ?column?
-&minus;-&minus;-&minus;-&minus;-&minus;
 t
</screen>

     The thesaurus dictionary <literal>thesaurus_astro</literal> does know the
     phrase <literal>supernovae stars</literal>, but <function>ts_lexize</function>
     fails since it does not parse the input text but treats it as a single
     token. Use <function>plainto_tsquery</function> or <function>to_tsvector</function> to
     test thesaurus dictionaries, for example:

<screen>
SELECT plainto_tsquery('supernovae stars');
 plainto_tsquery
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 'sn'
</screen>
    </para>
________________________________________________________-->
    <para>
     <function>ts_lexize</function>函数期望一个单一<emphasis>记号</emphasis>而不是文本。下面的情况会让它搞混：

<screen>
SELECT ts_lexize('thesaurus_astro', 'supernovae stars') is null;
 ?column?
----------
 t
</screen>

     分类词典<literal>thesaurus_astro</literal>确实知道短语<literal>supernovae stars</literal>，但是<function>ts_lexize</function>会失败，因为它无法解析输入文本而把它当做一个单一记号。可以使用<function>plainto_tsquery</function>或<function>to_tsvector</function>来测试分类词典，例如：

<screen>
SELECT plainto_tsquery('supernovae stars');
 plainto_tsquery
-----------------
 'sn'
</screen>
    </para>
<!-- pgdoc-cn_end sig_en=12d1435f9c8bcb8dd81ebb800b70a284 -->
   </note>

  </sect2>

 </sect1>

 <sect1 id="textsearch-indexes">
<!-- pgdoc-cn_start sig_en=b0e0d0c19c075a7883a1ff20bebeed4c sig_cn_org=1135ad01cbf615efeea6c30d66bca5df source=15.7 
  <title>Preferred Index Types for Text Search</title>
________________________________________________________-->
  <title>文本搜索的首选索引类型</title>
<!-- pgdoc-cn_end sig_en=b0e0d0c19c075a7883a1ff20bebeed4c -->

<!-- pgdoc-cn_start sig_en=cd88f6e1f6bf0fc02b6c47d352956716 sig_cn_org=None source=14.1 
  <indexterm zone="textsearch-indexes">
   <primary>text search</primary>
   <secondary>indexes</secondary>
  </indexterm>
________________________________________________________-->
  <indexterm zone="textsearch-indexes">
   <primary>文本搜索</primary>
   <secondary>索引</secondary>
  </indexterm>
<!-- pgdoc-cn_end sig_en=cd88f6e1f6bf0fc02b6c47d352956716 -->

<!-- pgdoc-cn_start sig_en=87520cdc7f9f6b168bd8369828025ca5 sig_cn_org=6d4266bcaad610edaefb401d8d4ecc26 source=15.7 
  <para>
   There are two kinds of indexes that can be used to speed up full text
   searches:
   <link linkend="gin"><acronym>GIN</acronym></link> and
   <link linkend="gist"><acronym>GiST</acronym></link>.
   Note that indexes are not mandatory for full text searching, but in
   cases where a column is searched on a regular basis, an index is
   usually desirable.
  </para>
________________________________________________________-->
  <para>
   有两种索引可以用来加速全文搜索：<link linkend="gin"><acronym>GIN</acronym></link>和
   <link linkend="gist"><acronym>GiST</acronym></link>。
   请注意，索引对于全文搜索并非强制要求，但在定期搜索某一列的情况下，通常是可取的。
</para>
<!-- pgdoc-cn_end sig_en=87520cdc7f9f6b168bd8369828025ca5 -->

<!-- pgdoc-cn_start sig_en=91be13d4ccb18cc35fc337b9fffb45ad sig_cn_org=56d919381c24bd0cf7133806d5f0b9f6 source=15.7 
  <para>
   To create such an index, do one of:

   <variablelist>

    <varlistentry>

     <term>
     <indexterm zone="textsearch-indexes">
      <primary>index</primary>
      <secondary>GIN</secondary>
      <tertiary>text search</tertiary>
     </indexterm>

      <literal>CREATE INDEX <replaceable>name</replaceable> ON <replaceable>table</replaceable> USING GIN (<replaceable>column</replaceable>);</literal>
     </term>

     <listitem>
      <para>
       Creates a GIN (Generalized Inverted Index)-based index.
       The <replaceable>column</replaceable> must be of <type>tsvector</type> type.
      </para>
     </listitem>
    </varlistentry>

    <varlistentry>

     <term>
     <indexterm zone="textsearch-indexes">
      <primary>index</primary>
      <secondary>GiST</secondary>
      <tertiary>text search</tertiary>
     </indexterm>

      <literal>CREATE INDEX <replaceable>name</replaceable> ON <replaceable>table</replaceable> USING GIST (<replaceable>column</replaceable> [ { DEFAULT | tsvector_ops } (siglen = <replaceable>number</replaceable>) ] );</literal>
     </term>

     <listitem>
      <para>
       Creates a GiST (Generalized Search Tree)-based index.
       The <replaceable>column</replaceable> can be of <type>tsvector</type> or
       <type>tsquery</type> type.
       Optional integer parameter <literal>siglen</literal> determines
       signature length in bytes (see below for details).
      </para>
     </listitem>
    </varlistentry>

   </variablelist>
  </para>
________________________________________________________-->
  <para>
   要创建这样的索引，请执行以下操作之一：

   <variablelist>

    <varlistentry>

     <term>
     <indexterm zone="textsearch-indexes">
      <primary>索引</primary>
      <secondary>GIN</secondary>
      <tertiary>文本搜索</tertiary>
     </indexterm>

      <literal>CREATE INDEX <replaceable>name</replaceable> ON <replaceable>table</replaceable> USING GIN (<replaceable>column</replaceable>);</literal>
     </term>

     <listitem>
      <para>
       创建基于GIN（广义倒排索引）的索引。
       <replaceable>column</replaceable>必须是<type>tsvector</type>类型。
      </para>
     </listitem>
    </varlistentry>

    <varlistentry>

     <term>
     <indexterm zone="textsearch-indexes">
      <primary>索引</primary>
      <secondary>GiST</secondary>
      <tertiary>文本搜索</tertiary>
     </indexterm>

      <literal>CREATE INDEX <replaceable>name</replaceable> ON <replaceable>table</replaceable> USING GIST (<replaceable>column</replaceable> [ { DEFAULT | tsvector_ops } (siglen = <replaceable>number</replaceable>) ] );</literal>
     </term>

     <listitem>
      <para>
       创建基于GiST（广义搜索树）的索引。
       <replaceable>column</replaceable>可以是<type>tsvector</type>或<type>tsquery</type>类型。
       可选的整数参数<literal>siglen</literal>确定签名长度（有关详细信息，请参见下文）。
      </para>
     </listitem>
    </varlistentry>

   </variablelist>
  </para>
<!-- pgdoc-cn_end sig_en=91be13d4ccb18cc35fc337b9fffb45ad -->

<!-- pgdoc-cn_start sig_en=b83514b375a1df86fbceab72969b23e7 sig_cn_org=None source=14.1 
  <para>
   GIN indexes are the preferred text search index type.  As inverted
   indexes, they contain an index entry for each word (lexeme), with a
   compressed list of matching locations.  Multi-word searches can find
   the first match, then use the index to remove rows that are lacking
   additional words.  GIN indexes store only the words (lexemes) of
   <type>tsvector</type> values, and not their weight labels.  Thus a table
   row recheck is needed when using a query that involves weights.
  </para>
________________________________________________________-->
  <para>
   GIN 索引是更好的文本搜索索引类型。作为倒排索引，每个词（词位）在
   其中都有一个索引项，其中有压缩过的匹配位置的列表。多词搜索可以找到
   第一个匹配，然后使用该索引移除缺少额外词的行。GIN 索引只存储
   <type>tsvector</type>值的词（词位），并且不存储它们的权重标签。因此，
   在使用涉及权重的查询时需要一次在表行上的重新检查。
  </para>
<!-- pgdoc-cn_end sig_en=b83514b375a1df86fbceab72969b23e7 -->

<!-- pgdoc-cn_start sig_en=d554b6f63b695330f5ef5c3f2716722d sig_cn_org=None source=14.1 
  <para>
   A GiST index is <firstterm>lossy</firstterm>, meaning that the index
   might produce false matches, and it is necessary
   to check the actual table row to eliminate such false matches.
   (<productname>PostgreSQL</productname> does this automatically when needed.)
   GiST indexes are lossy because each document is represented in the
   index by a fixed-length signature.  The signature length in bytes is determined
   by the value of the optional integer parameter <literal>siglen</literal>.
   The default signature length (when <literal>siglen</literal> is not specified) is
   124 bytes, the maximum signature length is 2024 bytes. The signature is generated by hashing
   each word into a single bit in an n-bit string, with all these bits OR-ed
   together to produce an n-bit document signature.  When two words hash to
   the same bit position there will be a false match.  If all words in
   the query have matches (real or false) then the table row must be
   retrieved to see if the match is correct.  Longer signatures lead to a more
   precise search (scanning a smaller fraction of the index and fewer heap
   pages), at the cost of a larger index.
  </para>
________________________________________________________-->
  <para>
   一个 GiST 索引是<firstterm>有损的</firstterm>，这表示索引可能产生假匹配，并且有必要检查真实的表行来消除这种假匹配（<productname>PostgreSQL</productname>在需要时会自动做这一步）。GiST 索引之所以是有损的，是因为每一个文档在索引中被表示为一个定长的签名。以字节为单位的签名长度由可选整数参数 <literal>siglen</literal> 的值决定。 默认签名长度（未指定 <literal>siglen</literal> 时）为 124 字节，最大签名长度为 2024 字节。该签名通过哈希每一个词到一个 n 位串中的一个单一位来产生，通过将所有这些位 OR 在一起产生一个 n 位的文档签名。当两个词哈希到同一个位位置时就会产生假匹配。如果查询中所有词都有匹配（真或假），则必须检索表行查看匹配是否正确。更长的签名导致更精确的搜索（扫描索引的一小部分和更少的堆页面），但代价是更大的索引。
  </para>
<!-- pgdoc-cn_end sig_en=d554b6f63b695330f5ef5c3f2716722d -->

<!-- pgdoc-cn_start sig_en=28b6280be29cbea9d26a83054b6d1c5c sig_cn_org=None source=14.1 
  <para>
   A GiST index can be covering, i.e., use the <literal>INCLUDE</literal>
   clause.  Included columns can have data types without any GiST operator
   class.  Included attributes will be stored uncompressed.
  </para>
________________________________________________________-->
  <para>
   GiST 索引可以被覆盖，例如使用<literal>INCLUDE</literal>子句。 包含的列可以具有没有任何 GiST 操作符类的数据类型。 包含的属性将非压缩存储。
  </para>
<!-- pgdoc-cn_end sig_en=28b6280be29cbea9d26a83054b6d1c5c -->

<!-- pgdoc-cn_start sig_en=6d909b10f5c1731583626e242f413c17 sig_cn_org=None source=14.1 
  <para>
   Lossiness causes performance degradation due to unnecessary fetches of table
   records that turn out to be false matches.  Since random access to table
   records is slow, this limits the usefulness of GiST indexes.  The
   likelihood of false matches depends on several factors, in particular the
   number of unique words, so using dictionaries to reduce this number is
   recommended.
  </para>
________________________________________________________-->
  <para>
   有损性导致的性能下降归因于不必要的表记录（即被证实为假匹配的记录）获取。因为表记录的随机访问是较慢的，这限制了 GiST 索引的可用性。假匹配的可能性取决于几个因素，特别是唯一词的数量，因此推荐使用词典来缩减这个数量。
  </para>
<!-- pgdoc-cn_end sig_en=6d909b10f5c1731583626e242f413c17 -->

<!-- pgdoc-cn_start sig_en=f9faf1d33b0ef5354495a6705994f309 sig_cn_org=None source=14.1 
  <para>
   Note that <acronym>GIN</acronym> index build time can often be improved
   by increasing <xref linkend="guc-maintenance-work-mem"/>, while
   <acronym>GiST</acronym> index build time is not sensitive to that
   parameter.
  </para>
________________________________________________________-->
  <para>
   注意<acronym>GIN</acronym>索引的构件时间常常可以通过增加<xref linkend="guc-maintenance-work-mem"/>来改进，而<acronym>GiST</acronym>索引的构建时间则与该参数无关。
  </para>
<!-- pgdoc-cn_end sig_en=f9faf1d33b0ef5354495a6705994f309 -->

<!-- pgdoc-cn_start sig_en=c36b89aa5660f2cb38e08b7e4c1410d7 sig_cn_org=None source=14.1 
  <para>
   Partitioning of big collections and the proper use of GIN and GiST indexes
   allows the implementation of very fast searches with online update.
   Partitioning can be done at the database level using table inheritance,
   or by distributing documents over
   servers and collecting external search results, e.g., via <link
   linkend="ddl-foreign-data">Foreign Data</link> access.
   The latter is possible because ranking functions use
   only local information.
  </para>
________________________________________________________-->
  <para>
   对大集合分区并正确使用 GIN 和 GiST 索引允许实现带在线更新的快速搜索。分区可以在数据库层面上使用表继承来完成，或者是通过将文档分布在服务器上并收集外部的搜索结果，例如通过<link
   linkend="ddl-foreign-data">外部数据</link>访问。后者是可能的，因为排名函数只使用本地信息。
  </para>
<!-- pgdoc-cn_end sig_en=c36b89aa5660f2cb38e08b7e4c1410d7 -->

 </sect1>

 <sect1 id="textsearch-psql">
<!-- pgdoc-cn_start sig_en=ebc7b92627a199f35cd2cff11dc56ed6 sig_cn_org=None source=14.1 
  <title><application>psql</application> Support</title>
________________________________________________________-->
  <title><application>psql</application>支持</title>
<!-- pgdoc-cn_end sig_en=ebc7b92627a199f35cd2cff11dc56ed6 -->

<!-- pgdoc-cn_start sig_en=52121f8253cfcb2831062913115042e5 sig_cn_org=None source=14.1 
  <para>
   Information about text search configuration objects can be obtained
   in <application>psql</application> using a set of commands:
<synopsis>
\dF{d,p,t}<optional>+</optional> <optional>PATTERN</optional>
</synopsis>
   An optional <literal>+</literal> produces more details.
  </para>
________________________________________________________-->
  <para>
   关于文本搜索配置对象的信息可以在<application>psql</application>中使用一组命令获得：
<synopsis>
\dF{d,p,t}<optional>+</optional> <optional>PATTERN</optional>
</synopsis>
   可选的<literal>+</literal>能产生更多细节。
  </para>
<!-- pgdoc-cn_end sig_en=52121f8253cfcb2831062913115042e5 -->

<!-- pgdoc-cn_start sig_en=441bca599d8149d6d8af957922f5cbc0 sig_cn_org=None source=14.1 
  <para>
   The optional parameter <replaceable>PATTERN</replaceable> can be the name of
   a text search object, optionally schema-qualified.  If
   <replaceable>PATTERN</replaceable> is omitted then information about all
   visible objects will be displayed.  <replaceable>PATTERN</replaceable> can be a
   regular expression and can provide <emphasis>separate</emphasis> patterns
   for the schema and object names.  The following examples illustrate this:

<screen>
=&gt; \dF *fulltext*
       List of text search configurations
 Schema |  Name        | Description
-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 public | fulltext_cfg |
</screen>

<screen>
=&gt; \dF *.fulltext*
       List of text search configurations
 Schema   |  Name        | Description
-&minus;-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 fulltext | fulltext_cfg |
 public   | fulltext_cfg |
</screen>

   The available commands are:
  </para>
________________________________________________________-->
  <para>
   可选参数<replaceable>PATTERN</replaceable>可以是一个文本搜索对象的名称，可以是模式限定的。如果<replaceable>PATTERN</replaceable>被忽略，则所有可见对象的信息都将被显示。<replaceable>PATTERN</replaceable>可以是一个正则表达式并且可以为模式和对象名称提供<emphasis>独立的</emphasis>模式。下面的例子展示了这些特性：

<screen>
=&gt; \dF *fulltext*
       List of text search configurations
 Schema |  Name        | Description
--------+--------------+-------------
 public | fulltext_cfg |
</screen>

<screen>
=&gt; \dF *.fulltext*
       List of text search configurations
 Schema   |  Name        | Description
----------+----------------------------
 fulltext | fulltext_cfg |
 public   | fulltext_cfg |
</screen>

   可用的命令是：
  </para>
<!-- pgdoc-cn_end sig_en=441bca599d8149d6d8af957922f5cbc0 -->

  <variablelist>
   <varlistentry>
    <term><literal>\dF<optional>+</optional> <optional>PATTERN</optional></literal></term>
    <listitem>
<!-- pgdoc-cn_start sig_en=63037c5fbbd3b78ec06609b98ddcffbf sig_cn_org=7ff78263fb451e3eb109fcdac64c5978 source=15.7 
     <para>
      List text search configurations (add <literal>+</literal> for more detail).
<screen>
=&gt; \dF russian
            List of text search configurations
   Schema   |  Name   |            Description
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 pg_catalog | russian | configuration for russian language

=&gt; \dF+ russian
Text search configuration "pg_catalog.russian"
Parser: "pg_catalog.default"
      Token      | Dictionaries
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 asciihword      | english_stem
 asciiword       | english_stem
 email           | simple
 file            | simple
 float           | simple
 host            | simple
 hword           | russian_stem
 hword_asciipart | english_stem
 hword_numpart   | simple
 hword_part      | russian_stem
 int             | simple
 numhword        | simple
 numword         | simple
 sfloat          | simple
 uint            | simple
 url             | simple
 url_path        | simple
 version         | simple
 word            | russian_stem
</screen>
     </para>
________________________________________________________-->
     <para>
      列出文本搜索配置（添加<literal>+</literal>以获取更多详细信息）。
<screen>
=&gt; \dF russian
            List of text search configurations
   Schema   |  Name   |            Description
------------+---------+------------------------------------
 pg_catalog | russian | configuration for russian language

=&gt; \dF+ russian
Text search configuration "pg_catalog.russian"
Parser: "pg_catalog.default"
      Token      | Dictionaries
-----------------+--------------
 asciihword      | english_stem
 asciiword       | english_stem
 email           | simple
 file            | simple
 float           | simple
 host            | simple
 hword           | russian_stem
 hword_asciipart | english_stem
 hword_numpart   | simple
 hword_part      | russian_stem
 int             | simple
 numhword        | simple
 numword         | simple
 sfloat          | simple
 uint            | simple
 url             | simple
 url_path        | simple
 version         | simple
 word            | russian_stem
</screen>
     </para>
<!-- pgdoc-cn_end sig_en=63037c5fbbd3b78ec06609b98ddcffbf -->
    </listitem>
   </varlistentry>

   <varlistentry>
    <term><literal>\dFd<optional>+</optional> <optional>PATTERN</optional></literal></term>
    <listitem>
<!-- pgdoc-cn_start sig_en=bf936df0ee3b67c749f21f02a98dfb00 sig_cn_org=None source=14.1 
     <para>
      List text search dictionaries (add <literal>+</literal> for more detail).
<screen>
=&gt; \dFd
                             List of text search dictionaries
   Schema   |      Name       |                        Description
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 pg_catalog | arabic_stem     | snowball stemmer for arabic language
 pg_catalog | armenian_stem   | snowball stemmer for armenian language
 pg_catalog | basque_stem     | snowball stemmer for basque language
 pg_catalog | catalan_stem    | snowball stemmer for catalan language
 pg_catalog | danish_stem     | snowball stemmer for danish language
 pg_catalog | dutch_stem      | snowball stemmer for dutch language
 pg_catalog | english_stem    | snowball stemmer for english language
 pg_catalog | finnish_stem    | snowball stemmer for finnish language
 pg_catalog | french_stem     | snowball stemmer for french language
 pg_catalog | german_stem     | snowball stemmer for german language
 pg_catalog | greek_stem      | snowball stemmer for greek language
 pg_catalog | hindi_stem      | snowball stemmer for hindi language
 pg_catalog | hungarian_stem  | snowball stemmer for hungarian language
 pg_catalog | indonesian_stem | snowball stemmer for indonesian language
 pg_catalog | irish_stem      | snowball stemmer for irish language
 pg_catalog | italian_stem    | snowball stemmer for italian language
 pg_catalog | lithuanian_stem | snowball stemmer for lithuanian language
 pg_catalog | nepali_stem     | snowball stemmer for nepali language
 pg_catalog | norwegian_stem  | snowball stemmer for norwegian language
 pg_catalog | portuguese_stem | snowball stemmer for portuguese language
 pg_catalog | romanian_stem   | snowball stemmer for romanian language
 pg_catalog | russian_stem    | snowball stemmer for russian language
 pg_catalog | serbian_stem    | snowball stemmer for serbian language
 pg_catalog | simple          | simple dictionary: just lower case and check for stopword
 pg_catalog | spanish_stem    | snowball stemmer for spanish language
 pg_catalog | swedish_stem    | snowball stemmer for swedish language
 pg_catalog | tamil_stem      | snowball stemmer for tamil language
 pg_catalog | turkish_stem    | snowball stemmer for turkish language
 pg_catalog | yiddish_stem    | snowball stemmer for yiddish language
</screen>
     </para>
________________________________________________________-->
     <para>
      列出文本搜索词典（加上<literal>+</literal>得到更多细节）。
<screen>
=&gt; \dFd
                             List of text search dictionaries
   Schema   |      Name       |                        Description
------------+-----------------+-----------------------------------------------------------
 pg_catalog | arabic_stem     | snowball stemmer for arabic language
 pg_catalog | armenian_stem   | snowball stemmer for armenian language
 pg_catalog | basque_stem     | snowball stemmer for basque language
 pg_catalog | catalan_stem    | snowball stemmer for catalan language
 pg_catalog | danish_stem     | snowball stemmer for danish language
 pg_catalog | dutch_stem      | snowball stemmer for dutch language
 pg_catalog | english_stem    | snowball stemmer for english language
 pg_catalog | finnish_stem    | snowball stemmer for finnish language
 pg_catalog | french_stem     | snowball stemmer for french language
 pg_catalog | german_stem     | snowball stemmer for german language
 pg_catalog | greek_stem      | snowball stemmer for greek language
 pg_catalog | hindi_stem      | snowball stemmer for hindi language
 pg_catalog | hungarian_stem  | snowball stemmer for hungarian language
 pg_catalog | indonesian_stem | snowball stemmer for indonesian language
 pg_catalog | irish_stem      | snowball stemmer for irish language
 pg_catalog | italian_stem    | snowball stemmer for italian language
 pg_catalog | lithuanian_stem | snowball stemmer for lithuanian language
 pg_catalog | nepali_stem     | snowball stemmer for nepali language
 pg_catalog | norwegian_stem  | snowball stemmer for norwegian language
 pg_catalog | portuguese_stem | snowball stemmer for portuguese language
 pg_catalog | romanian_stem   | snowball stemmer for romanian language
 pg_catalog | russian_stem    | snowball stemmer for russian language
 pg_catalog | serbian_stem    | snowball stemmer for serbian language
 pg_catalog | simple          | simple dictionary: just lower case and check for stopword
 pg_catalog | spanish_stem    | snowball stemmer for spanish language
 pg_catalog | swedish_stem    | snowball stemmer for swedish language
 pg_catalog | tamil_stem      | snowball stemmer for tamil language
 pg_catalog | turkish_stem    | snowball stemmer for turkish language
 pg_catalog | yiddish_stem    | snowball stemmer for yiddish language
</screen>
     </para>
<!-- pgdoc-cn_end sig_en=bf936df0ee3b67c749f21f02a98dfb00 -->
    </listitem>
   </varlistentry>

   <varlistentry>
   <term><literal>\dFp<optional>+</optional> <optional>PATTERN</optional></literal></term>
    <listitem>
<!-- pgdoc-cn_start sig_en=0baaf58099948c5139ef589756dd6d0d sig_cn_org=99aaafbf85d66f8840d2615d93386721 source=15.7 
     <para>
      List text search parsers (add <literal>+</literal> for more detail).
<screen>
=&gt; \dFp
        List of text search parsers
   Schema   |  Name   |     Description
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 pg_catalog | default | default word parser
=&gt; \dFp+
    Text search parser "pg_catalog.default"
     Method      |    Function    | Description
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 Start parse     | prsd_start     |
 Get next token  | prsd_nexttoken |
 End parse       | prsd_end       |
 Get headline    | prsd_headline  |
 Get token types | prsd_lextype   |

        Token types for parser "pg_catalog.default"
   Token name    |               Description
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 asciihword      | Hyphenated word, all ASCII
 asciiword       | Word, all ASCII
 blank           | Space symbols
 email           | Email address
 entity          | XML entity
 file            | File or path name
 float           | Decimal notation
 host            | Host
 hword           | Hyphenated word, all letters
 hword_asciipart | Hyphenated word part, all ASCII
 hword_numpart   | Hyphenated word part, letters and digits
 hword_part      | Hyphenated word part, all letters
 int             | Signed integer
 numhword        | Hyphenated word, letters and digits
 numword         | Word, letters and digits
 protocol        | Protocol head
 sfloat          | Scientific notation
 tag             | XML tag
 uint            | Unsigned integer
 url             | URL
 url_path        | URL path
 version         | Version number
 word            | Word, all letters
(23 rows)
</screen>
     </para>
________________________________________________________-->
     <para>
      列出文本搜索解析器（添加<literal>+</literal>以获取更多详细信息）。
<screen>
=> \dFp
        List of text search parsers
   Schema   |  Name   |     Description
------------+---------+---------------------
 pg_catalog | default | default word parser
=> \dFp+
    Text search parser "pg_catalog.default"
     Method      |    Function    | Description
-----------------+----------------+-------------
 Start parse     | prsd_start     |
 Get next token  | prsd_nexttoken |
 End parse       | prsd_end       |
 Get headline    | prsd_headline  |
 Get token types | prsd_lextype   |

        Token types for parser "pg_catalog.default"
   Token name    |               Description
-----------------+------------------------------------------
 asciihword      | Hyphenated word, all ASCII
 asciiword       | Word, all ASCII
 blank           | Space symbols
 email           | Email address
 entity          | XML entity
 file            | File or path name
 float           | Decimal notation
 host            | Host
 hword           | Hyphenated word, all letters
 hword_asciipart | Hyphenated word part, all ASCII
 hword_numpart   | Hyphenated word part, letters and digits
 hword_part      | Hyphenated word part, all letters
 int             | Signed integer
 numhword        | Hyphenated word, letters and digits
 numword         | Word, letters and digits
 protocol        | Protocol head
 sfloat          | Scientific notation
 tag             | XML tag
 uint            | Unsigned integer
 url             | URL
 url_path        | URL path
 version         | Version number
 word            | Word, all letters
(23 rows)
</screen>
     </para>
<!-- pgdoc-cn_end sig_en=0baaf58099948c5139ef589756dd6d0d -->
    </listitem>
   </varlistentry>

   <varlistentry>
   <term><literal>\dFt<optional>+</optional> <optional>PATTERN</optional></literal></term>
    <listitem>
<!-- pgdoc-cn_start sig_en=dda38977f5fb27b7a72139b05a4691cd sig_cn_org=5f928d8ba46637c9fc9b1abe79e5ef18 source=15.7 
     <para>
      List text search templates (add <literal>+</literal> for more detail).
<screen>
=&gt; \dFt
                           List of text search templates
   Schema   |   Name    |                        Description
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 pg_catalog | ispell    | ispell dictionary
 pg_catalog | simple    | simple dictionary: just lower case and check for stopword
 pg_catalog | snowball  | snowball stemmer
 pg_catalog | synonym   | synonym dictionary: replace word by its synonym
 pg_catalog | thesaurus | thesaurus dictionary: phrase by phrase substitution
</screen>
     </para>
________________________________________________________-->
     <para>
      列出文本搜索模板（添加<literal>+</literal>以获取更多详细信息）。
<screen>
=> \dFt
                           List of text search templates
   Schema   |   Name    |                        Description
------------+-----------+-----------------------------------------------------------
 pg_catalog | ispell    | ispell dictionary
 pg_catalog | simple    | simple dictionary: just lower case and check for stopword
 pg_catalog | snowball  | snowball stemmer
 pg_catalog | synonym   | synonym dictionary: replace word by its synonym
 pg_catalog | thesaurus | thesaurus dictionary: phrase by phrase substitution
</screen>
     </para>
<!-- pgdoc-cn_end sig_en=dda38977f5fb27b7a72139b05a4691cd -->
    </listitem>
   </varlistentry>
  </variablelist>

 </sect1>

 <sect1 id="textsearch-limitations">
<!-- pgdoc-cn_start sig_en=6f5b22a932265c21e464df6dcbb347ec sig_cn_org=None source=14.1 
  <title>Limitations</title>
________________________________________________________-->
  <title>限制</title>
<!-- pgdoc-cn_end sig_en=6f5b22a932265c21e464df6dcbb347ec -->

<!-- pgdoc-cn_start sig_en=aa10052088dafd97471f472d9b7f4936 sig_cn_org=None source=14.1 
  <para>
   The current limitations of <productname>PostgreSQL</productname>'s
   text search features are:
   <itemizedlist  spacing="compact" mark="bullet">
    <listitem>
     <para>The length of each lexeme must be less than 2 kilobytes</para>
    </listitem>
    <listitem>
     <para>The length of a <type>tsvector</type> (lexemes + positions) must be
     less than 1 megabyte</para>
    </listitem>
    <listitem>
     <!-&minus; TODO: number of lexemes in what?  This is unclear -&minus;>
     <para>The number of lexemes must be less than
     2<superscript>64</superscript></para>
    </listitem>
    <listitem>
     <para>Position values in <type>tsvector</type> must be greater than 0 and
     no more than 16,383</para>
    </listitem>
    <listitem>
     <para>The match distance in a <literal>&lt;<replaceable>N</replaceable>&gt;</literal>
     (FOLLOWED BY) <type>tsquery</type> operator cannot be more than
     16,384</para>
    </listitem>
    <listitem>
     <para>No more than 256 positions per lexeme</para>
    </listitem>
    <listitem>
     <para>The number of nodes (lexemes + operators) in a <type>tsquery</type>
     must be less than 32,768</para>
    </listitem>
   </itemizedlist>
  </para>
________________________________________________________-->
  <para>
   <productname>PostgreSQL</productname>的文本搜索特性的当前限制是：
   <itemizedlist  spacing="compact" mark="bullet">
    <listitem>
     <para>每一个词位的长度必须小于 2K 字节</para>
    </listitem>
    <listitem>
     <para>一个<type>tsvector</type>（词位 + 位置）的长度必须小于 1 兆字节</para>
    </listitem>
    <listitem>
     <!-- TODO: number of lexemes in what?  This is unclear -->
     <para>词位的数量必须小于
     2<superscript>64</superscript></para>
    </listitem>
    <listitem>
     <para><type>tsvector</type>中的位置值必须大于 0 并且小于 16,383</para>
    </listitem>
    <listitem>
     <para><literal>&lt;<replaceable>N</replaceable>&gt;</literal>（FOLLOWED BY）<type>tsquery</type>操作符中的匹配距离不能超过 16,384</para>
    </listitem>
    <listitem>
     <para>每个词位不超过 256 个位置</para>
    </listitem>
    <listitem>
     <para> 一个<type>tsquery</type>中结点（词位 + 操作符）的个数必须小于 32,768</para>
    </listitem>
   </itemizedlist>
  </para>
<!-- pgdoc-cn_end sig_en=aa10052088dafd97471f472d9b7f4936 -->

<!-- pgdoc-cn_start sig_en=e33fd81767d4efab49087c7e282c131c sig_cn_org=None source=14.1 
  <para>
   For comparison, the <productname>PostgreSQL</productname> 8.1 documentation
   contained 10,441 unique words, a total of 335,420 words, and the most
   frequent word <quote>postgresql</quote> was mentioned 6,127 times in 655
   documents.
  </para>
________________________________________________________-->
  <para>
   为了对比，<productname>PostgreSQL</productname> 8.1 的文档包含 10,441 个唯一词，总数 335,420 个词，并且最频繁的词<quote>postgresql</quote>在 655 个文档中被提到 6,127 次。
  </para>
<!-- pgdoc-cn_end sig_en=e33fd81767d4efab49087c7e282c131c -->

   <!-- TODO we need to put a date on these numbers? -->
<!-- pgdoc-cn_start sig_en=79c55a713434761db63d5321811d66a1 sig_cn_org=None source=14.1 
  <para>
   Another example &mdash; the <productname>PostgreSQL</productname> mailing
   list archives contained 910,989 unique words with 57,491,343 lexemes in
   461,020 messages.
  </para>
________________________________________________________-->
  <para>
   另一个例子 &mdash; <productname>PostgreSQL</productname>的邮件列表归档在 461,020 条消息的 57,491,343 个词位中包含 910,989 个唯一词。
  </para>
<!-- pgdoc-cn_end sig_en=79c55a713434761db63d5321811d66a1 -->

 </sect1>

</chapter>
