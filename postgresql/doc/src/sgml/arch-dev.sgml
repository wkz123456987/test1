<!-- doc/src/sgml/arch-dev.sgml -->

 <chapter id="overview">
<!-- pgdoc-cn_start sig_en=47ccb1278d0291a5cb60c740ba3fffa9 sig_cn_org=None source=14.1 
  <title>Overview of PostgreSQL Internals</title>
________________________________________________________-->
  <title>PostgreSQL内部概述</title>
<!-- pgdoc-cn_end sig_en=47ccb1278d0291a5cb60c740ba3fffa9 -->

  <note>
<!-- pgdoc-cn_start sig_en=4cfae8ddf9b6dcc33177b633e0f1dcfc sig_cn_org=None source=14.1 
   <title>Author</title>
________________________________________________________-->
   <title>作者</title>
<!-- pgdoc-cn_end sig_en=4cfae8ddf9b6dcc33177b633e0f1dcfc -->
<!-- pgdoc-cn_start sig_en=6b635e48434fe054c7c489384c0cdf62 sig_cn_org=None source=14.1 
   <para>
    This chapter originated as part of
    <xref linkend="sim98"/> Stefan Simkovics'
    Master's Thesis prepared at Vienna University of Technology under the direction
    of O.Univ.Prof.Dr. Georg Gottlob and Univ.Ass. Mag. Katrin Seyr.
   </para>
________________________________________________________-->
   <para>
    这一章的内容来自于<xref linkend="sim98"/>的一部分，它是Stefan Simkovics在维也纳技术大学的硕士学位论文，指导人是 Georg Gottlob教授和Mag. Katrin Seyr。
   </para>
<!-- pgdoc-cn_end sig_en=6b635e48434fe054c7c489384c0cdf62 -->
  </note>

<!-- pgdoc-cn_start sig_en=92c105eb59d845a7c452771b90a0f5a6 sig_cn_org=None source=14.1 
  <para>
   This chapter gives an overview of the internal structure of the
   backend of <productname>PostgreSQL</productname>.  After having
   read the following sections you should have an idea of how a query
   is processed.  This chapter is intended to help the reader
   understand the general sequence of operations that occur within the
   backend from the point at which a query is received, to the point
   at which the results are returned to the client.
  </para>
________________________________________________________-->
  <para>
   本章给出了<productname>PostgreSQL</productname>后台内部结构的一个总览。在阅读了下面的小节后，你将对一个查询是如何被执行的有一定了解。
   本章希望帮助读者理解当后台收到一个查询后，在结果被返回给客户之前通常会发生怎样的操作。
  </para>
<!-- pgdoc-cn_end sig_en=92c105eb59d845a7c452771b90a0f5a6 -->

  <sect1 id="query-path">
<!-- pgdoc-cn_start sig_en=44ac942c58e163729856690b05db5626 sig_cn_org=None source=14.1 
   <title>The Path of a Query</title>
________________________________________________________-->
   <title>一个查询的路径</title>
<!-- pgdoc-cn_end sig_en=44ac942c58e163729856690b05db5626 -->

<!-- pgdoc-cn_start sig_en=6bdc40549b20eebcd0b56ab45b20cddd sig_cn_org=None source=14.1 
   <para>
    Here we give a short overview of the stages a query has to pass
    to obtain a result.
   </para>
________________________________________________________-->
   <para>
    这里我们将对查询到获取结果之间的阶段给与简要概述。
   </para>
<!-- pgdoc-cn_end sig_en=6bdc40549b20eebcd0b56ab45b20cddd -->

   <procedure>
    <step>
<!-- pgdoc-cn_start sig_en=a659005e10e6b560d37d2f40716f6c32 sig_cn_org=None source=14.1 
     <para>
      A connection from an application program to the <productname>PostgreSQL</productname>
      server has to be established. The application program transmits a
      query to the server and waits to receive the results sent back by the
      server.
     </para>
________________________________________________________-->
     <para>
      一个由应用程序到<productname>PostgreSQL</productname>服务器的连接必须被建立。应用程序传递一个查询给服务器并等待接收由服务器传回的结果。
     </para>
<!-- pgdoc-cn_end sig_en=a659005e10e6b560d37d2f40716f6c32 -->
    </step>

    <step>
<!-- pgdoc-cn_start sig_en=a910c566579dbd6d5b727599d30ee726 sig_cn_org=None source=14.1 
     <para>
      The <firstterm>parser stage</firstterm> checks the query
      transmitted by the application
      program for correct syntax and creates
      a <firstterm>query tree</firstterm>.
     </para>
________________________________________________________-->
     <para>
      <firstterm>分析阶段</firstterm>对由应用程序传递的查询进行语法检查，并创建一个<firstterm>查询树</firstterm>。
     </para>
<!-- pgdoc-cn_end sig_en=a910c566579dbd6d5b727599d30ee726 -->
    </step>

    <step>
<!-- pgdoc-cn_start sig_en=c892263bb0ae892ce231ca9f4f4d3b92 sig_cn_org=None source=14.1 
     <para>
      The <firstterm>rewrite system</firstterm> takes
      the query tree created by the parser stage and looks for
      any <firstterm>rules</firstterm> (stored in the
      <firstterm>system catalogs</firstterm>) to apply to
      the query tree.  It performs the
      transformations given in the <firstterm>rule bodies</firstterm>.
     </para>
________________________________________________________-->
     <para>
      <firstterm>重写系统</firstterm>得到分析阶段创建的查询树，并查找可以应用到该查询树的任何<firstterm>规则</firstterm>（存储在<firstterm>系统目录</firstterm>中）。对找到的规则，它会执行<firstterm>规则体</firstterm>中给定的转换。
     </para>
<!-- pgdoc-cn_end sig_en=c892263bb0ae892ce231ca9f4f4d3b92 -->

<!-- pgdoc-cn_start sig_en=9027ee328b548d01d6c7c2a771e7a7c6 sig_cn_org=None source=14.1 
     <para>
      One application of the rewrite system is in the realization of
      <firstterm>views</firstterm>.
      Whenever a query against a view
      (i.e., a <firstterm>virtual table</firstterm>) is made,
      the rewrite system rewrites the user's query to
      a query that accesses the <firstterm>base tables</firstterm> given in
      the <firstterm>view definition</firstterm> instead.
     </para>
________________________________________________________-->
     <para>
      重写系统的一个应用是实现<firstterm>视图</firstterm>。不论何时发生一个视图（即一个<firstterm>虚拟表</firstterm>）上的查询，重写系统将用户查询重写为一个访问<firstterm>视图定义</firstterm>中给定的<firstterm>基本表</firstterm>的查询来替代。
     </para>
<!-- pgdoc-cn_end sig_en=9027ee328b548d01d6c7c2a771e7a7c6 -->
    </step>

    <step>
<!-- pgdoc-cn_start sig_en=d4882d35bb1d8b1408c6ff738eb25838 sig_cn_org=None source=14.1 
     <para>
      The <firstterm>planner/optimizer</firstterm> takes
      the (rewritten) query tree and creates a
      <firstterm>query plan</firstterm> that will be the input to the
      <firstterm>executor</firstterm>.
     </para>
________________________________________________________-->
     <para>
      <firstterm>规划器/优化器</firstterm>接手（重写过的）查询树并创建一个将被作为<firstterm>执行器</firstterm>输入的<firstterm>查询计划</firstterm>。
     </para>
<!-- pgdoc-cn_end sig_en=d4882d35bb1d8b1408c6ff738eb25838 -->

<!-- pgdoc-cn_start sig_en=2e81a12dc6f25f6e81669d3035686000 sig_cn_org=None source=14.1 
     <para>
      It does so by first creating all possible <firstterm>paths</firstterm>
      leading to the same result. For example if there is an index on a
      relation to be scanned, there are two paths for the
      scan. One possibility is a simple sequential scan and the other
      possibility is to use the index. Next the cost for the execution of
      each path is estimated and the cheapest path is chosen.  The cheapest
      path is expanded into a complete plan that the executor can use.
     </para>
________________________________________________________-->
     <para>
      它会先创建所有可能导向相同结果的<firstterm>路径</firstterm>。例如，如果在一个被扫描的关系上有一个索引，则有两条可供扫描的路径。其中之一是一个简单的顺序扫描，而另一个则是使用索引。接下来执行每条路径所需的代价被估算出来并且代价最低的路径将被选中。代价最低的路径将被扩展成一个完整的计划可供执行器使用。
     </para>
<!-- pgdoc-cn_end sig_en=2e81a12dc6f25f6e81669d3035686000 -->
    </step>

    <step>
<!-- pgdoc-cn_start sig_en=eb3e9f95e32b0ff448b696c865d336db sig_cn_org=None source=14.1 
     <para>
      The executor recursively steps through
      the <firstterm>plan tree</firstterm> and
      retrieves rows in the way represented by the plan.
      The executor makes use of the
      <firstterm>storage system</firstterm> while scanning
      relations, performs <firstterm>sorts</firstterm> and <firstterm>joins</firstterm>,
      evaluates <firstterm>qualifications</firstterm> and finally hands back the rows derived.
     </para>
________________________________________________________-->
     <para>
      执行器递归地逐步通过<firstterm>计划树</firstterm>并按照计划表述的方式获取行。执行器在扫描关系时会使用<firstterm>存储系统</firstterm>、执行<firstterm>排序</firstterm>和<firstterm>连接</firstterm>、估算<firstterm>条件</firstterm>并最后归还得到的行。
     </para>
<!-- pgdoc-cn_end sig_en=eb3e9f95e32b0ff448b696c865d336db -->
    </step>
   </procedure>

<!-- pgdoc-cn_start sig_en=383385c949bea2a11a394e5e233cbd0a sig_cn_org=None source=14.1 
   <para>
    In the following sections we will cover each of the above listed items
    in more detail to give a better understanding of <productname>PostgreSQL</productname>'s internal
    control and data structures.
   </para>
________________________________________________________-->
   <para>
    在下面的小节中我们将覆盖上述列出的每一项的详细内容，以便更好地理解<productname>PostgreSQL</productname>的内部控制和数据结构。
   </para>
<!-- pgdoc-cn_end sig_en=383385c949bea2a11a394e5e233cbd0a -->
  </sect1>

  <sect1 id="connect-estab">
<!-- pgdoc-cn_start sig_en=3343fbbff3789fdd182d7098d6b8aa07 sig_cn_org=None source=14.1 
   <title>How Connections Are Established</title>
________________________________________________________-->
   <title>连接如何建立</title>
<!-- pgdoc-cn_end sig_en=3343fbbff3789fdd182d7098d6b8aa07 -->

<!-- pgdoc-cn_start sig_en=97aabfcc7aea0d8c388f6ea729e5b4b4 sig_cn_org=None source=14.1 
   <para>
    <productname>PostgreSQL</productname> implements a
    <quote>process per user</quote> client/server model.
    In this model, every
    <glossterm linkend="glossary-client">client process</glossterm>
    connects to exactly one
    <glossterm linkend="glossary-backend">backend process</glossterm>.
    As we do not know ahead of time how many connections will be made,
    we have to use a <quote>supervisor process</quote> that spawns a new
    backend process every time a connection is requested. This supervisor
    process is called
    <glossterm linkend="glossary-postmaster">postmaster</glossterm>
    and listens at a specified TCP/IP port for incoming connections.
    Whenever it detects a request for a connection, it spawns a new
    backend process.  Those backend processes communicate with each
    other and with other processes of the
    <glossterm linkend="glossary-instance">instance</glossterm>
    using <firstterm>semaphores</firstterm> and
    <glossterm linkend="glossary-shared-memory">shared memory</glossterm>
    to ensure data integrity throughout concurrent data access.
   </para>
________________________________________________________-->
   <para>
    <productname>PostgreSQL</productname>实现了<quote>process per user</quote>客户端/服务器模型。
    在这个模型中，每个<glossterm linkend="glossary-client">客户端进程</glossterm> 只连接到一个<glossterm linkend="glossary-backend">后端进程</glossterm>。
    由于我们无法预先知道会有多少连接被建立，我们必须使用一个<quote>守护者进程(supervisor process)</quote>在每次连接请求时生产一个新的服务器进程。
    该守护者进程被称为<glossterm linkend="glossary-postmaster">postmaster</glossterm>，它在一个特定的TCP/IP端口监听进入的连接。
    当一个连接请求被监测到时，它会产生一个新的后端进程。
    后端进程相互之间，以及与<glossterm linkend="glossary-instance">instance</glossterm>中的其他进程之间，通过<firstterm>semaphores</firstterm> 和 <glossterm linkend="glossary-shared-memory">shared memory</glossterm>进行通信，以保证并发数据访问时的数据完整性。
   </para>
<!-- pgdoc-cn_end sig_en=97aabfcc7aea0d8c388f6ea729e5b4b4 -->

<!-- pgdoc-cn_start sig_en=f37d682d8b15dc90c507376a188fa9cb sig_cn_org=None source=14.1 
   <para>
    The client process can be any program that understands the
    <productname>PostgreSQL</productname> protocol described in
    <xref linkend="protocol"/>.  Many clients are based on the
    C-language library <application>libpq</application>, but several independent
    implementations of the protocol exist, such as the Java
    <application>JDBC</application> driver.
   </para>
________________________________________________________-->
   <para>
    客户端进程可以是任何符合<productname>PostgreSQL</productname>协议（见<xref linkend="protocol"/>）的程序。很多客户端基于C语言库<application>libpq</application>，但也有一些该协议的独立实现存在，例如Java的<application>JDBC</application>驱动。
   </para>
<!-- pgdoc-cn_end sig_en=f37d682d8b15dc90c507376a188fa9cb -->

<!-- pgdoc-cn_start sig_en=defbf2efe8790ad0384f26d69c1f102b sig_cn_org=None source=14.1 
   <para>
    Once a connection is established, the client process can send a query
    to the backend process it's connected to. The query is transmitted using
    plain text, i.e., there is no parsing done in the client. The backend
    process parses the query, creates an <firstterm>execution plan</firstterm>,
    executes the plan, and returns the retrieved rows to the client
    by transmitting them over the established connection.
   </para>
________________________________________________________-->
   <para>
    一旦一个连接被建立，客户端进程可以给它连接的后端进程发送一个查询。
    查询被以纯文本传送，在客户端不做分析。
    后端进程会分析查询，创建一个<firstterm>执行计划</firstterm>，然后执行这个计划，并通过已建立的连接向客户端返回检索到的行。
   </para>
<!-- pgdoc-cn_end sig_en=defbf2efe8790ad0384f26d69c1f102b -->
  </sect1>

  <sect1 id="parser-stage">
<!-- pgdoc-cn_start sig_en=8f2fc1bb3baee4a5d8e3a464cf4620a9 sig_cn_org=None source=14.1 
   <title>The Parser Stage</title>
________________________________________________________-->
   <title>分析器阶段</title>
<!-- pgdoc-cn_end sig_en=8f2fc1bb3baee4a5d8e3a464cf4620a9 -->

<!-- pgdoc-cn_start sig_en=986efdecf38b7151b2ac103b6f0f0373 sig_cn_org=None source=14.1 
   <para>
    The <firstterm>parser stage</firstterm> consists of two parts:

    <itemizedlist>
     <listitem>
      <para>
       The <firstterm>parser</firstterm> defined in
       <filename>gram.y</filename> and <filename>scan.l</filename> is
       built using the Unix tools <application>bison</application>
       and <application>flex</application>.
      </para>
     </listitem>
     <listitem>
      <para>
       The <firstterm>transformation process</firstterm> does
       modifications and augmentations to the data structures returned by the parser.
      </para>
     </listitem>
    </itemizedlist>
   </para>
________________________________________________________-->
   <para>
    <firstterm>分析器阶段</firstterm>由两部分组成：

    <itemizedlist>
     <listitem>
      <para>
       <firstterm>分析器</firstterm>定义在<filename>gram.y</filename>和<filename>scan.l</filename>中，它使用Unix工具<application>bison</application>和<application>flex</application>构建。
      </para>
     </listitem>
     <listitem>
      <para>
       <firstterm>转换处理</firstterm>将对分析器返回的数据结构进行修改和增加。
      </para>
     </listitem>
    </itemizedlist>
   </para>
<!-- pgdoc-cn_end sig_en=986efdecf38b7151b2ac103b6f0f0373 -->

   <sect2>
<!-- pgdoc-cn_start sig_en=34e3e1c05cdcb7f799fc3a8180f6ddb8 sig_cn_org=None source=14.1 
    <title>Parser</title>
________________________________________________________-->
    <title>分析器</title>
<!-- pgdoc-cn_end sig_en=34e3e1c05cdcb7f799fc3a8180f6ddb8 -->

<!-- pgdoc-cn_start sig_en=4a688508461fac97ad0e4ba4c5d39dae sig_cn_org=None source=14.1 
    <para>
     The parser has to check the query string (which arrives as plain
     text) for valid syntax. If the syntax is correct a
     <firstterm>parse tree</firstterm> is built up and handed back;
     otherwise an error is returned. The parser and lexer are
     implemented using the well-known Unix tools <application>bison</application>
     and <application>flex</application>.
    </para>
________________________________________________________-->
    <para>
     分析器必须检查查询字符串（以纯文本形式到达）是否为合法语法。如果语法正确将建立一个<firstterm>分析树</firstterm>并返回之，否则将返回一个错误。 语法分析器和词法分析器使用著名的Unix工具<application>bison</application>和<application>flex</application>实现。
    </para>
<!-- pgdoc-cn_end sig_en=4a688508461fac97ad0e4ba4c5d39dae -->

<!-- pgdoc-cn_start sig_en=25d2ada566ce7f491afef366bdd097d0 sig_cn_org=None source=14.1 
    <para>
     The <firstterm>lexer</firstterm> is defined in the file
     <filename>scan.l</filename> and is responsible
     for recognizing <firstterm>identifiers</firstterm>,
     the <firstterm>SQL key words</firstterm> etc. For
     every key word or identifier that is found, a <firstterm>token</firstterm>
     is generated and handed to the parser.
    </para>
________________________________________________________-->
    <para>
     <firstterm>词法分析器</firstterm>定义在文件<filename>scan.l</filename>中，并负责识别<firstterm>标识符</firstterm>、<firstterm>SQL关键词</firstterm>等。对于找到的每一个关键词或标识符将生成一个<firstterm>记号</firstterm>并返回给语法分析器。
    </para>
<!-- pgdoc-cn_end sig_en=25d2ada566ce7f491afef366bdd097d0 -->

<!-- pgdoc-cn_start sig_en=01cb67eb34c5a4617a77e95d3d30d6c1 sig_cn_org=None source=14.1 
    <para>
     The parser is defined in the file <filename>gram.y</filename> and
     consists of a set of <firstterm>grammar rules</firstterm> and
     <firstterm>actions</firstterm> that are executed whenever a rule
     is fired. The code of the actions (which is actually C code) is
     used to build up the parse tree.
    </para>
________________________________________________________-->
    <para>
     语法分析器定义在<filename>gram.y</filename>文件中，它由一组<firstterm>语法规则</firstterm> 和<firstterm>动作</firstterm>，动作将在规则被触发时被执行。动作的代码（实际上是C代码）将被用于构建分析树。
    </para>
<!-- pgdoc-cn_end sig_en=01cb67eb34c5a4617a77e95d3d30d6c1 -->

<!-- pgdoc-cn_start sig_en=68adefb4e9c61e45b0e1aa275136b6f3 sig_cn_org=None source=14.1 
    <para>
     The file <filename>scan.l</filename> is transformed to the C
     source file <filename>scan.c</filename> using the program
     <application>flex</application> and <filename>gram.y</filename> is
     transformed to <filename>gram.c</filename> using
     <application>bison</application>.  After these transformations
     have taken place a normal C compiler can be used to create the
     parser. Never make any changes to the generated C files as they
     will be overwritten the next time <application>flex</application>
     or <application>bison</application> is called.

     <note>
      <para>
       The mentioned transformations and compilations are normally done
       automatically using the <firstterm>makefiles</firstterm>
       shipped with the <productname>PostgreSQL</productname>
       source distribution.
      </para>
     </note>
    </para>
________________________________________________________-->
    <para>
     程序<application>flex</application>把文件<filename>scan.l</filename>转换成C源文件<filename>scan.c</filename>， 程序<application>bison</application>把文件<filename>gram.y</filename>转换为<filename>gram.c</filename>。在这些转换结束后，一个正规的C编译器就可以用于创建分析器。绝不要对生成的C文件做任何修改，因为每次<application>flex</application>或<application>bison</application>被调用都会重写它们。

     <note>
      <para>
       前面提到的转换和编译通常是由随<productname>PostgreSQL</productname>源代码发布的<firstterm>makefiles</firstterm>自动完成。
      </para>
     </note>
    </para>
<!-- pgdoc-cn_end sig_en=68adefb4e9c61e45b0e1aa275136b6f3 -->

<!-- pgdoc-cn_start sig_en=8bec4782e89c9cb86e0b1e0b9b85d582 sig_cn_org=None source=14.1 
    <para>
     A detailed description of <application>bison</application> or
     the grammar rules given in <filename>gram.y</filename> would be
     beyond the scope of this manual. There are many books and
     documents dealing with <application>flex</application> and
     <application>bison</application>. You should be familiar with
     <application>bison</application> before you start to study the
     grammar given in <filename>gram.y</filename> otherwise you won't
     understand what happens there.
    </para>
________________________________________________________-->
    <para>
     对于<application>bison</application>的详细介绍或者<filename>gram.y</filename>中的语法规则超出了本指南的范围。
     有很多书籍和文档介绍<application>flex</application>和<application>bison</application>。
     在学习<filename>gram.y</filename>中的语法之前你应该先熟悉<application>bison</application>，否则你将无法理解发生了什么。
    </para>
<!-- pgdoc-cn_end sig_en=8bec4782e89c9cb86e0b1e0b9b85d582 -->

   </sect2>

   <sect2>
<!-- pgdoc-cn_start sig_en=e2c1f1255a8be2aeffdd223102ad3f3c sig_cn_org=None source=14.1 
     <title>Transformation Process</title>
________________________________________________________-->
     <title>转换处理</title>
<!-- pgdoc-cn_end sig_en=e2c1f1255a8be2aeffdd223102ad3f3c -->

<!-- pgdoc-cn_start sig_en=77e7317b12fe406fe61b6a7b00d5472a sig_cn_org=None source=14.1 
    <para>
     The parser stage creates a parse tree using only fixed rules about
     the syntactic structure of SQL.  It does not make any lookups in the
     system catalogs, so there is no possibility to understand the detailed
     semantics of the requested operations.  After the parser completes,
     the <firstterm>transformation process</firstterm> takes the tree handed
     back by the parser as input and does the semantic interpretation needed
     to understand which tables, functions, and operators are referenced by
     the query.  The data structure that is built to represent this
     information is called the <firstterm>query tree</firstterm>.
    </para>
________________________________________________________-->
    <para>
     分析阶段根据SQL的语法结构的固定规则创建一个分析树。它不会在系统目录做任何查找，这样它不可能了解所请求的操作的详细语义。在分析器完成之后，<firstterm>转换处理</firstterm>接手分析器返还的树，并进行语义解释来理解该查询引用了哪些表、函数和操作符。用于表示该信息的数据结构被称为<firstterm>查询树</firstterm>。
    </para>
<!-- pgdoc-cn_end sig_en=77e7317b12fe406fe61b6a7b00d5472a -->

<!-- pgdoc-cn_start sig_en=2189ac3300a82a40eaca21f3d0a4087a sig_cn_org=029dc26480374dc768ca0d67a4e25c43 source=15.7 
    <para>
     The reason for separating raw parsing from semantic analysis is that
     system catalog lookups can only be done within a transaction, and we
     do not wish to start a transaction immediately upon receiving a query
     string.  The raw parsing stage is sufficient to identify the transaction
     control commands (<command>BEGIN</command>, <command>ROLLBACK</command>, etc.), and
     these can then be correctly executed without any further analysis.
     Once we know that we are dealing with an actual query (such as
     <command>SELECT</command> or <command>UPDATE</command>), it is okay to
     start a transaction if we're not already in one.  Only then can the
     transformation process be invoked.
    </para>
________________________________________________________-->
    <para>
     将原始解析与语义分析分开的原因是系统目录查找只能在事务内完成，我们不希望在接收到查询字符串后立即启动事务。原始解析阶段足以识别事务控制命令（<command>BEGIN</command>，<command>ROLLBACK</command>等），然后可以正确执行这些命令而无需进一步分析。一旦我们知道正在处理实际查询（如<command>SELECT</command>或<command>UPDATE</command>），如果我们尚未处于事务中，则可以启动事务。只有在这种情况下才能调用转换过程。
    </para>
<!-- pgdoc-cn_end sig_en=2189ac3300a82a40eaca21f3d0a4087a -->

<!-- pgdoc-cn_start sig_en=5ecea55709715ef09b237f03394bdc14 sig_cn_org=None source=14.1 
    <para>
     The query tree created by the transformation process is structurally
     similar to the raw parse tree in most places, but it has many differences
     in detail.  For example, a <structname>FuncCall</structname> node in the
     parse tree represents something that looks syntactically like a function
     call.  This might be transformed to either a <structname>FuncExpr</structname>
     or <structname>Aggref</structname> node depending on whether the referenced
     name turns out to be an ordinary function or an aggregate function.
     Also, information about the actual data types of columns and expression
     results is added to the query tree.
    </para>
________________________________________________________-->
    <para>
     由转换处理创建的查询树在结构上和原始分析树有很多地方相似，但是在细节上有很多不同之处。例如，分析树中的一个<structname>FuncCall</structname>节点表示某些在语法上看起来像一个函数调用的东西。它可能被转换成一个<structname>FuncExpr</structname>或<structname>Aggref</structname>节点，取决于被引用的名字是一个普通函数或是一个聚集函数。此外，关于列和表达式结果的实际数据类型的信息被加入到了查询树中。
    </para>
<!-- pgdoc-cn_end sig_en=5ecea55709715ef09b237f03394bdc14 -->
   </sect2>
  </sect1>

  <sect1 id="rule-system">
<!-- pgdoc-cn_start sig_en=7eaeb6b13a34242f288c24be74fa37b9 sig_cn_org=None source=14.1 
   <title>The <productname>PostgreSQL</productname> Rule System</title>
________________________________________________________-->
   <title><productname>PostgreSQL</productname>规则系统</title>
<!-- pgdoc-cn_end sig_en=7eaeb6b13a34242f288c24be74fa37b9 -->

<!-- pgdoc-cn_start sig_en=cfcafb1355dd33de0c1436e5cf1fc8b4 sig_cn_org=None source=14.1 
   <para>
    <productname>PostgreSQL</productname> supports a powerful
    <firstterm>rule system</firstterm> for the specification
    of <firstterm>views</firstterm> and ambiguous <firstterm>view updates</firstterm>.
    Originally the <productname>PostgreSQL</productname>
    rule system consisted of two implementations:

    <itemizedlist>
     <listitem>
      <para>
       The first one worked using <firstterm>row level</firstterm> processing and was
       implemented deep in the <firstterm>executor</firstterm>. The rule system was
       called whenever an individual row had been accessed. This
       implementation was removed in 1995 when the last official release
       of the <productname>Berkeley Postgres</productname> project was
       transformed into <productname>Postgres95</productname>.
      </para>
     </listitem>

     <listitem>
      <para>
       The second implementation of the rule system is a technique
       called <firstterm>query rewriting</firstterm>.
       The <firstterm>rewrite system</firstterm> is a module
       that exists between the <firstterm>parser stage</firstterm> and the
       <firstterm>planner/optimizer</firstterm>. This technique is still implemented.
      </para>
     </listitem>
    </itemizedlist>
   </para>
________________________________________________________-->
   <para>
    <productname>PostgreSQL</productname>支持一个强大的
    <firstterm>规则系统</firstterm>用于支持<firstterm>视图</firstterm>说明和模糊不清的<firstterm>视图更新</firstterm>。本来<productname>PostgreSQL</productname>规则系统由两种实现组成：

    <itemizedlist>
     <listitem>
      <para>
       第一种利用<firstterm>行级</firstterm>处理工作，并且被实现于<firstterm>执行器</firstterm>深层。当单独一行被访问时规则系统被调用。这种实现在1995年被移除，那时最后一个<productname>Berkeley Postgres</productname>项目的官方发布被转换为<productname>Postgres95</productname>。
      </para>
     </listitem>

     <listitem>
      <para>
       第二种规则系统的实现是一种称为<firstterm>查询重写</firstterm>的技术。<firstterm>重写系统</firstterm>是一个存在于<firstterm>分析器阶段</firstterm>和<firstterm>规划器/优化器</firstterm>之间的模块。这种技术也被实现了。
      </para>
     </listitem>
    </itemizedlist>
   </para>
<!-- pgdoc-cn_end sig_en=cfcafb1355dd33de0c1436e5cf1fc8b4 -->

<!-- pgdoc-cn_start sig_en=71b37a8ea57a2da13b97d4aa0118d815 sig_cn_org=None source=14.1 
   <para>
    The query rewriter is discussed in some detail in
    <xref linkend="rules"/>, so there is no need to cover it here.
    We will only point out that both the input and the output of the
    rewriter are query trees, that is, there is no change in the
    representation or level of semantic detail in the trees.  Rewriting
    can be thought of as a form of macro expansion.
   </para>
________________________________________________________-->
   <para>
    更多关于查询重写器的讨论可见<xref linkend="rules"/>，因此没有必要在这里涉及这些内容。我们将仅指出重写器的输入和输出都是查询树，即在树的表现形式或语义细节层次上都没有改变。重写可以被看成是某种形式的宏扩展。
   </para>
<!-- pgdoc-cn_end sig_en=71b37a8ea57a2da13b97d4aa0118d815 -->

  </sect1>

  <sect1 id="planner-optimizer">
<!-- pgdoc-cn_start sig_en=6bbec027ba9b706d7257a6740cc0dbd7 sig_cn_org=None source=14.1 
   <title>Planner/Optimizer</title>
________________________________________________________-->
   <title>规划器/优化器</title>
<!-- pgdoc-cn_end sig_en=6bbec027ba9b706d7257a6740cc0dbd7 -->

<!-- pgdoc-cn_start sig_en=b7842d63d3d8a8385134fe3f56d7fdb1 sig_cn_org=None source=14.1 
   <para>
    The task of the <firstterm>planner/optimizer</firstterm> is to
    create an optimal execution plan. A given SQL query (and hence, a
    query tree) can be actually executed in a wide variety of
    different ways, each of which will produce the same set of
    results.  If it is computationally feasible, the query optimizer
    will examine each of these possible execution plans, ultimately
    selecting the execution plan that is expected to run the fastest.
   </para>
________________________________________________________-->
   <para>
    <firstterm>规划器/优化器</firstterm>的任务是创建一个最佳的执行计划。一个给定的SQL查询（今后将是一个查询树）实际上可以以很多种不同的方式被执行，其中的每一种都会产生相同的结果集。如果在计算上可行，查询优化器将检查这些可能的执行计划中的每一个，最后选择其中被期望“跑得最快的”那一个。
   </para>
<!-- pgdoc-cn_end sig_en=b7842d63d3d8a8385134fe3f56d7fdb1 -->

   <note>
<!-- pgdoc-cn_start sig_en=1a9f9be228e309008e6ff950089e1f89 sig_cn_org=None source=14.1 
    <para>
     In some situations, examining each possible way in which a query
     can be executed would take an excessive amount of time and memory.
     In particular, this occurs when executing queries
     involving large numbers of join operations. In order to determine
     a reasonable (not necessarily optimal) query plan in a reasonable amount
     of time, <productname>PostgreSQL</productname> uses a <firstterm>Genetic
     Query Optimizer</firstterm> (see <xref linkend="geqo"/>) when the number of joins
     exceeds a threshold (see <xref linkend="guc-geqo-threshold"/>).
    </para>
________________________________________________________-->
    <para>
     在某些情况下，检查一个查询的每一种可能的执行方式会耗费非常多的时间和内存。特别是当查询涉及到大量连接操作时。
     为了能在合理的时间内决定一个合理的（不一定是最佳的）查询计划，当连接数量超过一个阈值（见<xref linkend="guc-geqo-threshold"/>）时<productname>PostgreSQL</productname>使用了一种<firstterm>遗传查询优化器</firstterm> （见<xref linkend="geqo"/>）。
    </para>
<!-- pgdoc-cn_end sig_en=1a9f9be228e309008e6ff950089e1f89 -->
   </note>

<!-- pgdoc-cn_start sig_en=97acb1b787527d04ccf3f5882d0506a3 sig_cn_org=None source=14.1 
   <para>
    The planner's search procedure actually works with data structures
    called <firstterm>paths</firstterm>, which are simply cut-down representations of
    plans containing only as much information as the planner needs to make
    its decisions. After the cheapest path is determined, a full-fledged
    <firstterm>plan tree</firstterm> is built to pass to the executor.  This represents
    the desired execution plan in sufficient detail for the executor to run it.
    In the rest of this section we'll ignore the distinction between paths
    and plans.
   </para>
________________________________________________________-->
   <para>
    规划器搜索过程实际上依靠称为<firstterm>路径</firstterm>的数据结构工作，它是一种缩短版的计划，其中只包含规划器做决定所需要的信息。当最低代价的路径被确定后，一个全功能的<firstterm>计划树</firstterm>将被建立并传递给执行器。这表示所期望的执行计划已经拥有足够的细节以供执行器执行它。在本节剩下的部分，我们将忽略路径和计划之间的区别。
   </para>
<!-- pgdoc-cn_end sig_en=97acb1b787527d04ccf3f5882d0506a3 -->

   <sect2>
<!-- pgdoc-cn_start sig_en=78d347458d267a3a771129967c8ccc07 sig_cn_org=None source=14.1 
    <title>Generating Possible Plans</title>
________________________________________________________-->
    <title>生成可能的计划</title>
<!-- pgdoc-cn_end sig_en=78d347458d267a3a771129967c8ccc07 -->

<!-- pgdoc-cn_start sig_en=be96ea3b33312e51434c37f56b9b609c sig_cn_org=None source=14.1 
    <para>
     The planner/optimizer starts by generating plans for scanning each
     individual relation (table) used in the query.  The possible plans
     are determined by the available indexes on each relation.
     There is always the possibility of performing a
     sequential scan on a relation, so a sequential scan plan is always
     created. Assume an index is defined on a
     relation (for example a B-tree index) and a query contains the
     restriction
     <literal>relation.attribute OPR constant</literal>. If
     <literal>relation.attribute</literal> happens to match the key of the B-tree
     index and <literal>OPR</literal> is one of the operators listed in
     the index's <firstterm>operator class</firstterm>, another plan is created using
     the B-tree index to scan the relation. If there are further indexes
     present and the restrictions in the query happen to match a key of an
     index, further plans will be considered.  Index scan plans are also
     generated for indexes that have a sort ordering that can match the
     query's <literal>ORDER BY</literal> clause (if any), or a sort ordering that
     might be useful for merge joining (see below).
    </para>
________________________________________________________-->
    <para>
     规划器/优化器从扫描查询中用到的每一个单独的关系（表）开始生成计划。可能的计划根据每一个关系上可用的索引决定。在一个关系上总是有执行一个顺序扫描的可能，因此一个顺序扫描计划总是会被创建。假设在一个关系上定义有一个索引（例如一个B-tree索引）并且查询包含限制<literal>relation.attribute OPR constant</literal>。如果<literal>relation.attribute</literal>正好匹配该B-tree索引的键并且<literal>OPR</literal>是该索引的<firstterm>操作符类</firstterm>之一，另一个使用B-tree索引扫描该索引的计划将被创建。如果还有索引存在且查询中的限制正好匹配一个索引的键，其他计划也会被考虑。如果有索引的顺序能匹配<literal>ORDER BY</literal>子句（如果有）或者对于归并连接有用（见下文），也会为该索引创建索引扫描计划。
    </para>
<!-- pgdoc-cn_end sig_en=be96ea3b33312e51434c37f56b9b609c -->

<!-- pgdoc-cn_start sig_en=50c188bb0e86d7cd4c9460877b39ed3b sig_cn_org=None source=14.1 
    <para>
     If the query requires joining two or more relations,
     plans for joining relations are considered
     after all feasible plans have been found for scanning single relations.
     The three available join strategies are:

     <itemizedlist>
      <listitem>
       <para>
        <firstterm>nested loop join</firstterm>: The right relation is scanned
        once for every row found in the left relation. This strategy
        is easy to implement but can be very time consuming.  (However,
        if the right relation can be scanned with an index scan, this can
        be a good strategy.  It is possible to use values from the current
        row of the left relation as keys for the index scan of the right.)
       </para>
      </listitem>

      <listitem>
       <para>
        <firstterm>merge join</firstterm>: Each relation is sorted on the join
        attributes before the join starts. Then the two relations are
        scanned in parallel, and matching rows are combined to form
        join rows. This kind of join is
        attractive because each relation has to be scanned only once.
        The required sorting might be achieved either by an explicit sort
        step, or by scanning the relation in the proper order using an
        index on the join key.
       </para>
      </listitem>

      <listitem>
       <para>
        <firstterm>hash join</firstterm>: the right relation is first scanned
        and loaded into a hash table, using its join attributes as hash keys.
        Next the left relation is scanned and the
        appropriate values of every row found are used as hash keys to
        locate the matching rows in the table.
       </para>
      </listitem>
     </itemizedlist>
    </para>
________________________________________________________-->
    <para>
     如果查询需要连接两个或更多关系，在所有扫描单个关系的可能计划都被找到后，连接计划将会被考虑。三种可用的连接策略是：

     <itemizedlist>
      <listitem>
       <para>
        <firstterm>嵌套循环连接</firstterm>: 对左关系找到的每一行都要扫描右关系一次。这种策略最容易实现但是可能非常耗时（但是，如果右关系可以通过索引扫描，这将是一个不错的策略。因为可以用左关系当前行的值来作为右关系上索引扫描的键）。
       </para>
      </listitem>

      <listitem>
       <para>
        <firstterm>归并连接</firstterm>：在连接开始之前，每一个关系都按照连接属性排好序。然后两个关系会被并行扫描，匹配的行被整合成连接行。由于这种连接中每个关系只被扫描一次，因此它很具有吸引力。它所要求的排序可以通过一个显式的排序步骤得到，或使用一个连接键上的索引按适当顺序扫描关系得到。
       </para>
      </listitem>

      <listitem>
       <para>
        <firstterm>哈希连接</firstterm>：右关系先被扫描并且被载入到一个哈希表，使用连接属性作为哈希键。接下来左关系被扫描，扫描中找到的每一行的连接属性值被用作哈希键在哈希表中查找匹配的行。
       </para>
      </listitem>
     </itemizedlist>
    </para>
<!-- pgdoc-cn_end sig_en=50c188bb0e86d7cd4c9460877b39ed3b -->

<!-- pgdoc-cn_start sig_en=beb37cc1b7d32a256ce7885117bc4602 sig_cn_org=None source=14.1 
    <para>
     When the query involves more than two relations, the final result
     must be built up by a tree of join steps, each with two inputs.
     The planner examines different possible join sequences to find the
     cheapest one.
    </para>
________________________________________________________-->
    <para>
     当查询涉及两个以上的关系时，最终结果必须由一个连接步骤树构成，每个连接步骤有两个输入。规划器会检查不同可能的连接序列来找到代价最小的那一个。
    </para>
<!-- pgdoc-cn_end sig_en=beb37cc1b7d32a256ce7885117bc4602 -->

<!-- pgdoc-cn_start sig_en=3778b65208f8bd5cc2a3bcd0b8e4c7d1 sig_cn_org=None source=14.1 
    <para>
     If the query uses fewer than <xref linkend="guc-geqo-threshold"/>
     relations, a near-exhaustive search is conducted to find the best
     join sequence.  The planner preferentially considers joins between any
     two relations for which there exists a corresponding join clause in the
     <literal>WHERE</literal> qualification (i.e., for
     which a restriction like <literal>where rel1.attr1=rel2.attr2</literal>
     exists). Join pairs with no join clause are considered only when there
     is no other choice, that is, a particular relation has no available
     join clauses to any other relation. All possible plans are generated for
     every join pair considered by the planner, and the one that is
     (estimated to be) the cheapest is chosen.
    </para>
________________________________________________________-->
    <para>
     如果查询是用的关系数少于<xref linkend="guc-geqo-threshold"/>，将使用一次接近穷举的搜索来查找最好的连接顺序。如果任何两个关系在<literal>WHERE</literal>条件中存在一个相应的连接子句（即存在类似于<literal>where rel1.attr1=rel2.attr2</literal>的限制），规划器会有限考虑它们之间的连接。没有任何连接子句的连接对只有在别无选择时才会被考虑，即一个关系没有任何可用的对于其他关系的连接子句。对规划器所考虑的每一个连接对会生成所有可能的计划，其中代价（被估计为）最低的一个将被选择。
    </para>
<!-- pgdoc-cn_end sig_en=3778b65208f8bd5cc2a3bcd0b8e4c7d1 -->

<!-- pgdoc-cn_start sig_en=97af8454edb47640d4acfb488f0c1b13 sig_cn_org=None source=14.1 
    <para>
     When <varname>geqo_threshold</varname> is exceeded, the join
     sequences considered are determined by heuristics, as described
     in <xref linkend="geqo"/>.  Otherwise the process is the same.
    </para>
________________________________________________________-->
    <para>
     当连接关系数超过<varname>geqo_threshold</varname>时，连接序列将考虑通过启发式方法来确定，详见<xref linkend="geqo"/>。否则处理将和前面相同。
    </para>
<!-- pgdoc-cn_end sig_en=97af8454edb47640d4acfb488f0c1b13 -->

<!-- pgdoc-cn_start sig_en=ccb72071950025cb25c9ed6b3db6335b sig_cn_org=None source=14.1 
    <para>
     The finished plan tree consists of sequential or index scans of
     the base relations, plus nested-loop, merge, or hash join nodes as
     needed, plus any auxiliary steps needed, such as sort nodes or
     aggregate-function calculation nodes.  Most of these plan node
     types have the additional ability to do <firstterm>selection</firstterm>
     (discarding rows that do not meet a specified Boolean condition)
     and <firstterm>projection</firstterm> (computation of a derived column set
     based on given column values, that is, evaluation of scalar
     expressions where needed).  One of the responsibilities of the
     planner is to attach selection conditions from the
     <literal>WHERE</literal> clause and computation of required
     output expressions to the most appropriate nodes of the plan
     tree.
    </para>
________________________________________________________-->
    <para>
     成品计划树包含基本关系的顺序或索引扫描，外加所需的嵌套循环、归并或哈希连接节点，以及任何所需的辅助步骤，例如排序节点或聚集函数计算节点。这些节点中的大部分具有执行<firstterm>选择</firstterm>（丢弃不符合指定布尔条件的行）和<firstterm>投影</firstterm>（根据指定列值计算派生列，即标量表达式的计算）的能力。规划器的职责之一就是在计划树最合适的节点上附加来自于子句的选择条件和需要的输出表达式。
    </para>
<!-- pgdoc-cn_end sig_en=ccb72071950025cb25c9ed6b3db6335b -->
   </sect2>
  </sect1>

  <sect1 id="executor">
<!-- pgdoc-cn_start sig_en=34f02afdb3c0de7ce0e385d73df10c24 sig_cn_org=None source=14.1 
   <title>Executor</title>
________________________________________________________-->
   <title>执行器</title>
<!-- pgdoc-cn_end sig_en=34f02afdb3c0de7ce0e385d73df10c24 -->

<!-- pgdoc-cn_start sig_en=17a14c3bcce3bc00a8aff4dea22878d1 sig_cn_org=None source=14.1 
   <para>
    The <firstterm>executor</firstterm> takes the plan created by the
    planner/optimizer and recursively processes it to extract the required set
    of rows.  This is essentially a demand-pull pipeline mechanism.
    Each time a plan node is called, it must deliver one more row, or
    report that it is done delivering rows.
   </para>
________________________________________________________-->
   <para>
    <firstterm>执行器</firstterm>接手规划器/优化器创建的计划，并递归地处理之以抽取所需的行集。这本质上是一种需求拉动的管道机制。每次一个计划节点被调用时，它必须交付一个或多个行，或者报告已经完成了行的交付。
   </para>
<!-- pgdoc-cn_end sig_en=17a14c3bcce3bc00a8aff4dea22878d1 -->

<!-- pgdoc-cn_start sig_en=01d76f29ae4ff47b47ca085d21c87483 sig_cn_org=None source=14.1 
   <para>
    To provide a concrete example, assume that the top
    node is a <literal>MergeJoin</literal> node.
    Before any merge can be done two rows have to be fetched (one from
    each subplan). So the executor recursively calls itself to
    process the subplans (it starts with the subplan attached to
    <literal>lefttree</literal>). The new top node (the top node of the left
    subplan) is, let's say, a
    <literal>Sort</literal> node and again recursion is needed to obtain
    an input row.  The child node of the <literal>Sort</literal> might
    be a <literal>SeqScan</literal> node, representing actual reading of a table.
    Execution of this node causes the executor to fetch a row from the
    table and return it up to the calling node.  The <literal>Sort</literal>
    node will repeatedly call its child to obtain all the rows to be sorted.
    When the input is exhausted (as indicated by the child node returning
    a NULL instead of a row), the <literal>Sort</literal> code performs
    the sort, and finally is able to return its first output row, namely
    the first one in sorted order.  It keeps the remaining rows stored so
    that it can deliver them in sorted order in response to later demands.
   </para>
________________________________________________________-->
   <para>
    为了提供一个具体例子，假设顶层节点是一个<literal>MergeJoin</literal>节点。在归并完成之前，两个行必须先被获取（每一个来自于一个子计划）。因此执行器递归地调用它自己去处理子计划（从附加在<literal>lefttree</literal>的子计划开始）。新的顶层节点（左子计划的顶层节点），我们说是一个<literal>Sort</literal>节点，并且又要递归来获取一个输入行。<literal>Sort</literal>的子节点可以是一个<literal>SeqScan</literal>节点，表示真正地读取一个表。该节点的执行将会使执行器从表中获取一行并将它返回给调用节点。<literal>Sort</literal>节点将反复调用它的子节点来获得所有需要排序的行。当输入耗尽后（子节点将返回一个NULL来标识），<literal>Sort</literal>节点执行排序，并且最后能够返回它的第一个输出行，及排序后的第一个。它会把剩下的行保存下来，这样它可以根据后续的要求按照排好的顺序返回这些行。
   </para>
<!-- pgdoc-cn_end sig_en=01d76f29ae4ff47b47ca085d21c87483 -->

<!-- pgdoc-cn_start sig_en=e8acbaa6e19d00b1b47f9cae1e7da781 sig_cn_org=None source=14.1 
   <para>
    The <literal>MergeJoin</literal> node similarly demands the first row
    from its right subplan.  Then it compares the two rows to see if they
    can be joined; if so, it returns a join row to its caller.  On the next
    call, or immediately if it cannot join the current pair of inputs,
    it advances to the next row of one table
    or the other (depending on how the comparison came out), and again
    checks for a match.  Eventually, one subplan or the other is exhausted,
    and the <literal>MergeJoin</literal> node returns NULL to indicate that
    no more join rows can be formed.
   </para>
________________________________________________________-->
   <para>
    <literal>MergeJoin</literal>节点也会相似地从其右子计划要求第一个行。然后它会比较两个子节点提供的行看它们是否能被连接，如果可以它会返回一个连接行给调用者。在下一次调用时，或者它无法连接当前的输入对时，它会前进到一个表或另一个表的下一行（取决于比较的结果），并再次检查匹配。最后，某个子计划耗尽，<literal>MergeJoin</literal>节点返回NULL表示它没有更多连接行可以提供。
   </para>
<!-- pgdoc-cn_end sig_en=e8acbaa6e19d00b1b47f9cae1e7da781 -->

<!-- pgdoc-cn_start sig_en=805e87f5a3c1af603dc2c4388a3fcff8 sig_cn_org=None source=14.1 
   <para>
    Complex queries can involve many levels of plan nodes, but the general
    approach is the same: each node computes and returns its next output
    row each time it is called.  Each node is also responsible for applying
    any selection or projection expressions that were assigned to it by
    the planner.
   </para>
________________________________________________________-->
   <para>
    复杂的查询可能涉及多层计划节点，但是一般的方法是相同的：每个节点在被调用时计算并返回它的下一个输出行。每个节点同时也负责应用由规划器分配给它的选择或投影表达式。
   </para>
<!-- pgdoc-cn_end sig_en=805e87f5a3c1af603dc2c4388a3fcff8 -->

<!-- pgdoc-cn_start sig_en=c1f3852ac12165b9dc2da1364314ab6e sig_cn_org=3b6a78eb6e2a75e5844c7bfa9b18e0e1 source=15.7 
   <para>
    The executor mechanism is used to evaluate all five basic SQL query
    types: <command>SELECT</command>, <command>INSERT</command>,
    <command>UPDATE</command>, <command>DELETE</command>, and
    <command>MERGE</command>.
    For <command>SELECT</command>, the top-level executor code
    only needs to send each row returned by the query plan tree
    off to the client.  <command>INSERT ... SELECT</command>,
    <command>UPDATE</command>, <command>DELETE</command>, and
    <command>MERGE</command>
    are effectively <command>SELECT</command>s under a special
    top-level plan node called <literal>ModifyTable</literal>.
   </para>
________________________________________________________-->
   <para>
    执行器机制用于评估所有五种基本的SQL查询类型：<command>SELECT</command>、<command>INSERT</command>、
    <command>UPDATE</command>、<command>DELETE</command>和<command>MERGE</command>。
    对于<command>SELECT</command>，顶层执行器代码只需要将查询计划树返回的每一行发送给客户端。
    <command>INSERT ... SELECT</command>、<command>UPDATE</command>、<command>DELETE</command>和
    <command>MERGE</command>实际上是在一个名为<literal>ModifyTable</literal>的特殊顶层计划节点下的
    <command>SELECT</command>。
</para>
<!-- pgdoc-cn_end sig_en=c1f3852ac12165b9dc2da1364314ab6e -->

<!-- pgdoc-cn_start sig_en=627b5ab30568e060ff977ec2532922fe sig_cn_org=6b523f18484c693ec3edc8a5f1b4aae0 source=15.7 
   <para>
    <command>INSERT ... SELECT</command> feeds the rows up
    to <literal>ModifyTable</literal> for insertion.  For
    <command>UPDATE</command>, the planner arranges that each
    computed row includes all the updated column values, plus the
    <firstterm>TID</firstterm> (tuple ID, or row ID) of the original
    target row; this data is fed up to the <literal>ModifyTable</literal>
    node, which uses the information to create a new updated row and
    mark the old row deleted.  For <command>DELETE</command>, the only
    column that is actually returned by the plan is the TID, and the
    <literal>ModifyTable</literal> node simply uses the TID to visit each
    target row and mark it deleted.  For <command>MERGE</command>, the
    planner joins the source and target relations, and includes all
    column values required by any of the <literal>WHEN</literal> clauses,
    plus the TID of the target row; this data is fed up to the
    <literal>ModifyTable</literal> node, which uses the information to
    work out which <literal>WHEN</literal> clause to execute, and then
    inserts, updates or deletes the target row, as required.
   </para>
________________________________________________________-->
   <para>
    <command>INSERT ... SELECT</command> 将行提供给 <literal>ModifyTable</literal> 进行插入。
    对于 <command>UPDATE</command>，规划器安排每个计算出的行包含所有更新列的值， 加上原始目标行的 <firstterm>TID</firstterm> (元组ID或行ID)；这些数据被提供给 <literal>ModifyTable</literal> 节点，该节点使用这些信息创建一个新的更新行并标记旧行已删除。
    对于 <command>DELETE</command>，计划实际返回的唯一列是TID， <literal>ModifyTable</literal> 节点只需使用TID访问每个目标行并将其标记为已删除。
    对于 <command>MERGE</command>， 规划器连接源和目标关系，并包含所有 <literal>WHEN</literal> 子句所需的列值，加上目标行的TID；
    这些数据被提供给 <literal>ModifyTable</literal> 节点，该节点使用这些信息来决定执行哪个 <literal>WHEN</literal> 子句，然后根据需要插入、更新或删除目标行。
</para>
<!-- pgdoc-cn_end sig_en=627b5ab30568e060ff977ec2532922fe -->

<!-- pgdoc-cn_start sig_en=38b7099870636cf6d0e4f6f0812ef21b sig_cn_org=4dc41404537f876739e4a37d199189bb source=15.7 
   <para>
    A simple <command>INSERT ... VALUES</command> command creates a
    trivial plan tree consisting of a single <literal>Result</literal>
    node, which computes just one result row, feeding that up
    to <literal>ModifyTable</literal> to perform the insertion.
   </para>
________________________________________________________-->
   <para>
    一个简单的<command>INSERT ... VALUES</command>命令创建了一个简单的计划树，由一个单独的<literal>Result</literal>节点组成，
    该节点仅计算一个结果行，将其传递给<literal>ModifyTable</literal>执行插入操作。
</para>
<!-- pgdoc-cn_end sig_en=38b7099870636cf6d0e4f6f0812ef21b -->

  </sect1>

 </chapter>
